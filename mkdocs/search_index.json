{
    "docs": [
        {
            "location": "/",
            "text": "CalTRACK Executive Summary\n\n\nDefinition\n\n\nCalTRACK is a set of methods for calculating site-based, weather-normalized, metered energy savings from an existing conditions baseline and applied to single family residential retrofits using data from utility meters.\n\n\nScope\n\n\nCalTRACK can be used by Program Administrators or third party implementers for managing energy efficiency programs. CalTRACK also supports Pay-for-Performance programs by tracking metered savings using calculations that are transparent and replicable. When both parties - purchaser and vendor - use the same standardized set of methods for calculating energy savings, a mature and robust energy efficiency market is possible.\n\n\nCalTRACK attempts to comply with\n AB-802\n (Williams, 2015) and\n SB-350\n (de Le\u00f3n, 2015).\n\n\nCalTRACK calculates the whole-building site-based savings that result from any mix of measures, building types, and consumer behavior. CalTRACK does not estimate the amount of savings that can be attributed to a particular measure.\n\n\nCalTRACK does not take the place of program evaluation. Calculating site-based, weather normalized metered energy savings is often a first step in a program evaluation, but a full evaluation that seeks to control for other effects, such as exogenous factors like economic growth or technology adoption or endogenous factors like socioeconomic status would be expected to consider additional variables.\n\n\nThese methods focus specifically on calculating site-based, weather-normalized metered energy savings for determining payments under a Pay-for-Performance program, rather than the more evaluation oriented guidance that is found in ASHRAE Guideline 14 or the Uniform Methods Project (UMP). CalTRACK methods do not require energy consumption data from a population of energy users beyond the treatment group.\n\n\nCalTRACK allows third-party energy efficiency program implementers to conduct energy savings analysis on their own customers themselves, provided they are given access to their customers\u2019 energy consumption data via Green Button or other means. This ability to track program performance in real time gives implementers an essential tool to monitor their performance and adjust their implementation practices. It also allows aggregators to quantify their expected yields for Pay-for-Performance programs.\n\n\nTesting\n\n\nThe CalTRACK methods were informed by and developed in concert with empirical testing by members of the CalTRACK technical Working Group listed below.\n\n\nThe empirical testing and refinement of the methods was performed using historical program data supplied by PG&E from an existing home upgrade program and included data from 4,777 homes that were retrofitted during 2014 and 2015. The CalTRACK methods include instructions for data cleaning and formatting as well as a two-stage model for calculating savings and aggregating site based savings into portfolios. The results of the methods testing as well as the deliberations of the working group are documented in GitHub.\n\n\nThe CalTRACK technical working group\u2019s empirical testing of these methods is archived in a Github repository. The repository contains the results of a variety of tests related to the methods choices. In general, the group limited its discussions to focus on specific technical issues rather than on broader, policy-oriented issues. These discussions can be found in the \"\nIssues\n\" section of the\n CalTRACK Github repository\n. While summary statistics are presented for both monthly and daily analysis, the intent was to use testing to inform methods guidance rather than to provide for a software equivalency testing process.\n\n\nMethods\n\n\nThe technical working group arrived at two sets of methods specifications, the first for calculating savings using monthly data, and the second for calculating savings using daily data. These methods are referred to as Monthly and Daily, respectively, and have each been tagged with a version number of 1.0.\n\n\nThe purpose of versioning the CalTRACK methods specification that informed the initial guidance is to lay the foundation for further efforts to refine and expand upon these methods. We invite collaboration from stakeholders to perform their own empirical tests of these methods and to offer suggestions for improvement, ideas for how to handle edge cases, or provide further tests to identify potential issues.\n\n\nWe have taken this first step towards an empirically-informed, professionally-tested, and transparent set of methods. We encourage others to work together to continue to make progress.\n\n\nCalTRACK Working Group\n\n\n\u25cf   \nLeif Magnuson - PG&E Project Lead\n\n\n\u25cf   \nMatt Golden - Open Energy Efficiency\n*\n\n\n\u25cf   \nMatt Gee - Open Energy Efficiency\n*\n\n\n\u25cf   \nMcGee Young - Open Energy Efficiency\n*\n\n\n\u25cf   \nKen Agnew \u2013 DNV GL\n*\n\n\n\u25cf   \nJarred Metoyer \u2013 DNV GL\n*\n\n\n\u25cf   \nJonathan Farland \u2013 DNV GL\n*\n\n\n\u25cf   \nBen Polly - NREL\n\n\n\u25cf   \nBrian A. Smith - PG&E\n\n\n\u25cf   \nCharlene Chi-Johnston - PG&E\n\n\n\u25cf   \nCynthia Swaim - Sempra Utilities\u200b\n\n\n\u25cf   \nDenise Parker - SoCal Edison\n\n\n\u25cf   \nGamaliel Lodge - Optimiser Energy\n\n\n\u25cf   \nJake Oster -  EnergySavvy\n*\n\n\n\u25cf   \nJohn Backus Mayes \u2013 EnergySavvy\n*\n\n\n\u25cf   \nBlake Hough \u2013 EnergySavvy\n*\n\n\n\u25cf   \nLisa Schmidt - Home Energy Analyzer\n\n\n\u25cf   \nMartha Brook - CEC\n\n\n\u25cf   \nRichard Ridge, PhD - PG&E\n\n\n\u25cf   \nRobert Hansen - CPUC\n\n\n\u25cf   \nRyan Bullard - SoCal Edison\n\n\n\u25cf   \nTorsten Glidden - Build it Green\n\n\n\u25cf   \nAlfredo Gutierrez - ICF\n\n\n\u25cf   \nAble Gomez - RHA\n\n\n*Open Energy Efficiency, DNV GL, and EnergySavvy participated in methods development and testing for both monthly and daily methods.\n\n\n=======",
            "title": "Home"
        },
        {
            "location": "/#caltrack-executive-summary",
            "text": "Definition  CalTRACK is a set of methods for calculating site-based, weather-normalized, metered energy savings from an existing conditions baseline and applied to single family residential retrofits using data from utility meters.  Scope  CalTRACK can be used by Program Administrators or third party implementers for managing energy efficiency programs. CalTRACK also supports Pay-for-Performance programs by tracking metered savings using calculations that are transparent and replicable. When both parties - purchaser and vendor - use the same standardized set of methods for calculating energy savings, a mature and robust energy efficiency market is possible.  CalTRACK attempts to comply with  AB-802  (Williams, 2015) and  SB-350  (de Le\u00f3n, 2015).  CalTRACK calculates the whole-building site-based savings that result from any mix of measures, building types, and consumer behavior. CalTRACK does not estimate the amount of savings that can be attributed to a particular measure.  CalTRACK does not take the place of program evaluation. Calculating site-based, weather normalized metered energy savings is often a first step in a program evaluation, but a full evaluation that seeks to control for other effects, such as exogenous factors like economic growth or technology adoption or endogenous factors like socioeconomic status would be expected to consider additional variables.  These methods focus specifically on calculating site-based, weather-normalized metered energy savings for determining payments under a Pay-for-Performance program, rather than the more evaluation oriented guidance that is found in ASHRAE Guideline 14 or the Uniform Methods Project (UMP). CalTRACK methods do not require energy consumption data from a population of energy users beyond the treatment group.  CalTRACK allows third-party energy efficiency program implementers to conduct energy savings analysis on their own customers themselves, provided they are given access to their customers\u2019 energy consumption data via Green Button or other means. This ability to track program performance in real time gives implementers an essential tool to monitor their performance and adjust their implementation practices. It also allows aggregators to quantify their expected yields for Pay-for-Performance programs.  Testing  The CalTRACK methods were informed by and developed in concert with empirical testing by members of the CalTRACK technical Working Group listed below.  The empirical testing and refinement of the methods was performed using historical program data supplied by PG&E from an existing home upgrade program and included data from 4,777 homes that were retrofitted during 2014 and 2015. The CalTRACK methods include instructions for data cleaning and formatting as well as a two-stage model for calculating savings and aggregating site based savings into portfolios. The results of the methods testing as well as the deliberations of the working group are documented in GitHub.  The CalTRACK technical working group\u2019s empirical testing of these methods is archived in a Github repository. The repository contains the results of a variety of tests related to the methods choices. In general, the group limited its discussions to focus on specific technical issues rather than on broader, policy-oriented issues. These discussions can be found in the \" Issues \" section of the  CalTRACK Github repository . While summary statistics are presented for both monthly and daily analysis, the intent was to use testing to inform methods guidance rather than to provide for a software equivalency testing process.  Methods  The technical working group arrived at two sets of methods specifications, the first for calculating savings using monthly data, and the second for calculating savings using daily data. These methods are referred to as Monthly and Daily, respectively, and have each been tagged with a version number of 1.0.  The purpose of versioning the CalTRACK methods specification that informed the initial guidance is to lay the foundation for further efforts to refine and expand upon these methods. We invite collaboration from stakeholders to perform their own empirical tests of these methods and to offer suggestions for improvement, ideas for how to handle edge cases, or provide further tests to identify potential issues.  We have taken this first step towards an empirically-informed, professionally-tested, and transparent set of methods. We encourage others to work together to continue to make progress.  CalTRACK Working Group  \u25cf    Leif Magnuson - PG&E Project Lead  \u25cf    Matt Golden - Open Energy Efficiency *  \u25cf    Matt Gee - Open Energy Efficiency *  \u25cf    McGee Young - Open Energy Efficiency *  \u25cf    Ken Agnew \u2013 DNV GL *  \u25cf    Jarred Metoyer \u2013 DNV GL *  \u25cf    Jonathan Farland \u2013 DNV GL *  \u25cf    Ben Polly - NREL  \u25cf    Brian A. Smith - PG&E  \u25cf    Charlene Chi-Johnston - PG&E  \u25cf    Cynthia Swaim - Sempra Utilities\u200b  \u25cf    Denise Parker - SoCal Edison  \u25cf    Gamaliel Lodge - Optimiser Energy  \u25cf    Jake Oster -  EnergySavvy *  \u25cf    John Backus Mayes \u2013 EnergySavvy *  \u25cf    Blake Hough \u2013 EnergySavvy *  \u25cf    Lisa Schmidt - Home Energy Analyzer  \u25cf    Martha Brook - CEC  \u25cf    Richard Ridge, PhD - PG&E  \u25cf    Robert Hansen - CPUC  \u25cf    Ryan Bullard - SoCal Edison  \u25cf    Torsten Glidden - Build it Green  \u25cf    Alfredo Gutierrez - ICF  \u25cf    Able Gomez - RHA  *Open Energy Efficiency, DNV GL, and EnergySavvy participated in methods development and testing for both monthly and daily methods.  =======",
            "title": "CalTRACK Executive Summary"
        },
        {
            "location": "/data-sources/v1.0/README/",
            "text": "Data Sources for CalTRACK Methods\n\n\nThree types of data files are required to run the CalTRACK methods: project data, energy consumption data, and weather data. These data must be linked with cross-reference files that define the mapping between ID columns in each of the data source types (Projects ID to Usage ID & Project ID to Weather Station ID).\n\n\nThis documentation is intended to provide general guidance on these three data sources for use in implementing CalTRACK methods.\n\n\nProject Data\n\n\nWhile project data can be incredibly rich and incredibly varied, the CalTRACK methods aim to define a minimal set of data fields on projects necessary to perform CalTRACK analysis. Thankfully, this set is comparatively small. To perform CalTRACK analysis, you need to be able to uniquely identify a project, identify the location of the project, and the timing of the efficiency investment or intervention. We recommend your project data take on the general form:\n\n\n\n  \n\n    \nColumn Name\n\n    \nDescription\n\n  \n\n  \n\n    \nProjectID\n\n    \nA unique identifier for projects in the aggregator's database that can be used to link with additional project-specific information if desired\n\n  \n\n  \n\n    \nElectric Account ID\n\n    \nID used for uniquely matching with electric consumption files\n\n  \n\n  \n\n    \nGas Account ID\n\n    \nID used for uniquely matching with gas consumption files\n\n  \n\n  \n\n    \nWork Start Date\n\n    \nPreferably the date actual work on the retrofit started, not the date that the application was made or approved\n\n  \n\n  \n\n    \nWork Finish Date\n\n    \nPreferably the date that actual work on the retrofit or intervention was finished, not the date that the reimbursement was filed or approved\n\n  \n\n  \n\n    \nBuilding ZIP Code\n\n    \nThe minimal geographic identifier for matching a site to a weather station\n\n  \n\n\n\n\n\nConsumption Data\n\n\nConsumption data for this project took the form of 15-minute and hourly electricity data and daily natural gas data. The raw files were provided by PG&E in a file format typically associated with the SAS statistical package (.XPT). You will need to find a parser that can output this data into the format that you need. Consider the unique date format associated with .XPT to make sure you are formatting your dates correctly. The following table reflects the data that were provided.\n\n\n\n  \n\n    \nColumn Name\n\n    \nDescription\n\n  \n\n  \n\n    \nSPID\n\n    \nService Point ID to be used to link to project records\n\n  \n\n  \n\n    \nSA\n\n    \nAccount ID to be used to link to project records\n\n  \n\n  \n\n    \nUOM\n\n    \nUnit of Measurement (kWh or Therms)\n\n  \n\n  \n\n    \nDIR\n\n    \nUsed for Net Metering. R indicates presence of solar production\n\n  \n\n  \n\n    \nDATE\n\n    \nDate of usage readings\n\n  \n\n  \n\n    \nRS\n\n    \nRate code classification. Also useful for indicating presence of solar production and other DR programs.\n\n  \n\n  \n\n    \nUsage Columns\n\n    \nTotal usage for time period specified measured in total consumption for the time interval preceding the column header\n\n  \n\n\n\n\n\nCross-reference files\n\n\nBoth \nelectric and gas\n cross-reference files contain the same columns of interest. These files were used to obtain a mapping between project files and consumption files.\n\n\n\n  \n\n    \nColumn Name\n\n    \nDescription\n\n  \n\n  \n\n    \nProject ID\n\n    \nA unique identifier for projects in the aggregators project database.\n\n  \n\n  \n\n    \nUsage Record ID\n\n    \nThis typically corresponds to a meter ID, account ID, or service point ID used to uniquely identify a usage trace with a customer in the utility's usage database. There are often separate IDs for gas and electric\n\n  \n\n  \n\n    \nPremise ID\n\n    \n(Optional) This typically corresponds to a unique premise can be necessary for combining multiple usage records into a single premise-level record in the event that households have multiple meters for one fuel type, or usage IDs change when the same customer enters into a new service agreement with the utility\n\n  \n\n\n\n\n\nWeather\n\n\nBoth actual observed weather data and normal year weather data are used in the CalTRACK analysis. The appropriate observed weather and normal year weather for each project are determined using the site\u2019s ZIP code, which is mapped to weather stations using \nthe mapping file\n, which has five fields for each ZIP code in California:\n\n\n\n  \n\n    \nZipCode\n\n    \n5-digit ZIP code for the project site\n\n  \n\n  \n\n    \nClimateZone\n\n    \nThe climate zone number; not used.\n\n  \n\n  \n\n    \nWeatherFile\n\n    \nThe file name for the CZ2010 normal year temperatues\n\n  \n\n  \n\n    \nWthrStationNum\n\n    \nThe weather station identifier in the ISD data set.\n\n  \n\n  \n\n    \nIsValid\n\n    \n1 for valid, 0 for invalid.\n\n  \n\n\n\n\n\nOnce the appropriate WthrStationNum is identified, the observed temperatures can be downloaded from the ISD data set at ftp.ncdc.noaa.gov/pub/data/noaa/, in the format described \nhere\n. Two fields on each line of the relevant weather station\u2019s file are used: the date/time (YYYYmmddHHMM, from characters 16-27) and the hourly dry bulb temperature in degrees Celsius (characters 88-92). \n\n\nThe available hourly temperatures for each day (where day is defined by dropping the HHMM fields from the date/time field) are averaged together and converted to degrees Fahrenheit to produce the daily temperature, which is then used to calculate heating and cooling degree days. Missing data points are ignored as long as at least one hourly temperature reading for a given day is available. \n\n\nNormal year temperatures are determined using the CZ2010 files available \nhere\n; the particular file for each ZIP code is identified by the WeatherFile field in the mapping file described above. Again, the only relevant columns are Date (MM/DD/YYYY),Time (HH:MM), and Dry-bulb (C), where the year is ignored. The normal year temperatures are averaged over days as with the ISD observed temperature data.",
            "title": "Data Sources"
        },
        {
            "location": "/data-sources/v1.0/README/#data-sources-for-caltrack-methods",
            "text": "Three types of data files are required to run the CalTRACK methods: project data, energy consumption data, and weather data. These data must be linked with cross-reference files that define the mapping between ID columns in each of the data source types (Projects ID to Usage ID & Project ID to Weather Station ID).  This documentation is intended to provide general guidance on these three data sources for use in implementing CalTRACK methods.",
            "title": "Data Sources for CalTRACK Methods"
        },
        {
            "location": "/data-sources/v1.0/README/#project-data",
            "text": "While project data can be incredibly rich and incredibly varied, the CalTRACK methods aim to define a minimal set of data fields on projects necessary to perform CalTRACK analysis. Thankfully, this set is comparatively small. To perform CalTRACK analysis, you need to be able to uniquely identify a project, identify the location of the project, and the timing of the efficiency investment or intervention. We recommend your project data take on the general form:  \n   \n     Column Name \n     Description \n   \n   \n     ProjectID \n     A unique identifier for projects in the aggregator's database that can be used to link with additional project-specific information if desired \n   \n   \n     Electric Account ID \n     ID used for uniquely matching with electric consumption files \n   \n   \n     Gas Account ID \n     ID used for uniquely matching with gas consumption files \n   \n   \n     Work Start Date \n     Preferably the date actual work on the retrofit started, not the date that the application was made or approved \n   \n   \n     Work Finish Date \n     Preferably the date that actual work on the retrofit or intervention was finished, not the date that the reimbursement was filed or approved \n   \n   \n     Building ZIP Code \n     The minimal geographic identifier for matching a site to a weather station",
            "title": "Project Data"
        },
        {
            "location": "/data-sources/v1.0/README/#consumption-data",
            "text": "Consumption data for this project took the form of 15-minute and hourly electricity data and daily natural gas data. The raw files were provided by PG&E in a file format typically associated with the SAS statistical package (.XPT). You will need to find a parser that can output this data into the format that you need. Consider the unique date format associated with .XPT to make sure you are formatting your dates correctly. The following table reflects the data that were provided.  \n   \n     Column Name \n     Description \n   \n   \n     SPID \n     Service Point ID to be used to link to project records \n   \n   \n     SA \n     Account ID to be used to link to project records \n   \n   \n     UOM \n     Unit of Measurement (kWh or Therms) \n   \n   \n     DIR \n     Used for Net Metering. R indicates presence of solar production \n   \n   \n     DATE \n     Date of usage readings \n   \n   \n     RS \n     Rate code classification. Also useful for indicating presence of solar production and other DR programs. \n   \n   \n     Usage Columns \n     Total usage for time period specified measured in total consumption for the time interval preceding the column header",
            "title": "Consumption Data"
        },
        {
            "location": "/data-sources/v1.0/README/#cross-reference-files",
            "text": "Both  electric and gas  cross-reference files contain the same columns of interest. These files were used to obtain a mapping between project files and consumption files.  \n   \n     Column Name \n     Description \n   \n   \n     Project ID \n     A unique identifier for projects in the aggregators project database. \n   \n   \n     Usage Record ID \n     This typically corresponds to a meter ID, account ID, or service point ID used to uniquely identify a usage trace with a customer in the utility's usage database. There are often separate IDs for gas and electric \n   \n   \n     Premise ID \n     (Optional) This typically corresponds to a unique premise can be necessary for combining multiple usage records into a single premise-level record in the event that households have multiple meters for one fuel type, or usage IDs change when the same customer enters into a new service agreement with the utility",
            "title": "Cross-reference files"
        },
        {
            "location": "/data-sources/v1.0/README/#weather",
            "text": "Both actual observed weather data and normal year weather data are used in the CalTRACK analysis. The appropriate observed weather and normal year weather for each project are determined using the site\u2019s ZIP code, which is mapped to weather stations using  the mapping file , which has five fields for each ZIP code in California:  \n   \n     ZipCode \n     5-digit ZIP code for the project site \n   \n   \n     ClimateZone \n     The climate zone number; not used. \n   \n   \n     WeatherFile \n     The file name for the CZ2010 normal year temperatues \n   \n   \n     WthrStationNum \n     The weather station identifier in the ISD data set. \n   \n   \n     IsValid \n     1 for valid, 0 for invalid. \n     Once the appropriate WthrStationNum is identified, the observed temperatures can be downloaded from the ISD data set at ftp.ncdc.noaa.gov/pub/data/noaa/, in the format described  here . Two fields on each line of the relevant weather station\u2019s file are used: the date/time (YYYYmmddHHMM, from characters 16-27) and the hourly dry bulb temperature in degrees Celsius (characters 88-92).   The available hourly temperatures for each day (where day is defined by dropping the HHMM fields from the date/time field) are averaged together and converted to degrees Fahrenheit to produce the daily temperature, which is then used to calculate heating and cooling degree days. Missing data points are ignored as long as at least one hourly temperature reading for a given day is available.   Normal year temperatures are determined using the CZ2010 files available  here ; the particular file for each ZIP code is identified by the WeatherFile field in the mapping file described above. Again, the only relevant columns are Date (MM/DD/YYYY),Time (HH:MM), and Dry-bulb (C), where the year is ignored. The normal year temperatures are averaged over days as with the ISD observed temperature data.",
            "title": "Weather"
        },
        {
            "location": "/data-prep/v1.0/README/",
            "text": "Data Preparation for CalTRACK Methods\n\n\nCalTRACK employs the following processes when preparing weather, project, and daily/hourly/monthly consumption data for performing the analysis specified in the CalTRACK v1.0 methods.\n\n\nOverview\n\n\nBelow are guidelines and a general process for addressing the most common issues that arise during data cleaning efforts for analysis. It is recommended to conduct these steps in the order they appear because the final combined dataset is highly sensitive to the order of data preparation steps.\n\n\nGuidelines on Project Data Preparation\n\n\nThe minimum field requirements for project data under the CalTRACK daily specification are outlined \nhere\n. Notably, a prepared project file should consist of one row per project, with a unique ID that can be used to link to gas and/or electric usage data, project start and stop dates, and zip code for the site.\n\n\nThe following data cleaning steps for project data are meant to ensure that the prepared project file meets these field requirements and uniqueness constraints.\n\n\nCreating Work Start and Work End dates from raw project data\n\n\nAccurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, considerable variation may occur in database records identifying dates associated with project start and project completion. In general, users should try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), it is recommended that users identify an average time to completion. CalTRACK implementations should use official work start date and work end date fields provided by aggregators rather than proxy fields when available.\n\n\nDealing with miscoded dates\n\n\nImplausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window. Implausible month and year values should be flagged and corrected or removed from the analysis.\n\n\nDeduplicate project records\n\n\nIf a building appears multiple times within a project database, and the project dates are the same, the most complete record for that building should be used. If a building appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.\n\n\nGuidelines on Weather Data Preparation\n\n\nWeather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects\n* For California, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files. Clean versions of these files can be found \nhere\n.\n\n\nGuidelines on Daily Electric and Gas Usage Preparation\n\n\nGenerally, the quality of your consumption data may vary substantially from sample to sample. You will need to clean your data so that it meets the following requirements:\n\n\n\n\nTraces are clearly marked for interval frequency (e.g., 15-minute, hour, day)\n\n\nTraces are clearly marked for direction (reverse if net-metered and net solar production is higher than gross consumption).\n\n\nWhere available, the presence of net-metering is clearly marked (CalTRACK excludes homes that are net-metered)\n\n\nTraces are not duplicated in whole or in part\n\n\n\n\nThe dataset generated for the CalTRACK beta test originated from a pool of projects and consumption data provided by PG&E (see \nData Sources\n). A smaller set of 1000 natural gas meters and 1000 electricity meters were selected from this larger pool for the purposes of testing. These meters were selected based on location (attempting to maximize coverage over each of the climate zones) and data sufficiency (each meter contains at least two years of historical usage data prior to the intervention period). \n\n\nRoll up sub-daily interval data to daily totals\n\n\nIf using sub-daily interval data (hourly, 15-minute, etc intervals), roll it up to daily totals following this procedure:\n\n Check to make sure at least 50% of the intervals in the day have usage data.  For electricity, usage values of 0 should count as missing (for gas a usage value of 0 is valid and does not indicate missing data).  If more than 50% of the interval data is missing drop this day from the analysis.\n\n Calculate total daily usage: multiply the average usage for all intervals in the day by the number of intervals (i.e. for hourly data, 24 * average hourly usage)\n\n\nLink project records and usage files\n\n\nOnce project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. CalTRACK recommends using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, CalTRACK does not offer specific guidance.\n\n\nUnmatched data should be excluded from analysis.\n\n\nDeduplicate records based on combined attributes\n\n\n\n\nIf two duplicate records have identical consumption traces and date ranges, drop one at random\n\n\nIf two duplicate records have identical consumption traces but different date ranges, prioritize the record that overlaps the baseline period in its entirety and encompasses a greater portion of the reporting period. \n\n\nIf the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.\n\n\nIf the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.\n\n\n\n\nDrop records not meeting data sufficiency requirements\n\n\n\n\n12 months consumption data prior to the date of the intervention recommended for all projects.\n\n\nData is considered sufficient when it contains usage data for 90% of coverage period.\n\n\n12 months consumption data after the date of the intervention is recommended for all projects. \n\n\nData is considered missing if it is clearly marked as NaN or similar by the data provider.\n\n\nConsumption records marked as \u201cestimated\u201d are rare when parsing AMI data, but if any should appear they should be discarded.\n\n\n\n\nDrop project records with unsupported characteristics\n\n\n\n\nDrop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. \n\n\nFuture efforts may provide the ability to access sub-meter data that may allow for backing out onsite generation and storage to arrive at savings.\n\n\n\n\nGuidelines for Monthly Electric and Gas Usage Preparation\n\n\nDealing with missing values in monthly usage data\n\n\nUsage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with \u201cestimated\u201d reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.\n\n\n\n\nFor the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the use per day for that period.\n\n\nMissing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements.\n\n\nCalTRACK does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.\n\n\nIf flags exist for estimated values, they are counted as missing and count against the site\u2019s data sufficiency criteria detailed later in this guidance.\n\n\n\n\nDealing with extreme values in usage data\n\n\nOccasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels) and should be handled based on the following guidance:\n\n\n\n\nNegative values for monthly use should be treated as missing and count against sufficiency criterion. Negative values in monthly data may also be a valid sign of possible solar/net metering and should be flagged for verification.\n\n\n\n\nDeduplicate records based on combined attributes\n\n\n\n\nIf two duplicate records have identical consumption traces and date ranges, drop one at random.\n\n\nIf two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.\n\n\nIf the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.\n\n\n\n\nDrop records not meeting data sufficiency requirements\n\n\nCalculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.\n\n\n\n\n12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months.\n\n\nTotal annual savings estimates will require 12 months post-retrofit.\n\n\n\n\nDrop project records with unsupported characteristics\n\n\n\n\nDrop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. However, if you only have access to billing data, CalTRACK recommends working with the utility to get flags for accounts that have net metering present so they can be excluded from the analysis.\n\n\nFuture efforts may provide the ability to access sub-meter data that may allow for backing out onsite generation and storage to arrive at savings.\n\n\n\n\nGuidelines for Linking Project and Usage Files\n\n\nOnce project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. CalTRACK recommends using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, CalTRACK does not offer specific guidance.\n\n\nUnmatched data should be excluded from analysis.\n\n\nGuidelines for Final Combined Data Sufficiency Checks\n\n\nIt is recommended that you run a final audit of your data to evaluate the outputs of the data cleaning process. You should be able to match the number of projects eliminated from your analysis at each step listed above. Your final audit will also serve as a useful reference for further data analysis and aggregation.\n\n\n\n\nBilling periods (the period between bill start date and bill end date in the monthly usage data) with more than 10% missing days of weather data will be thrown out and count against the required number of billing period observations.\n\n\nAny projects with fewer than 12 months pre and 12 months post are not included in the analysis.\n\n\n\n\nDetailed Data Preparation Instructions\n\n\nWhat follows in an example of data prep steps that could be used to create files for analysis. These steps are one example implementation of the guidelines laid out above.\n\n\nOverall, 3 types of files are generated during this process for use in the CalTRACK methods:\n\n\n\n\nProject data\n\n\nTrace data\n\n\nProject to Trace mappings\n\n\n\n\nThe Project Data file should have the following fields:\n\n\n\n\nproject_id\n: A unique identifier for the project (should occur once in the file).\n\n\nzipcode\n: Used for linking weather data for the project.\n\n\nbaseline_period_end\n: Date the project started - usage data prior to this is used to establish a baseline.\n\n\nreporting_period_start\n: Date the project ended. Usage after this is used to determine savings against the baseline.\n\n\n\n\nTrace Data files should have the following fields:\n\n\n\n\ntrace_id\n: A unique identifier for the trace (can occur more than once in the file to identify individual trace records).\n\n\nunit\n: Unit of measurement for the trace record (\u201cKWH\u201d or \u201cTHERM\u201d).\n\n\nestimated\n: Whether this is an estimated reading (\u201cTrue\u201d or \u201cFalse\u201d).\n\n\n\n\ninterpretation\n: For purposes of this data, one of the following is always used:\n\n\n\n\nELECTRICITY_CONSUMPTION_SUPPLIED - Represents the amount of utility-supplied electrical energy consumed on-site, as metered at a single usage point, such as a utility-owned electricity meter. Specifically does not include consumption of electricity generated on site, such as by locally installed solar photovoltaic panels.\n\n\nELECTRICITY_ON_SITE_GENERATION_UNCONSUMED - Represents the amount of excess locally generated energy, which instead of being consumed on-site, is fed back into the grid or sold back a utility.\n\n\nNATURAL_GAS_CONSUMPTION_SUPPLIED - Represents the amount of energy supplied by a utility in the form of natural gas and used on site, as metered at a single usage point.\n\n\n\n\n\n\n\n\nstart\n: Starting date time for the trace record.\n\n\n\n\nvalue\n: Value of the trace record (i.e. number of KWH/THERM)\n\n\n\n\nProject to Trace mapping files contain just two fields:\n\n\n\n\nproject_id\n\n\ntrace_id\n\n\n\n\nA fourth type of file containing weather data is also used, but is not generated by the data prep process - weather data is described in greater detail in the \nLink weather data and project records\n section below.\n\n\nThe CalTRACK data preparations guidelines for daily analysis consist of the following steps:\n\n\n\n\nCross Reference File Preparation\n\n\nProject Data Preparation\n\n\n15 Minute Electric Use Preparation\n\n\nHourly Electric Use Preparation\n\n\nMonthly Electric Use Preparation\n\n\nDaily Gas Use Preparation\n\n\nMonthly Gas Use Preparation\n\n\nLinking Projects to Usage/Trace Data\n\n\n\n\nFile List\n\n\nCross Reference Files\n\n\n\n\nEES25162_ELECINTV_XREF_CPUC.csv (Electricity Cross Reference)\n\n\nEES25162_GASINTV_XREF_CPUC.csv (Gas Cross Reference 1 of 2)\n\n\nEES25162_GASINTV2_XREF_CPUC.csv (Gas Cross Reference 2 of 2)\n\n\n\n\nProject Files\n\n\n\n\nCalTrack (AHU) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n\n\nCalTrack (AHU) from 7_1_15__6_30_16_v2_FINAL_090816.csv\n\n\nCalTrack (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n\n\n\n\nUsage Files\n\n\n\n\nIDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv (15 minute electricity)\n\n\nEES25162_gasdy_160720.csv (daily gas 1 of 2)\n\n\nEES25162_gasdy_160920.csv (daily gas 2 of 2)\n\n\nIDA.60MIN.SMY1.EES25162-EHUP.20160719161716.csv (hourly electricity)\n\n\nEES25162.ERESBL12 (1).XPT (monthly electricity 1 of 4)\n\n\nEES25162.ERESBL13.XPT (monthly electricity 2 of 4)\n\n\nEES25162.ERESBL15.XPT (monthly electricity 3 of 4)\n\n\nEES25162.ERESBL16.XPT (monthly electricity 4 of 4)\n\n\nEES25162.G2RSBL12.XPT (monthly gas 1 of 11)\n\n\nEES25162.G2RSBL13.XPT (monthly gas 2 of 11)\n\n\nEES25162.G2RSBL14.XPT (monthly gas 3 of 11)\n\n\nEES25162.G2RSBL15.XPT (monthly gas 4 of 11)\n\n\nEES25162.G2RSBL16.XPT (monthly gas 5 of 11)\n\n\nEES25162.GRESBL12.XPT (monthly gas 6 of 11)\n\n\nEES25162.GRESBL13.XPT (monthly gas 7 of 11)\n\n\nEES25162.GRESBL14.XPT (monthly gas 8 of 11)\n\n\nEES25162.GRESBL15.XPT (monthly gas 9 of 11)\n\n\nEES25162.GRESBL16.JANJUNE.XPT (monthly gas 10 of 11)\n\n\nEES25162.GRESBL16.XPT (monthly gas 11 of 11)\n\n\n\n\nCross Reference File preparation\n\n\nA series of cross reference files are provided that can be used to link projects to usage information. These are:\n\n\n\n\nEES25162_ELECINTV_XREF_CPUC.csv (Electricity Cross Reference)\n\n\nEES25162_GASINTV_XREF_CPUC.csv (Gas Cross Reference 1 of 2)\n\n\nEES25162_GASINTV2_XREF_CPUC.csv (Gas Cross Reference 2 of 2)\n\n\n\n\nIt is recommended that cross reference (or \u201cxref\u201d) files be prepared first since they contain information that will be useful in formatting the project and usage data in later steps.\n\n\nAlso required for this cleaning step will be the following:\n\n\n\n\nIDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv (15 minute electricity)\n\n\nIDA.60MIN.SMY1.EES25162-EHUP.20160719161716.csv (hourly electricity)\n\n\n\n\nWith the electricity cross reference file, perform the following:\n\n\n\n\n\n\nObtain all net metered Service Account Ids from the 15 minute file electricity file.\n\n\n\n\nIn the 15 minute and hourly electricity data, any record where \nDIR\n is \nR\n is net metered.\n\n\n\n\n\n\n\n\nObtain all net metered SA ids from the hourly electricity file, combine with those found in step 1.\n\n\n\n\nLeft pad with zeroes (or zfill) to 10 all \nchar_prem_id\ns.\n\n\nUsing the Electricity Cross Reference file, build a map of \nsa_id\n to \nchar_prem_id\n.\n\n\n\n\nUsing a combination of the Electricity Cross Reference file, the net metered SA id set from steps 1 and 2, and the map from 4, add the \nis_net_metered\n column to the Electricity Cross Reference file.\n\n\n\n\nAny row in the file that has \nnet_mtr_ind\n set to \nY\n is net metered\n\n\nAny row that has an \nsa_id\n in the set from steps 1 and 2 is net metered\n\n\n\n\n\n\n\n\nBuild a map of \nsa_id\n to \nchar_prem_id\n.\n\n\n\n\nBuild a map of \nsp_id\n to \nchar_prem_id\n.\n\n\n\n\nYour Electricity Cross Reference file now has what is needed. In future steps, the map from step 5 will be used to help map projects, and any project that is net metered should be excluded from analysis.\n\n\nUpon completion, your finalized Electricity Cross Reference file should contain 8004 records (not including header).\n\n\nWith the gas cross reference file, perform the following:\n\n\n\n\nCombine the two files into a single CSV.\n\n\nLeft pad with zeroes (or zfill) the \nchar_prem_id\ns.\n\n\nBuild a map of \nsa_id\n to \nchar_prem_id\n.\n\n\nBuild a map of \nsp_id\n to \nchar_prem_id\n.\n\n\n\n\nYou now have a single Gas Cross Reference file. In future steps, the map from step 3 will be used to help map projects, while the map in step 4 will be used to help map traces.\n\n\nUpon completion, your finalized Gas Cross Reference file should contain 6928 records (not including header).\n\n\nProject data preparation\n\n\nIn the beta test data, the following files were provided containing project information:\n\n\n\n\nCalTrack (AHU) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n\n\nCalTrack (AHU) from 7_1_15__6_30_16_v2_FINAL_090816.csv\n\n\nCalTrack (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n\n\n\n\nYou\u2019ll also be using the \nsa_id\n to \nchar_prem_id\n maps you created from the Electric and Gas Cross Reference Files in the \nCross Reference File Preparation\n section above.\n\n\nPerform the following:\n\n\n\n\n\n\nCombine the 3 project files into a single file.\n\n\n\n\nThe \nCalTrack (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n file has a column called \nApplication: Application No.\n instead of simply \nApplication No.\n like the other two files - the column should be treated the same when combining the files.\n\n\n\n\n\n\n\n\nEstimate project dates using the combined file - each project should have a \nWork Start Date\n and a \nWork Finish Date\n.\n\n\n\n\n\n\nFor each row, check if the \nNotice to Proceed Issued\n column is blank.\n\n\n\n\nIf it is, this is a project from one of the AHU files. Set the \nWork Start Date\n to the \nInitial Approval Date\n and the \nWork Finish Date\n to the \nInitial Submission Date\n.\n\n\n\n\nIf it is not, this is a project from the AHUP file. Set the \nWork Start Date\n to the \nNotice to Proceed Issued\n.\n\n\n\n\nIf the \nFull Application Returned\n field is blank, set the \nWork Finish Date\n to \nFull Application Submitted\n.\n\n\nOtherwise set \nWork Finish Date\n to \nFull Application Started\n.\n\n\n\n\n\n\n\n\n\n\n\n\nIf after completing step 2a above your \nWork Finish Date\n is still blank and your \nWork Start Date\n is not, set the \nWork Finish Date\n to 60 days after the \nWork Start Date\n.\n\n\n\n\n\n\n\n\n\n\nUsing the \nsa_id\n to \nchar_prem_id\n maps you saved from \nCross Reference File Preparation\n, add a \nchar_prem_id\n column to your combined project file.\n\n\n\n\nFor each row, check \nElectric Service ID\n against the \nsa_id\n in your electric map.\n\n\nFor each row, check \nGas Service ID\n against the \nsa_id\n in your gas map.\n\n\n\n\n\n\n\n\nMerge duplicate projects into one project.\n\n\n\n\nThere should only be one project per \nchar_prem_id\n. Build a dictionary with \nchar_prem_id\n as the key and a list of projects as the value.\n\n\n\n\nIf there is more than one project for a \nchar_prem_id\n, merge the projects.\n\n\n\n\nSet \nWork Start Date\n to the earliest available.\n\n\nSet \nWork Finish Date\n to the latest available.\n\n\n\n\n\n\n\n\n\n\n\n\nBuild a map of \nchar_prem_id\n to \nApplication No.\n for later use in mapping projects to traces.\n\n\n\n\n\n\nTranslate the file into the format required. If using the format laid out in \nOverview\n, map the following:\n\n\n\n\nproject_id\n -> Application No.\n\n\nzipcode\n -> Building ZIP Code\n\n\nbaseline_period_end\n -> Work Start Date\n\n\nreporting_period_start -> Work Finish Date\n\n\n\n\n\n\n\n\nUpon completion you should have 4206 projects.\n\n\n15 Minute Electric Use Preparation\n\n\nThe following file is cleaned and formatted in this section:\n\n\n\n\nIDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv (15 minute electricity)\n\n\n\n\nIn this section we\u2019ll also begin building a dictionary of projects to traces. This will be added to by subsequent usage data preparation steps.\n\n\nPerform the following:\n\n\n\n\nAdjust the dates in the \nDATE\n column to \nyyyy-MM-dd\n format for sorting purposes.\n\n\nSort the file by \nDIR\n, then \nSPID\n, then \nDATE\n.\n\n\n\n\nRemove duplicate records.\n\n\n\n\nSince the file is now sorted, compare the previous row's \nDATE\n and \nSPID\n. If they are the same, check each of the interval columns. If all match, throw out one of the records. 566 duplicates should be removed this way across 163 unique SPIDs.\n\n\n\n\n\n\n\n\nFormat trace records.\n\n\n\n\ntrace_id\n -> \nelec-15min-[SA]-[SPID]-[DIR]\n\n\nIf \nDIR\n is \nD\n, the \ninterpretation\n is \nELECTRICITY_CONSUMPTION_SUPPLIED\n. If \nR\n, it is \nELECTRICITY_ON_SITE_GENERATION_UNCONSUMED\n.\n\n\nestimated\n -> False\n\n\nunit\n -> KWH\n\n\nFor \nstart\n, it is necessary to unroll each trace in the file into a separate line/record per interval column. i.e. \n00:15,00:30,00:45 ... 24:00\n become separate lines with start of \nDATE + 00:15, DATE + 00:30, etc.\n\n\nFor \nvalue\n, assign the value of the column in step 4.5.\n\n\nUsing the map created in electricity step 6 of \nCross Reference File Preparation\n, check the \nSPID\n to get a \nchar_prem_id\n. Check the \nchar_prem_id\n against the map you created in step 5 of \nProject File Preparation\n above. Using the project id (or \nApplication No.\n) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.\n\n\n\n\n\n\n\n\nThis step should yield 19,355,328 trace records and 400 traces.\n\n\nOptionally, between step 3 and 4 you could split the file into multiple CSVs to make the files easier to work with.\n\n\nHourly Electric Use Preparation\n\n\nThe following file is cleaned and formatted in this section:\n\n\n\n\nIDA.60MIN.SMY1.EES25162-EHUP.20160719161716.csv (hourly electricity)\n\n\n\n\nMany of the steps performed here match those in \n15 Minute Electric Use Preparation\n, so it is possible to reuse some of what you have done already if desired.\n\n\nPerform the following:\n\n\n\n\nAdjust the dates in the \nDATE\n column to \nyyyy-MM-dd\n format for sorting purposes.\n\n\nSort the file by \nDIR\n, then \nSPID\n, then \nDATE\n.\n\n\n\n\nRemove duplicate records.\n\n\n\n\nSince the file is now sorted, compare the previous row\u2019s \nDATE\n and \nSPID\n. If they are the same, check each of the interval columns. If all match, throw out one of the records.\n\n\n\n\n\n\n\n\nFormat trace records.\n\n\n\n\ntrace_id\n -> \nelec-hourly-[SA]-[SPID]-[DIR]\n\n\nIf \nDIR\n is \nD\n, the \ninterpretation\n is \nELECTRICITY_CONSUMPTION_SUPPLIED\n. If \nR\n, it is \nELECTRICITY_ON_SITE_GENERATION_UNCONSUMED\n.\n\n\nestimated\n -> False\n\n\nunit\n -> KWH\n\n\nFor \nstart\n, it is necessary to unroll each interval column into a separate line/record. i.e. \n01:00,02:00,03:00 ... 24:00\n become separate lines with \nstart\n of \nDATE + 01:00, DATE + 02:00\n, etc.\n\n\nFor \nvalue\n, assign the value of the column in step 4.5.\n\n\nUsing the map created in electricity step 6 of \nCross Reference File Preparation\n, check the \nSPID\n to get a \nchar_prem_id\n. Check the \nchar_prem_id\n against the map you created in step 5 of \nProject File Preparation\n above. Using the project id (or \nApplication No.\n) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.\n\n\n\n\n\n\n\n\nOptionally, between step 3 and 4 you could split the file into multiple CSVs to make the files easier to work with. This is advisable for this file in particular since it is quite large.\n\n\nThis step should yield 161,755,296 trace records and 8,778 traces.\n\n\nMonthly Electric Use Preparation\n\n\nThe following files are cleaned and formatted in this section:\n\n\n\n\nEES25162.ERESBL12 (1).XPT (monthly electricity 1 of 4)\n\n\nEES25162.ERESBL13.XPT (monthly electricity 2 of 4)\n\n\nEES25162.ERESBL15.XPT (monthly electricity 3 of 4)\n\n\nEES25162.ERESBL16.XPT (monthly electricity 4 of 4)\n\n\n\n\nThese files are in SAS XPORT format: http://support.sas.com/techsup/technote/ts140.pdf\nYour first step will be to convert these into CSV files to perform operations that, by now, are likely becoming familiar. The Python xport library (https://pypi.python.org/pypi/xport/) is one option for doing this conversion easily.\n\n\nFor each file in the list above, perform the following:\n\n\n\n\nConvert from XPORT to CSV format.\n\n\nSort the file by \nSA_ID\n.\n\n\n\n\nRemove duplicate records.\n\n\n\n\nWith the file sorted by \nSA_ID\n, you can simply check whether the previous \nSA_ID\n matches the current \nSA_ID\n. If it does, discard one of the records. There should be no duplicate records in this data.\n\n\n\n\n\n\n\n\nConvert the SAS dates.\n\n\n\n\nSAS dates are represented as a number of days since 1960-Jan-01.\n\n\nThe file has columns named \nCDT__1, CDT__2...  CDT__12\n for the months of the year (as well as \nKWH__1, KWH__2... KWH__12\n for the consumption values that correspond to those months). Each of the \nCDT__x\n dates needs to be converted.\n\n\n\n\n\n\n\n\nPad left with zeroes to 10 (zfill) the \nPREM_ID\n.\n\n\n\n\n\n\nFormat trace records.\n\n\n\n\ntrace_id\n -> \u201celec_monthly_\u201d + SA_ID \n\n\ninterpretation\n -> ELECTRICITY_CONSUMPTION_SUPPLIED\n\n\nFor \nstart\n, it is necessary to unroll each interval column into a separate line/record. i.e. the value in \nCDT__1, CDT__2\n (which should be a converted date value from step 4) should have its own record where it is the start.\n\n\nFor \nvalue\n, it is necessary to match the \nCDT\nx\n column in step 6.3 with a value column. i.e. \nCDT\n1\n matches the value column \nKWH__1\n. As previously stated, these belong on their own line/record.\n\n\nestimated\n -> False\n\n\nunit\n -> KWH\n\n\nCheck the \nPREM_ID\n against the map you created in step 5 of \nProject File Preparation\n above. Using the project id (or \nApplication No.\n) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.\n\n\n\n\n\n\n\n\nThis step should yield 164,129 trace records and 7,701 traces.\n\n\nDaily Gas Use Preparation\n\n\nThe following files are cleaned and formatted in this section:\n\n\n\n\nEES25162_gasdy_160720.csv (daily gas 1 of 2)\n\n\nEES25162_gasdy_160920.csv (daily gas 2 of 2)\n\n\n\n\nFor each file in the above list, perform the following steps:\n\n\n\n\nRemove the extraneous headers/first two lines of the file.\n\n\nConvert the dates in the \nMeasurement Date\n column to \nyyyy-MM-dd\n format for sorting purposes.\n\n\nSort by \nService Point\n, then by \nMeasurement Date\n.\n\n\n\n\nRemove duplicate records.\n\n\n\n\nSince the file is now sorted, if \nService Point\n and \nMeasurement Date\n match the previous row, discard one of the rows.\n\n\n\n\n\n\n\n\nFormat trace records.\n\n\n\n\ntrace_id\n -> Service Point\n\n\nstart\n -> Measurement Date\n\n\nvalue\n -> Therms per Day\n\n\ninterpretation\n -> NATURAL_GAS_CONSUMPTION_SUPPLIED\n\n\nunit\n -> THERM\n\n\nestimated\n -> False\n\n\nUsing the map created in electricity step 6 of \nCross Reference File Preparation\n, check the \nService Point\n to get a \nchar_prem_id\n. Check the \nchar_prem_id\n against the map you created in step 5 of \nProject File Preparation\n above. Using the project id (or \nApplication No.\n) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.\n\n\n\n\n\n\n\n\nOptionally, between step 4 and 5 you could split the file into multiple CSVs to make the files easier to work with.\n\n\nThis step should yield 6,892,834 trace records and 4,223 traces.\n\n\nMonthly Gas Use Preparation\n\n\nThe following files are cleaned and formatted in this section:\n\n\n\n\nEES25162.G2RSBL12.XPT (monthly gas 1 of 11)\n\n\nEES25162.G2RSBL13.XPT (monthly gas 2 of 11)\n\n\nEES25162.G2RSBL14.XPT (monthly gas 3 of 11)\n\n\nEES25162.G2RSBL15.XPT (monthly gas 4 of 11)\n\n\nEES25162.G2RSBL16.XPT (monthly gas 5 of 11)\n\n\nEES25162.GRESBL12.XPT (monthly gas 6 of 11)\n\n\nEES25162.GRESBL13.XPT (monthly gas 7 of 11)\n\n\nEES25162.GRESBL14.XPT (monthly gas 8 of 11)\n\n\nEES25162.GRESBL15.XPT (monthly gas 9 of 11)\n\n\nEES25162.GRESBL16.JANJUNE.XPT (monthly gas 10 of 11)\n\n\nEES25162.GRESBL16.XPT (monthly gas 11 of 11)\n\n\n\n\nThese files are in SAS XPORT format: http://support.sas.com/techsup/technote/ts140.pdf\nYour first step will be to convert these into CSV files to perform operations that, by now, are likely becoming familiar. The Python xport library (https://pypi.python.org/pypi/xport/) is one option for doing this conversion easily.\n\n\nFor each file in the list above, perform the following:\n\n\n\n\nConvert from XPORT to CSV format.\n\n\nSort the file by \nSA_ID\n, then by \nCDT__1\n.\n\n\n\n\nRemove duplicate records.\n\n\n\n\nSince the file is now sorted, if \nSA_ID\n and \nCDT__1\n match the previous record, one of them should be discarded.\n\n\n\n\n\n\n\n\nConvert the SAS dates.\n\n\n\n\nSAS dates are represented as a number of days since 1960-Jan-01.\n\n\nThe file has columns named \nCDT__1, CDT__2...  CDT__12\n for the months of the year (as well as \nTHM__1, THM__2... THM__12\n for the consumption values that correspond to those months). Each of the \nCDT__x\n dates needs to be converted.\n\n\n\n\n\n\n\n\nFormat trace records.\n\n\n\n\ntrace_id\n -> \u201cgas-monthly-\u201d + SA_ID\n\n\ninterpretation\n -> NATURAL_GAS_CONSUMPTION_SUPPLIED\n\n\nunit\n -> THERM\n\n\nestimated\n -> False\n\n\nFor \nstart\n, it is necessary to unroll each interval column into a separate line/record. i.e. the value in \nCDT__1, CDT__2\n (which should be a converted date value from step 4) should have its own record where it is the start.\n\n\nFor \nvalue\n, it is necessary to match the \nCDT\nx\n column in step 5.5 with a value column. i.e. \nCDT\n1\n matches the value column \nTHM__1\n. As previously stated, these belong on their own line/record.\n\n\nCheck the \nPREM_ID\n against the map you created in step 5 of \nProject File Preparation\n above. Using the project id (or \nApplication No.\n) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.\n\n\n\n\n\n\n\n\nThis step should yield 233,053 trace records and 6,893 traces.\n\n\nLinking Projects to Usage/Trace Data\n\n\nThroughout the process above you've been building a dictionary of projects to traces or outputting files with project to trace mappings as you go. If the former, simply spin through your dictionary and write a single record for each project-trace mapping in a 2 column CSV file with \nproject_id\n and \ntrace_id\n.",
            "title": "Data Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#data-preparation-for-caltrack-methods",
            "text": "CalTRACK employs the following processes when preparing weather, project, and daily/hourly/monthly consumption data for performing the analysis specified in the CalTRACK v1.0 methods.",
            "title": "Data Preparation for CalTRACK Methods"
        },
        {
            "location": "/data-prep/v1.0/README/#overview",
            "text": "Below are guidelines and a general process for addressing the most common issues that arise during data cleaning efforts for analysis. It is recommended to conduct these steps in the order they appear because the final combined dataset is highly sensitive to the order of data preparation steps.",
            "title": "Overview"
        },
        {
            "location": "/data-prep/v1.0/README/#guidelines-on-project-data-preparation",
            "text": "The minimum field requirements for project data under the CalTRACK daily specification are outlined  here . Notably, a prepared project file should consist of one row per project, with a unique ID that can be used to link to gas and/or electric usage data, project start and stop dates, and zip code for the site.  The following data cleaning steps for project data are meant to ensure that the prepared project file meets these field requirements and uniqueness constraints.",
            "title": "Guidelines on Project Data Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#creating-work-start-and-work-end-dates-from-raw-project-data",
            "text": "Accurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, considerable variation may occur in database records identifying dates associated with project start and project completion. In general, users should try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), it is recommended that users identify an average time to completion. CalTRACK implementations should use official work start date and work end date fields provided by aggregators rather than proxy fields when available.",
            "title": "Creating Work Start and Work End dates from raw project data"
        },
        {
            "location": "/data-prep/v1.0/README/#dealing-with-miscoded-dates",
            "text": "Implausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window. Implausible month and year values should be flagged and corrected or removed from the analysis.",
            "title": "Dealing with miscoded dates"
        },
        {
            "location": "/data-prep/v1.0/README/#deduplicate-project-records",
            "text": "If a building appears multiple times within a project database, and the project dates are the same, the most complete record for that building should be used. If a building appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.",
            "title": "Deduplicate project records"
        },
        {
            "location": "/data-prep/v1.0/README/#guidelines-on-weather-data-preparation",
            "text": "Weather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects\n* For California, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files. Clean versions of these files can be found  here .",
            "title": "Guidelines on Weather Data Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#guidelines-on-daily-electric-and-gas-usage-preparation",
            "text": "Generally, the quality of your consumption data may vary substantially from sample to sample. You will need to clean your data so that it meets the following requirements:   Traces are clearly marked for interval frequency (e.g., 15-minute, hour, day)  Traces are clearly marked for direction (reverse if net-metered and net solar production is higher than gross consumption).  Where available, the presence of net-metering is clearly marked (CalTRACK excludes homes that are net-metered)  Traces are not duplicated in whole or in part   The dataset generated for the CalTRACK beta test originated from a pool of projects and consumption data provided by PG&E (see  Data Sources ). A smaller set of 1000 natural gas meters and 1000 electricity meters were selected from this larger pool for the purposes of testing. These meters were selected based on location (attempting to maximize coverage over each of the climate zones) and data sufficiency (each meter contains at least two years of historical usage data prior to the intervention period).",
            "title": "Guidelines on Daily Electric and Gas Usage Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#roll-up-sub-daily-interval-data-to-daily-totals",
            "text": "If using sub-daily interval data (hourly, 15-minute, etc intervals), roll it up to daily totals following this procedure:  Check to make sure at least 50% of the intervals in the day have usage data.  For electricity, usage values of 0 should count as missing (for gas a usage value of 0 is valid and does not indicate missing data).  If more than 50% of the interval data is missing drop this day from the analysis.  Calculate total daily usage: multiply the average usage for all intervals in the day by the number of intervals (i.e. for hourly data, 24 * average hourly usage)",
            "title": "Roll up sub-daily interval data to daily totals"
        },
        {
            "location": "/data-prep/v1.0/README/#link-project-records-and-usage-files",
            "text": "Once project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. CalTRACK recommends using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, CalTRACK does not offer specific guidance.  Unmatched data should be excluded from analysis.",
            "title": "Link project records and usage files"
        },
        {
            "location": "/data-prep/v1.0/README/#deduplicate-records-based-on-combined-attributes",
            "text": "If two duplicate records have identical consumption traces and date ranges, drop one at random  If two duplicate records have identical consumption traces but different date ranges, prioritize the record that overlaps the baseline period in its entirety and encompasses a greater portion of the reporting period.   If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.  If the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.",
            "title": "Deduplicate records based on combined attributes"
        },
        {
            "location": "/data-prep/v1.0/README/#drop-records-not-meeting-data-sufficiency-requirements",
            "text": "12 months consumption data prior to the date of the intervention recommended for all projects.  Data is considered sufficient when it contains usage data for 90% of coverage period.  12 months consumption data after the date of the intervention is recommended for all projects.   Data is considered missing if it is clearly marked as NaN or similar by the data provider.  Consumption records marked as \u201cestimated\u201d are rare when parsing AMI data, but if any should appear they should be discarded.",
            "title": "Drop records not meeting data sufficiency requirements"
        },
        {
            "location": "/data-prep/v1.0/README/#drop-project-records-with-unsupported-characteristics",
            "text": "Drop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables.   Future efforts may provide the ability to access sub-meter data that may allow for backing out onsite generation and storage to arrive at savings.",
            "title": "Drop project records with unsupported characteristics"
        },
        {
            "location": "/data-prep/v1.0/README/#guidelines-for-monthly-electric-and-gas-usage-preparation",
            "text": "",
            "title": "Guidelines for Monthly Electric and Gas Usage Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#dealing-with-missing-values-in-monthly-usage-data",
            "text": "Usage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with \u201cestimated\u201d reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.   For the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the use per day for that period.  Missing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements.  CalTRACK does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.  If flags exist for estimated values, they are counted as missing and count against the site\u2019s data sufficiency criteria detailed later in this guidance.",
            "title": "Dealing with missing values in monthly usage data"
        },
        {
            "location": "/data-prep/v1.0/README/#dealing-with-extreme-values-in-usage-data",
            "text": "Occasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels) and should be handled based on the following guidance:   Negative values for monthly use should be treated as missing and count against sufficiency criterion. Negative values in monthly data may also be a valid sign of possible solar/net metering and should be flagged for verification.",
            "title": "Dealing with extreme values in usage data"
        },
        {
            "location": "/data-prep/v1.0/README/#deduplicate-records-based-on-combined-attributes_1",
            "text": "If two duplicate records have identical consumption traces and date ranges, drop one at random.  If two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.  If the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.",
            "title": "Deduplicate records based on combined attributes"
        },
        {
            "location": "/data-prep/v1.0/README/#drop-records-not-meeting-data-sufficiency-requirements_1",
            "text": "Calculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.   12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months.  Total annual savings estimates will require 12 months post-retrofit.",
            "title": "Drop records not meeting data sufficiency requirements"
        },
        {
            "location": "/data-prep/v1.0/README/#drop-project-records-with-unsupported-characteristics_1",
            "text": "Drop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. However, if you only have access to billing data, CalTRACK recommends working with the utility to get flags for accounts that have net metering present so they can be excluded from the analysis.  Future efforts may provide the ability to access sub-meter data that may allow for backing out onsite generation and storage to arrive at savings.",
            "title": "Drop project records with unsupported characteristics"
        },
        {
            "location": "/data-prep/v1.0/README/#guidelines-for-linking-project-and-usage-files",
            "text": "Once project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. CalTRACK recommends using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, CalTRACK does not offer specific guidance.  Unmatched data should be excluded from analysis.",
            "title": "Guidelines for Linking Project and Usage Files"
        },
        {
            "location": "/data-prep/v1.0/README/#guidelines-for-final-combined-data-sufficiency-checks",
            "text": "It is recommended that you run a final audit of your data to evaluate the outputs of the data cleaning process. You should be able to match the number of projects eliminated from your analysis at each step listed above. Your final audit will also serve as a useful reference for further data analysis and aggregation.   Billing periods (the period between bill start date and bill end date in the monthly usage data) with more than 10% missing days of weather data will be thrown out and count against the required number of billing period observations.  Any projects with fewer than 12 months pre and 12 months post are not included in the analysis.",
            "title": "Guidelines for Final Combined Data Sufficiency Checks"
        },
        {
            "location": "/data-prep/v1.0/README/#detailed-data-preparation-instructions",
            "text": "What follows in an example of data prep steps that could be used to create files for analysis. These steps are one example implementation of the guidelines laid out above.  Overall, 3 types of files are generated during this process for use in the CalTRACK methods:   Project data  Trace data  Project to Trace mappings   The Project Data file should have the following fields:   project_id : A unique identifier for the project (should occur once in the file).  zipcode : Used for linking weather data for the project.  baseline_period_end : Date the project started - usage data prior to this is used to establish a baseline.  reporting_period_start : Date the project ended. Usage after this is used to determine savings against the baseline.   Trace Data files should have the following fields:   trace_id : A unique identifier for the trace (can occur more than once in the file to identify individual trace records).  unit : Unit of measurement for the trace record (\u201cKWH\u201d or \u201cTHERM\u201d).  estimated : Whether this is an estimated reading (\u201cTrue\u201d or \u201cFalse\u201d).   interpretation : For purposes of this data, one of the following is always used:   ELECTRICITY_CONSUMPTION_SUPPLIED - Represents the amount of utility-supplied electrical energy consumed on-site, as metered at a single usage point, such as a utility-owned electricity meter. Specifically does not include consumption of electricity generated on site, such as by locally installed solar photovoltaic panels.  ELECTRICITY_ON_SITE_GENERATION_UNCONSUMED - Represents the amount of excess locally generated energy, which instead of being consumed on-site, is fed back into the grid or sold back a utility.  NATURAL_GAS_CONSUMPTION_SUPPLIED - Represents the amount of energy supplied by a utility in the form of natural gas and used on site, as metered at a single usage point.     start : Starting date time for the trace record.   value : Value of the trace record (i.e. number of KWH/THERM)   Project to Trace mapping files contain just two fields:   project_id  trace_id   A fourth type of file containing weather data is also used, but is not generated by the data prep process - weather data is described in greater detail in the  Link weather data and project records  section below.  The CalTRACK data preparations guidelines for daily analysis consist of the following steps:   Cross Reference File Preparation  Project Data Preparation  15 Minute Electric Use Preparation  Hourly Electric Use Preparation  Monthly Electric Use Preparation  Daily Gas Use Preparation  Monthly Gas Use Preparation  Linking Projects to Usage/Trace Data",
            "title": "Detailed Data Preparation Instructions"
        },
        {
            "location": "/data-prep/v1.0/README/#file-list",
            "text": "Cross Reference Files   EES25162_ELECINTV_XREF_CPUC.csv (Electricity Cross Reference)  EES25162_GASINTV_XREF_CPUC.csv (Gas Cross Reference 1 of 2)  EES25162_GASINTV2_XREF_CPUC.csv (Gas Cross Reference 2 of 2)   Project Files   CalTrack (AHU) from 1_1_14__6_30_15_v2_FINAL_090816.csv  CalTrack (AHU) from 7_1_15__6_30_16_v2_FINAL_090816.csv  CalTrack (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv   Usage Files   IDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv (15 minute electricity)  EES25162_gasdy_160720.csv (daily gas 1 of 2)  EES25162_gasdy_160920.csv (daily gas 2 of 2)  IDA.60MIN.SMY1.EES25162-EHUP.20160719161716.csv (hourly electricity)  EES25162.ERESBL12 (1).XPT (monthly electricity 1 of 4)  EES25162.ERESBL13.XPT (monthly electricity 2 of 4)  EES25162.ERESBL15.XPT (monthly electricity 3 of 4)  EES25162.ERESBL16.XPT (monthly electricity 4 of 4)  EES25162.G2RSBL12.XPT (monthly gas 1 of 11)  EES25162.G2RSBL13.XPT (monthly gas 2 of 11)  EES25162.G2RSBL14.XPT (monthly gas 3 of 11)  EES25162.G2RSBL15.XPT (monthly gas 4 of 11)  EES25162.G2RSBL16.XPT (monthly gas 5 of 11)  EES25162.GRESBL12.XPT (monthly gas 6 of 11)  EES25162.GRESBL13.XPT (monthly gas 7 of 11)  EES25162.GRESBL14.XPT (monthly gas 8 of 11)  EES25162.GRESBL15.XPT (monthly gas 9 of 11)  EES25162.GRESBL16.JANJUNE.XPT (monthly gas 10 of 11)  EES25162.GRESBL16.XPT (monthly gas 11 of 11)",
            "title": "File List"
        },
        {
            "location": "/data-prep/v1.0/README/#cross-reference-file-preparation",
            "text": "A series of cross reference files are provided that can be used to link projects to usage information. These are:   EES25162_ELECINTV_XREF_CPUC.csv (Electricity Cross Reference)  EES25162_GASINTV_XREF_CPUC.csv (Gas Cross Reference 1 of 2)  EES25162_GASINTV2_XREF_CPUC.csv (Gas Cross Reference 2 of 2)   It is recommended that cross reference (or \u201cxref\u201d) files be prepared first since they contain information that will be useful in formatting the project and usage data in later steps.  Also required for this cleaning step will be the following:   IDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv (15 minute electricity)  IDA.60MIN.SMY1.EES25162-EHUP.20160719161716.csv (hourly electricity)   With the electricity cross reference file, perform the following:    Obtain all net metered Service Account Ids from the 15 minute file electricity file.   In the 15 minute and hourly electricity data, any record where  DIR  is  R  is net metered.     Obtain all net metered SA ids from the hourly electricity file, combine with those found in step 1.   Left pad with zeroes (or zfill) to 10 all  char_prem_id s.  Using the Electricity Cross Reference file, build a map of  sa_id  to  char_prem_id .   Using a combination of the Electricity Cross Reference file, the net metered SA id set from steps 1 and 2, and the map from 4, add the  is_net_metered  column to the Electricity Cross Reference file.   Any row in the file that has  net_mtr_ind  set to  Y  is net metered  Any row that has an  sa_id  in the set from steps 1 and 2 is net metered     Build a map of  sa_id  to  char_prem_id .   Build a map of  sp_id  to  char_prem_id .   Your Electricity Cross Reference file now has what is needed. In future steps, the map from step 5 will be used to help map projects, and any project that is net metered should be excluded from analysis.  Upon completion, your finalized Electricity Cross Reference file should contain 8004 records (not including header).  With the gas cross reference file, perform the following:   Combine the two files into a single CSV.  Left pad with zeroes (or zfill) the  char_prem_id s.  Build a map of  sa_id  to  char_prem_id .  Build a map of  sp_id  to  char_prem_id .   You now have a single Gas Cross Reference file. In future steps, the map from step 3 will be used to help map projects, while the map in step 4 will be used to help map traces.  Upon completion, your finalized Gas Cross Reference file should contain 6928 records (not including header).",
            "title": "Cross Reference File preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#project-data-preparation",
            "text": "In the beta test data, the following files were provided containing project information:   CalTrack (AHU) from 1_1_14__6_30_15_v2_FINAL_090816.csv  CalTrack (AHU) from 7_1_15__6_30_16_v2_FINAL_090816.csv  CalTrack (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv   You\u2019ll also be using the  sa_id  to  char_prem_id  maps you created from the Electric and Gas Cross Reference Files in the  Cross Reference File Preparation  section above.  Perform the following:    Combine the 3 project files into a single file.   The  CalTrack (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv  file has a column called  Application: Application No.  instead of simply  Application No.  like the other two files - the column should be treated the same when combining the files.     Estimate project dates using the combined file - each project should have a  Work Start Date  and a  Work Finish Date .    For each row, check if the  Notice to Proceed Issued  column is blank.   If it is, this is a project from one of the AHU files. Set the  Work Start Date  to the  Initial Approval Date  and the  Work Finish Date  to the  Initial Submission Date .   If it is not, this is a project from the AHUP file. Set the  Work Start Date  to the  Notice to Proceed Issued .   If the  Full Application Returned  field is blank, set the  Work Finish Date  to  Full Application Submitted .  Otherwise set  Work Finish Date  to  Full Application Started .       If after completing step 2a above your  Work Finish Date  is still blank and your  Work Start Date  is not, set the  Work Finish Date  to 60 days after the  Work Start Date .      Using the  sa_id  to  char_prem_id  maps you saved from  Cross Reference File Preparation , add a  char_prem_id  column to your combined project file.   For each row, check  Electric Service ID  against the  sa_id  in your electric map.  For each row, check  Gas Service ID  against the  sa_id  in your gas map.     Merge duplicate projects into one project.   There should only be one project per  char_prem_id . Build a dictionary with  char_prem_id  as the key and a list of projects as the value.   If there is more than one project for a  char_prem_id , merge the projects.   Set  Work Start Date  to the earliest available.  Set  Work Finish Date  to the latest available.       Build a map of  char_prem_id  to  Application No.  for later use in mapping projects to traces.    Translate the file into the format required. If using the format laid out in  Overview , map the following:   project_id  -> Application No.  zipcode  -> Building ZIP Code  baseline_period_end  -> Work Start Date  reporting_period_start -> Work Finish Date     Upon completion you should have 4206 projects.",
            "title": "Project data preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#15-minute-electric-use-preparation",
            "text": "The following file is cleaned and formatted in this section:   IDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv (15 minute electricity)   In this section we\u2019ll also begin building a dictionary of projects to traces. This will be added to by subsequent usage data preparation steps.  Perform the following:   Adjust the dates in the  DATE  column to  yyyy-MM-dd  format for sorting purposes.  Sort the file by  DIR , then  SPID , then  DATE .   Remove duplicate records.   Since the file is now sorted, compare the previous row's  DATE  and  SPID . If they are the same, check each of the interval columns. If all match, throw out one of the records. 566 duplicates should be removed this way across 163 unique SPIDs.     Format trace records.   trace_id  ->  elec-15min-[SA]-[SPID]-[DIR]  If  DIR  is  D , the  interpretation  is  ELECTRICITY_CONSUMPTION_SUPPLIED . If  R , it is  ELECTRICITY_ON_SITE_GENERATION_UNCONSUMED .  estimated  -> False  unit  -> KWH  For  start , it is necessary to unroll each trace in the file into a separate line/record per interval column. i.e.  00:15,00:30,00:45 ... 24:00  become separate lines with start of  DATE + 00:15, DATE + 00:30, etc.  For  value , assign the value of the column in step 4.5.  Using the map created in electricity step 6 of  Cross Reference File Preparation , check the  SPID  to get a  char_prem_id . Check the  char_prem_id  against the map you created in step 5 of  Project File Preparation  above. Using the project id (or  Application No. ) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.     This step should yield 19,355,328 trace records and 400 traces.  Optionally, between step 3 and 4 you could split the file into multiple CSVs to make the files easier to work with.",
            "title": "15 Minute Electric Use Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#hourly-electric-use-preparation",
            "text": "The following file is cleaned and formatted in this section:   IDA.60MIN.SMY1.EES25162-EHUP.20160719161716.csv (hourly electricity)   Many of the steps performed here match those in  15 Minute Electric Use Preparation , so it is possible to reuse some of what you have done already if desired.  Perform the following:   Adjust the dates in the  DATE  column to  yyyy-MM-dd  format for sorting purposes.  Sort the file by  DIR , then  SPID , then  DATE .   Remove duplicate records.   Since the file is now sorted, compare the previous row\u2019s  DATE  and  SPID . If they are the same, check each of the interval columns. If all match, throw out one of the records.     Format trace records.   trace_id  ->  elec-hourly-[SA]-[SPID]-[DIR]  If  DIR  is  D , the  interpretation  is  ELECTRICITY_CONSUMPTION_SUPPLIED . If  R , it is  ELECTRICITY_ON_SITE_GENERATION_UNCONSUMED .  estimated  -> False  unit  -> KWH  For  start , it is necessary to unroll each interval column into a separate line/record. i.e.  01:00,02:00,03:00 ... 24:00  become separate lines with  start  of  DATE + 01:00, DATE + 02:00 , etc.  For  value , assign the value of the column in step 4.5.  Using the map created in electricity step 6 of  Cross Reference File Preparation , check the  SPID  to get a  char_prem_id . Check the  char_prem_id  against the map you created in step 5 of  Project File Preparation  above. Using the project id (or  Application No. ) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.     Optionally, between step 3 and 4 you could split the file into multiple CSVs to make the files easier to work with. This is advisable for this file in particular since it is quite large.  This step should yield 161,755,296 trace records and 8,778 traces.",
            "title": "Hourly Electric Use Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#monthly-electric-use-preparation",
            "text": "The following files are cleaned and formatted in this section:   EES25162.ERESBL12 (1).XPT (monthly electricity 1 of 4)  EES25162.ERESBL13.XPT (monthly electricity 2 of 4)  EES25162.ERESBL15.XPT (monthly electricity 3 of 4)  EES25162.ERESBL16.XPT (monthly electricity 4 of 4)   These files are in SAS XPORT format: http://support.sas.com/techsup/technote/ts140.pdf\nYour first step will be to convert these into CSV files to perform operations that, by now, are likely becoming familiar. The Python xport library (https://pypi.python.org/pypi/xport/) is one option for doing this conversion easily.  For each file in the list above, perform the following:   Convert from XPORT to CSV format.  Sort the file by  SA_ID .   Remove duplicate records.   With the file sorted by  SA_ID , you can simply check whether the previous  SA_ID  matches the current  SA_ID . If it does, discard one of the records. There should be no duplicate records in this data.     Convert the SAS dates.   SAS dates are represented as a number of days since 1960-Jan-01.  The file has columns named  CDT__1, CDT__2...  CDT__12  for the months of the year (as well as  KWH__1, KWH__2... KWH__12  for the consumption values that correspond to those months). Each of the  CDT__x  dates needs to be converted.     Pad left with zeroes to 10 (zfill) the  PREM_ID .    Format trace records.   trace_id  -> \u201celec_monthly_\u201d + SA_ID   interpretation  -> ELECTRICITY_CONSUMPTION_SUPPLIED  For  start , it is necessary to unroll each interval column into a separate line/record. i.e. the value in  CDT__1, CDT__2  (which should be a converted date value from step 4) should have its own record where it is the start.  For  value , it is necessary to match the  CDT x  column in step 6.3 with a value column. i.e.  CDT 1  matches the value column  KWH__1 . As previously stated, these belong on their own line/record.  estimated  -> False  unit  -> KWH  Check the  PREM_ID  against the map you created in step 5 of  Project File Preparation  above. Using the project id (or  Application No. ) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.     This step should yield 164,129 trace records and 7,701 traces.",
            "title": "Monthly Electric Use Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#daily-gas-use-preparation",
            "text": "The following files are cleaned and formatted in this section:   EES25162_gasdy_160720.csv (daily gas 1 of 2)  EES25162_gasdy_160920.csv (daily gas 2 of 2)   For each file in the above list, perform the following steps:   Remove the extraneous headers/first two lines of the file.  Convert the dates in the  Measurement Date  column to  yyyy-MM-dd  format for sorting purposes.  Sort by  Service Point , then by  Measurement Date .   Remove duplicate records.   Since the file is now sorted, if  Service Point  and  Measurement Date  match the previous row, discard one of the rows.     Format trace records.   trace_id  -> Service Point  start  -> Measurement Date  value  -> Therms per Day  interpretation  -> NATURAL_GAS_CONSUMPTION_SUPPLIED  unit  -> THERM  estimated  -> False  Using the map created in electricity step 6 of  Cross Reference File Preparation , check the  Service Point  to get a  char_prem_id . Check the  char_prem_id  against the map you created in step 5 of  Project File Preparation  above. Using the project id (or  Application No. ) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.     Optionally, between step 4 and 5 you could split the file into multiple CSVs to make the files easier to work with.  This step should yield 6,892,834 trace records and 4,223 traces.",
            "title": "Daily Gas Use Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#monthly-gas-use-preparation",
            "text": "The following files are cleaned and formatted in this section:   EES25162.G2RSBL12.XPT (monthly gas 1 of 11)  EES25162.G2RSBL13.XPT (monthly gas 2 of 11)  EES25162.G2RSBL14.XPT (monthly gas 3 of 11)  EES25162.G2RSBL15.XPT (monthly gas 4 of 11)  EES25162.G2RSBL16.XPT (monthly gas 5 of 11)  EES25162.GRESBL12.XPT (monthly gas 6 of 11)  EES25162.GRESBL13.XPT (monthly gas 7 of 11)  EES25162.GRESBL14.XPT (monthly gas 8 of 11)  EES25162.GRESBL15.XPT (monthly gas 9 of 11)  EES25162.GRESBL16.JANJUNE.XPT (monthly gas 10 of 11)  EES25162.GRESBL16.XPT (monthly gas 11 of 11)   These files are in SAS XPORT format: http://support.sas.com/techsup/technote/ts140.pdf\nYour first step will be to convert these into CSV files to perform operations that, by now, are likely becoming familiar. The Python xport library (https://pypi.python.org/pypi/xport/) is one option for doing this conversion easily.  For each file in the list above, perform the following:   Convert from XPORT to CSV format.  Sort the file by  SA_ID , then by  CDT__1 .   Remove duplicate records.   Since the file is now sorted, if  SA_ID  and  CDT__1  match the previous record, one of them should be discarded.     Convert the SAS dates.   SAS dates are represented as a number of days since 1960-Jan-01.  The file has columns named  CDT__1, CDT__2...  CDT__12  for the months of the year (as well as  THM__1, THM__2... THM__12  for the consumption values that correspond to those months). Each of the  CDT__x  dates needs to be converted.     Format trace records.   trace_id  -> \u201cgas-monthly-\u201d + SA_ID  interpretation  -> NATURAL_GAS_CONSUMPTION_SUPPLIED  unit  -> THERM  estimated  -> False  For  start , it is necessary to unroll each interval column into a separate line/record. i.e. the value in  CDT__1, CDT__2  (which should be a converted date value from step 4) should have its own record where it is the start.  For  value , it is necessary to match the  CDT x  column in step 5.5 with a value column. i.e.  CDT 1  matches the value column  THM__1 . As previously stated, these belong on their own line/record.  Check the  PREM_ID  against the map you created in step 5 of  Project File Preparation  above. Using the project id (or  Application No. ) as the dictionary key with a list as the value, add the trace id from step a above to that list. You\u2019ll be continuing to build this as you perform additional steps.     This step should yield 233,053 trace records and 6,893 traces.",
            "title": "Monthly Gas Use Preparation"
        },
        {
            "location": "/data-prep/v1.0/README/#linking-projects-to-usagetrace-data",
            "text": "Throughout the process above you've been building a dictionary of projects to traces or outputting files with project to trace mappings as you go. If the former, simply spin through your dictionary and write a single record for each project-trace mapping in a 2 column CSV file with  project_id  and  trace_id .",
            "title": "Linking Projects to Usage/Trace Data"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/",
            "text": "CalTRACK Site-level Monthly Weather Normalized, Metered Energy Savings Estimation Technical Guideline\n\n\n\n\nMethodological Overview\n\n\nSite-level weather normalized, metered energy savings using monthly billing data (both electricity and gas) will use a two-stage estimation approach that closely follows methodological recommendations in the technical appendices of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, with some modifications and more specific guidance developed through empirical testing to ensure consistency and replicability of results.\n\n\nThe idea behind two-stage site-level models is to model the energy use of each house before and after an energy efficiency retrofit.\n\n\nMore formally, the two-stage approach first fits \ntwo\n separate parametric models to daily average energy use, one on the pre-intervention (baseline) period and one on the post-intervention (reporting) period for a single site using an ordinary least squares regression of the general form:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\beta_{Ci}CDD_m + \\epsilon_{mi}\n\n\n\n\nWhere\n\n\n\n\nUPD_{mi}\n is average use (gas in therms, electricity in kWh) per day during billing period m for site i.\n\n\n\n\n\\mu_i\n is the mean use for site \ni\n, or intercept.\n\n\n\n\n\\beta_{Hi}\n is the coefficient site \ni\n on average heating degree days per day.\n\n\n\n\n\\beta_{Ci}\n is the coefficient or site \ni\n on average cooling degree days per day.\n\n\n\n\nHDD_m\n is the average number of heating degree days per day in billing period \nm\n, which is a function of a fixed base temperature, the average daily temperatures from the weather station matched to site \ni\n during the billing period \nm\n, and the number of days in billing period \nm\n with matched usage and weather data for site \ni\n.\n\n\n\n\nCDD_m\n is the average number of cooling degree days per day in month \nm\n, which is a function of a selected base temperature, the average daily temperatures from the weather station matched to site \ni\n during month \nm\n, and the number of days in month \nm\n with matched usage and weather data for site \ni\n.\n\n\n\n\n\\epsilon_{mi}\n is the site specific error term for a given month.\n\n\nIn the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized metered energy savings), or by using current-year weather to project forward baseline period use (current year weather normalized metered energy savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.\n\n\nThis site-level two-stage approach without the use of a comparison group was decided by the technical working group to be appropriate for the two main use cases for CalTRACK, which emphasize effects on the grid and feedback to software vendors, rather than causal programatic effects. In addition to its long history of use in the EM&V literature, it draws on a methodological foundation developed in the more general literature on piecewise linear regression or segmented regression for policy analysis and effect estimates that is used in fields as diverse as public health, medical research, and econometrics.\n\n\nWe now proceed with a detailed technical treatment of the steps for monthly savings estimation.\n\n\nTechnical guidelines for implementing two-stage estimation on monthly electric and gas usage data for CalTRACK\n\n\nCalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Cleaning and Integration technical specification. Starting with the prepared data, site-level monthly weather normalized metered energy savings analysis is performed by implementing the following steps:\n\n\n1. Generate Use Per Day values and separate usage data into a pre- and a post-intervention data series\n\n\nThe CalTRACK monthly weather normalized metered energy savings analysis uses average use per day (\nUPD\n) values for each month by taking the bill-period usage values, then dividing by the number of days in that bill period, as follows:\n\n\n\n\nUPD_m = \\frac{1}{n_{U_d}} * \\sum{U_d}\n\n\n\n\nWhere\n\n\n\n\nUPD_m\n is the average use per day for a given month \nm\n\n\n\n\n\n\n\\sum{U_d}\n is the sum of all daily use values \nU_d\n for a given month \nm\n\n\n\n\n\n\nn_{U_d}\n is the total number of daily use values provided in the usage series that are between the first calendar day of month \nm\n and the last calendar day of month \nm\n\n\n\n\nNote: If daily use data for gas or electric is not available, monthly billing data can be used for the monthly billing analysis. However, modifications of the denominators for average use per day and for average HDD and CDD per day are necessary.\n\n\nNow split the series of \nUPD_m\n values into pre- and post-intervention periods according to the following rules:\n\n\nPre-intervention period\n: all UPDm values from the beginning of the series up to the the complete billing month prior to the \nwork_start_date\n. The month containing \nwork_start_date\n is excluded from this series.\n\n\nPost-intervention period\n: all UPDm values from the first billing month after the \nwork_end_date\n to the end of the series.\n\n\nFinal data sufficiency qualification check\n: All qualifying sites must have at least 12 months of contiguous UPDm values in the pre-intervention series and at least 12 months of contiguous post-intervention UPDm values starting with the month after \nwork_end_date\n.\n\n\nAll sites not meeting these minimum data requirements are thrown out of the analysis\n\n\n2. Set fixed degree day base temperature and calculated HDD and CDD\n\n\nNext you calculate total HDD and CDD for the each billing period in the series. CalTRACK will use a fixed degree day base for monthly billing analysis. The following balance point temperatures will be use:\n\n\nHDD base temp: 60 F\n\n\nCDD base temp: 70 F\n\n\nHDD and CDD values are calculated as follows\n\n\n\n\nHDD_m = \\frac{1}{n_{Ud}} * \\sum{\\max(60 - \\bar{T}, 0)}\n\n\n\n\nWhere\n\n\n\n\nHDD_m\n = Average heating degree days per day for billing period \nm\n\n\n\n\n\n\nn_{U_d}\n = the number of days with both weather and usage data\n\n\n\n\n\\sum{}\n = the sum of the degree  over each day \nd\n in billing period \nm\n\n\n\n\n\n\n\\max{}\n = the maximum of the two values in ()\n\n\n\n\n\\bar{T}\n = the average temperature for day \nd\n\n\n\n\nAnd\n\n\n\n\n CDD_m = \\frac{1}{n_{Ud}} * \\sum{\\max(\\bar{T_d} - 70, 0)}\n\n\n\n\nWhere\n\n\n\n\nCDD_m\n = Cooling degree days for billing period \nm\n\n\n\n\n\n\nn_{Ud}\n = the number of days with both weather and usage data\n\n\n\n\n\\sum{}\n = the sum of values in {} over each day \nd\n in billing period \nm\n\n\n\n\n\n\n\\max{}\n = the maximum of the two values in ()\n\n\n\n\n\\bar{T_d}\n = the average temperature for day \nd\n\n\n\n\nDaily average temperatures are taken from the GSOD average data temperature dataset provided by NOAA\n\n\n3. Fit All Candidate Models and Apply Qualification Criteria\n\n\nFor each site, all allowable models will be run as candidate models and then have minimum fitness criteria set for qualification.\n\n\nFor CalTRACK electric monthly savings analysis, the following candidate models are fit:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\beta_{Ci}CDD_m +  \\epsilon_{mi}\n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\epsilon_{mi}\n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Ci}CDD_m+ \\epsilon_{mi}\n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\epsilon_{mi}\n\n\n\n\nwith the constraints\n\n\n\n\n\\beta_H > 0\n\n\n\n\n\n\n\\beta_C > 0\n\n\n\n\n\n\n\\mu_i > 0\n\n\n\n\nFor electric, qualifying models for selection must have each parameter estimate meet the minimum significance criteria of p < 0.1 and are strictly positive. All qualifying models are considered for final model selection.\n\n\nFor CalTRACK gas monthly savings analysis, the following candidate models are fit:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\epsilon_{mi}\n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Ci}CDD_m+ \\epsilon_{mi}\n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\epsilon_{mi}\n\n\n\n\nwith the constraints\n\n\n\n\n\\beta_H > 0\n\n\n\n\n\n\n\\mu_i > 0\n\n\n\n\nIf each parameter estimate meets minimum significance criteria \n(p < 0.1)\n and are strictly positive, then the model is a qualifying model for inclusion in model selection.\n\n\n4. Select the best for pre-intervenion and post-intervention periods for use in second-stage savings estimation\n\n\nAll qualifying pre-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.\n\n\nFor the monthly billing analysis, because we are using fixed degree days instead of variable degree days, adjusted R-squared will be defined as\n\n\n\n\nR^2_{adj} = 1 - \\frac{(SS_{res}/df_e)}{(SS_{tot}/df_t)}\n\n\n\n\nWhere\n\n\n\n\nSS_{res}\n is the sum of squares of residuals\n\n\n\n\ndf_e\n is the degrees of freedom of the estimate of the underlying population error variance, and is calculated using \nn-p-1\n, where \nn\n is the number of observations in the sample used to estimate the model and \np\n is the number of explanatory variables, not including the constant term and not including degree day base temperature as a parameter because it\u2019s fixed\n\n\n\n\nSS_{tot}\n is the total sum of squares\n\n\n\n\ndf_t\n is the degrees of freedom of the estimate of the population variance of the dependent variable, and is calculated as \nn-1\n, were \nn\n is the size of the sample use to estimate the model\n\n\nAll qualifying post-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.\n\n\n5. Estimate second-stage weather normalized metered energy savings quantities based on selected first stage pre- and post-intervention models\n\n\nDuring the second stage, up to five savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.\n\n\nCumulative weather normalized metered energy savings over entire performance period\nYear one annualized actual weather normalized metered energy savings in the the reporting (post-intervention) period\nYear two annualized actual weather normalized metered energy savings in the the reporting (post-intervention) period\nYear one annualized weather normalized metered energy savings in the normal year\nYear two annualized weather normalized metered energy savings in the normal year\n\n\nThese site-level second stage quantities are calculated as follows:\n\n\nCumulative weather normalized metered energy savings over entire performance period (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period after \nwork_end_date\n using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for every complete billing periods after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over every complete billing period since \nwork_end_date\n.\n\n\n\n\nYear one weather normalized metered energy savings from 1 to 12 months after site visit. (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period after \nwork_end_date\n until 12 billing periods after \nwork_end_date\n  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for 12 complete billing periods after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over the 12 billing periods since \nwork_end_date\n.\n\n\n\n\nYear two weather normalized metered energy savings from 13 to 24 months after site visit. (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period starting 13 months after \nwork_end_date\n until 24 billing periods after \nwork_end_date\n  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for month 13 to month 24 after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over the 12 billing periods from 13 months after \nwork_end_date\n to 24 months.\n\n\n\n\nYear one site-level annualized weather normalized metered energy savings in the normal year\n\n\n\n\nCompute \npredicted_baseline_monthly_use\n using the stage one model from the baseline period and average degree days from the CZ2010 normal weather year. Use the full month of available values when calculating the average degree days per billing period for the normal year.\n\n\nCompute \npredicted_reporting_monthly_use\n using a \nstage one\n model fit to only the first 12 months of post-intervention values and degree days from the CZ2010 normal weather year file. Use the full month of available values when calculating the average degree days per billing period for the normal year.\n\n\nCompute \nmonthly_normal_year_gross_savings\n = \npredicted_baseline_monthly_use - predicted_reporting_monthly_use\n for normal year months\n\n\nSum  \nmonthly_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nYear two site-level annualized weather normalized metered energy savings in the normal year\n\n\n\n\nCompute \npredicted_baseline_monthly_use\n using the stage one model from the baseline period and degree days from the CZ2010 normal weather year.\n\n\nCompute \npredicted_reporting_monthly_use\n using a \nstage one\n model fit to only the 13th-24th months of post-intervention values and degree days from the CZ2010 normal weather year file for the relevant months.\n\n\nCompute \nmonthly_normal_year_gross_savings\n = \npredicted_baseline_monthly_use - predicted_reporting_monthly_use\n for each normal year month.\n\n\nSum  \nmonthly_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nPost-estimation steps and portfolio aggregation\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over \nportfolios of homes\n. In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified \nhere\n.",
            "title": "Analysis of Monthly Data"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#caltrack-site-level-monthly-weather-normalized-metered-energy-savings-estimation-technical-guideline",
            "text": "",
            "title": "CalTRACK Site-level Monthly Weather Normalized, Metered Energy Savings Estimation Technical Guideline"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#methodological-overview",
            "text": "Site-level weather normalized, metered energy savings using monthly billing data (both electricity and gas) will use a two-stage estimation approach that closely follows methodological recommendations in the technical appendices of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, with some modifications and more specific guidance developed through empirical testing to ensure consistency and replicability of results.  The idea behind two-stage site-level models is to model the energy use of each house before and after an energy efficiency retrofit.  More formally, the two-stage approach first fits  two  separate parametric models to daily average energy use, one on the pre-intervention (baseline) period and one on the post-intervention (reporting) period for a single site using an ordinary least squares regression of the general form:   UPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\beta_{Ci}CDD_m + \\epsilon_{mi}   Where   UPD_{mi}  is average use (gas in therms, electricity in kWh) per day during billing period m for site i.   \\mu_i  is the mean use for site  i , or intercept.   \\beta_{Hi}  is the coefficient site  i  on average heating degree days per day.   \\beta_{Ci}  is the coefficient or site  i  on average cooling degree days per day.   HDD_m  is the average number of heating degree days per day in billing period  m , which is a function of a fixed base temperature, the average daily temperatures from the weather station matched to site  i  during the billing period  m , and the number of days in billing period  m  with matched usage and weather data for site  i .   CDD_m  is the average number of cooling degree days per day in month  m , which is a function of a selected base temperature, the average daily temperatures from the weather station matched to site  i  during month  m , and the number of days in month  m  with matched usage and weather data for site  i .   \\epsilon_{mi}  is the site specific error term for a given month.  In the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized metered energy savings), or by using current-year weather to project forward baseline period use (current year weather normalized metered energy savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.  This site-level two-stage approach without the use of a comparison group was decided by the technical working group to be appropriate for the two main use cases for CalTRACK, which emphasize effects on the grid and feedback to software vendors, rather than causal programatic effects. In addition to its long history of use in the EM&V literature, it draws on a methodological foundation developed in the more general literature on piecewise linear regression or segmented regression for policy analysis and effect estimates that is used in fields as diverse as public health, medical research, and econometrics.  We now proceed with a detailed technical treatment of the steps for monthly savings estimation.",
            "title": "Methodological Overview"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#technical-guidelines-for-implementing-two-stage-estimation-on-monthly-electric-and-gas-usage-data-for-caltrack",
            "text": "CalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Cleaning and Integration technical specification. Starting with the prepared data, site-level monthly weather normalized metered energy savings analysis is performed by implementing the following steps:",
            "title": "Technical guidelines for implementing two-stage estimation on monthly electric and gas usage data for CalTRACK"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#1-generate-use-per-day-values-and-separate-usage-data-into-a-pre-and-a-post-intervention-data-series",
            "text": "The CalTRACK monthly weather normalized metered energy savings analysis uses average use per day ( UPD ) values for each month by taking the bill-period usage values, then dividing by the number of days in that bill period, as follows:   UPD_m = \\frac{1}{n_{U_d}} * \\sum{U_d}   Where   UPD_m  is the average use per day for a given month  m    \\sum{U_d}  is the sum of all daily use values  U_d  for a given month  m    n_{U_d}  is the total number of daily use values provided in the usage series that are between the first calendar day of month  m  and the last calendar day of month  m   Note: If daily use data for gas or electric is not available, monthly billing data can be used for the monthly billing analysis. However, modifications of the denominators for average use per day and for average HDD and CDD per day are necessary.  Now split the series of  UPD_m  values into pre- and post-intervention periods according to the following rules:  Pre-intervention period : all UPDm values from the beginning of the series up to the the complete billing month prior to the  work_start_date . The month containing  work_start_date  is excluded from this series.  Post-intervention period : all UPDm values from the first billing month after the  work_end_date  to the end of the series.  Final data sufficiency qualification check : All qualifying sites must have at least 12 months of contiguous UPDm values in the pre-intervention series and at least 12 months of contiguous post-intervention UPDm values starting with the month after  work_end_date .  All sites not meeting these minimum data requirements are thrown out of the analysis",
            "title": "1. Generate Use Per Day values and separate usage data into a pre- and a post-intervention data series"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#2-set-fixed-degree-day-base-temperature-and-calculated-hdd-and-cdd",
            "text": "Next you calculate total HDD and CDD for the each billing period in the series. CalTRACK will use a fixed degree day base for monthly billing analysis. The following balance point temperatures will be use:  HDD base temp: 60 F  CDD base temp: 70 F  HDD and CDD values are calculated as follows   HDD_m = \\frac{1}{n_{Ud}} * \\sum{\\max(60 - \\bar{T}, 0)}   Where   HDD_m  = Average heating degree days per day for billing period  m    n_{U_d}  = the number of days with both weather and usage data   \\sum{}  = the sum of the degree  over each day  d  in billing period  m    \\max{}  = the maximum of the two values in ()   \\bar{T}  = the average temperature for day  d   And    CDD_m = \\frac{1}{n_{Ud}} * \\sum{\\max(\\bar{T_d} - 70, 0)}   Where   CDD_m  = Cooling degree days for billing period  m    n_{Ud}  = the number of days with both weather and usage data   \\sum{}  = the sum of values in {} over each day  d  in billing period  m    \\max{}  = the maximum of the two values in ()   \\bar{T_d}  = the average temperature for day  d   Daily average temperatures are taken from the GSOD average data temperature dataset provided by NOAA",
            "title": "2. Set fixed degree day base temperature and calculated HDD and CDD"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#3-fit-all-candidate-models-and-apply-qualification-criteria",
            "text": "For each site, all allowable models will be run as candidate models and then have minimum fitness criteria set for qualification.  For CalTRACK electric monthly savings analysis, the following candidate models are fit:   UPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\beta_{Ci}CDD_m +  \\epsilon_{mi}    UPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\epsilon_{mi}    UPD_{mi} = \\mu_i + \\beta_{Ci}CDD_m+ \\epsilon_{mi}    UPD_{mi} = \\mu_i + \\epsilon_{mi}   with the constraints   \\beta_H > 0    \\beta_C > 0    \\mu_i > 0   For electric, qualifying models for selection must have each parameter estimate meet the minimum significance criteria of p < 0.1 and are strictly positive. All qualifying models are considered for final model selection.  For CalTRACK gas monthly savings analysis, the following candidate models are fit:   UPD_{mi} = \\mu_i + \\beta_{Hi}HDD_m + \\epsilon_{mi}    UPD_{mi} = \\mu_i + \\beta_{Ci}CDD_m+ \\epsilon_{mi}    UPD_{mi} = \\mu_i + \\epsilon_{mi}   with the constraints   \\beta_H > 0    \\mu_i > 0   If each parameter estimate meets minimum significance criteria  (p < 0.1)  and are strictly positive, then the model is a qualifying model for inclusion in model selection.",
            "title": "3. Fit All Candidate Models and Apply Qualification Criteria"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#4-select-the-best-for-pre-intervenion-and-post-intervention-periods-for-use-in-second-stage-savings-estimation",
            "text": "All qualifying pre-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.  For the monthly billing analysis, because we are using fixed degree days instead of variable degree days, adjusted R-squared will be defined as   R^2_{adj} = 1 - \\frac{(SS_{res}/df_e)}{(SS_{tot}/df_t)}   Where   SS_{res}  is the sum of squares of residuals   df_e  is the degrees of freedom of the estimate of the underlying population error variance, and is calculated using  n-p-1 , where  n  is the number of observations in the sample used to estimate the model and  p  is the number of explanatory variables, not including the constant term and not including degree day base temperature as a parameter because it\u2019s fixed   SS_{tot}  is the total sum of squares   df_t  is the degrees of freedom of the estimate of the population variance of the dependent variable, and is calculated as  n-1 , were  n  is the size of the sample use to estimate the model  All qualifying post-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.",
            "title": "4. Select the best for pre-intervenion and post-intervention periods for use in second-stage savings estimation"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#5-estimate-second-stage-weather-normalized-metered-energy-savings-quantities-based-on-selected-first-stage-pre-and-post-intervention-models",
            "text": "During the second stage, up to five savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.  Cumulative weather normalized metered energy savings over entire performance period\nYear one annualized actual weather normalized metered energy savings in the the reporting (post-intervention) period\nYear two annualized actual weather normalized metered energy savings in the the reporting (post-intervention) period\nYear one annualized weather normalized metered energy savings in the normal year\nYear two annualized weather normalized metered energy savings in the normal year  These site-level second stage quantities are calculated as follows:",
            "title": "5. Estimate second-stage weather normalized metered energy savings quantities based on selected first stage pre- and post-intervention models"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#cumulative-weather-normalized-metered-energy-savings-over-entire-performance-period-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period after  work_end_date  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for every complete billing periods after  work_end_date  for project  Sum   monthly_gross_savings  over every complete billing period since  work_end_date .",
            "title": "Cumulative weather normalized metered energy savings over entire performance period (site-level)"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#year-one-weather-normalized-metered-energy-savings-from-1-to-12-months-after-site-visit-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period after  work_end_date  until 12 billing periods after  work_end_date   using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for 12 complete billing periods after  work_end_date  for project  Sum   monthly_gross_savings  over the 12 billing periods since  work_end_date .",
            "title": "Year one weather normalized metered energy savings from 1 to 12 months after site visit. (site-level)"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#year-two-weather-normalized-metered-energy-savings-from-13-to-24-months-after-site-visit-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period starting 13 months after  work_end_date  until 24 billing periods after  work_end_date   using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for month 13 to month 24 after  work_end_date  for project  Sum   monthly_gross_savings  over the 12 billing periods from 13 months after  work_end_date  to 24 months.",
            "title": "Year two weather normalized metered energy savings from 13 to 24 months after site visit. (site-level)"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#year-one-site-level-annualized-weather-normalized-metered-energy-savings-in-the-normal-year",
            "text": "Compute  predicted_baseline_monthly_use  using the stage one model from the baseline period and average degree days from the CZ2010 normal weather year. Use the full month of available values when calculating the average degree days per billing period for the normal year.  Compute  predicted_reporting_monthly_use  using a  stage one  model fit to only the first 12 months of post-intervention values and degree days from the CZ2010 normal weather year file. Use the full month of available values when calculating the average degree days per billing period for the normal year.  Compute  monthly_normal_year_gross_savings  =  predicted_baseline_monthly_use - predicted_reporting_monthly_use  for normal year months  Sum   monthly_normal_year_gross_savings  over entire normal year.",
            "title": "Year one site-level annualized weather normalized metered energy savings in the normal year"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#year-two-site-level-annualized-weather-normalized-metered-energy-savings-in-the-normal-year",
            "text": "Compute  predicted_baseline_monthly_use  using the stage one model from the baseline period and degree days from the CZ2010 normal weather year.  Compute  predicted_reporting_monthly_use  using a  stage one  model fit to only the 13th-24th months of post-intervention values and degree days from the CZ2010 normal weather year file for the relevant months.  Compute  monthly_normal_year_gross_savings  =  predicted_baseline_monthly_use - predicted_reporting_monthly_use  for each normal year month.  Sum   monthly_normal_year_gross_savings  over entire normal year.",
            "title": "Year two site-level annualized weather normalized metered energy savings in the normal year"
        },
        {
            "location": "/savings-calculations/v1.0/monthly/README/#post-estimation-steps-and-portfolio-aggregation",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over  portfolios of homes . In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified  here .",
            "title": "Post-estimation steps and portfolio aggregation"
        },
        {
            "location": "/savings-calculations/v1.0/daily/README/",
            "text": "CalTRACK Site-level Daily Weather Normalized, Metered Energy Savings Estimation Technical Guidelines\n\n\n\n\nMethodological Overview\n\n\nSite-level Weather Normalized, Metered Energy Savings using daily billing data (both electricity and gas) will use a two-stage estimation approach that builds on the technical appendix of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, while providing more specific guidance to ensure replicability and address specific methodological issues related to both the data sources and the CalTRACK-specific use cases that are not addressed in prior standards.\n\n\nThe two-stage approach fits two separate parametric models to daily energy use data in both the pre-intervention (baseline) period and the post-intervention (reporting) period using ordinary least squares with the following first stage equation:\n\n\n\n\nUPD_{di} = \\mu_i + \\beta_{Hi}HDD_d + \\beta_{Ci}CDD_d + \\epsilon_{di}\n\n\n\n\nWhere:\n\n\n\n\nUPD_{di}\n is the total use (therms for gas, kWh for electricity) per day on day, \nd\n, for site, \ni\n\n\n\n\n\n\n\\mu_i\n is the mean use for site, \ni\n\n\n\n\n\n\n\\beta_{Hi}\n is the coefficient for site, \ni\n, of heating degree days\n\n\n\n\n\\beta_{Ci}\n is the coefficient for site, \ni\n, of cooling degree days\n\n\n\n\nHDD_d\n is the number of heating degree days on day, \nd\n, calculated as \nmax(heating balance point - average daily temperature at site i, 0)\n\n\n\n\nCDD_d\n is the number of cooling degree days on day, \nd\n, calculated as \nmax(average daily temperature at site i - cooling balance point, 0)\n\n\n\n\n\\epsilon_{di}\n is the error term at site, \ni\n, for day, \nd\n\n\n\n\nNote\n: during the beta test we explored the use of robust linear regression instead of ordinary least squares but ultimately decided to use ordinary least squares for the initial CalTRACK use case.  A robust regression may offer some significant advantages, as described \nhere\n along with our reasons for sticking with ordinary least squares, and is worth considering as a future improvement to these methods.\n\n\nIn the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized metered energy savings), or by using current-year weather to project forward baseline period use (current year weather normalized metered energy savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.\n\n\nWe now proceed with a detailed technical treatment of the steps for daily savings estimation.\n\n\nTechnical guidelines for implementing two-stage estimation on daily electric and gas usage data for CalTRACK\n\n\nCalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Preparation technical specification. Starting with the prepared data, site-level daily metered energy savings analysis is performed by implementing the following steps:\n\n\n\n\n\n\nUsage data used in the CalTRACK daily analysis will be done on Use Per Day (\nUPD\n) values from daily AMI usage data.\n\n\n\n\n\n\nStage one modeling will be done sequentially as a joint optimization problem using minimum model qualification criteria to constrain the space of candidate models, then using model selection criteria for choosing the \"best\" among candidate models for savings estimation.\n\n\n\n\n\n\nVariable Degree Day Base Temperature Search and Optimization\n\n\nCalTRACK daily methods will use variable degree day base temperatures. Balance point temperatures will be selected by doing a search over the one or two parameter HDD and CDD models separately using the following grid search criteria:\n\n\n1) Search range for HDD base temp: \n55 degrees F to 65 degrees F\n\n\n2) Search range for CDD base temp: \n65 degrees F to 75 degrees F\n\n\n3) With the constraint \nHDD Base Temp\n<=\nCDD Base Temp\n\n\n4) Grid search step size: \n1 degree\n\n\nGrid Search Data Sufficiency\n\n\nWhen searching across balance points, only model those balance points for which there are either: \n\n\n\n\n\n\nat least 10 non-zero degree days\n\n\n\n\n\n\na sum of at least 20 degree days\n\n\n\n\n\n\nThis avoids overfitting in the case where only a few days exist with usage and nonzero degree-days, and the usage happens by chance to be unusually high on those days.\n\n\nModel Qualification\n\n\nFor each site, the choice must be made between using one of the single parameter models (just \nHDD\n or \nCDD\n) or combined models (\nHDD\n and \nCDD\n), or the intercept-only model.  This choice is called \nmodel selection\n.  Before model selection, choose qualifying models in the following way:\n\n\n\n\n\n\nFor each set of balance points in the grid search, fit the single parameter and combined models.\n\n\n\n\n\n\nQualifying models are those meeting the following constraints:\n\n\n\n\n\n\n\n\n \\beta_{Hi}, \\beta_{Ci} >= 0 \n\n\n\n\n\n\n\n\np-values for \n\\beta_{Hi}\n and  \n\\beta_{Ci}\n are \n< 0.1\n\n\n\n\n\n\n\n\nModel Selection/Optimization\n\n\nAmong qualifying models, the model with the maximum adjusted R-squared will be selected as the best fit model for second-stage savings estimation.  If there are no qualifying models, fit the intercept-only model and use that for second-stage savings estimation.\n\n\nSecond Stage Estimated Quantities\n\n\nDuring the second stage, four savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.\n\n\n\n\nCumulative weather normalized metered energy savings over entire performance period\n\n\nNormal year annualized weather normalized metered energy savings\n\n\nYear one annualized weather normalized metered energy savings in the the reporting (post-intervention) period\n\n\nYear two annualized weather normalized metered energy savings in the the reporting (post-intervention) period\n\n\n\n\nThese site-level second stage quantities are calculated as follows:\n\n\nCumulative weather normalized metered energy savings over entire performance period (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each day after \nwork_end_date\n using the Stage One model with the reporting period weather data. Be sure to use balance point temperatures from the baseline model when calculating reporting period HDD and CDD values.\n\n\nCompute \ndaily_gross_savings\n = \npredicted_baseline_use - actual_use\n for every day after \nwork_end_date\n.\n\n\nSum  \ndaily_gross_savings\n over every day since \nwork_end_date\n.\n\n\n\n\nNormal year annualized weather normalized metered energy savings (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n using the Stage One model from the baseline period and degree days from the CZ2010 normal weather year. Be sure to use balance point temperatures from the baseline model when calculating baseline period HDD and CDD values.\n\n\nCompute \npredicted_reporting_use\n using the Stage One model from the reporting period and degree days from the CZ2010 normal weather year file. Be sure to use balance point temperatures from the reporting period model when calculating reporting period HDD and CDD values.\n\n\nCompute \ndaily_normal_year_gross_savings\n = \npredicted_baseline_use - predicted_reporting_use\n for normal year days\n\n\nSum  \ndaily_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nYear one weather normalized metered energy savings from 1 to 12 months after site visit.  (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each day after \nwork_end_date\n until 12 calendar months after \nwork_end_date\n using the Stage One model from the baseline period and reporting period weather data. Be sure to use balance point temperatures from the baseline model when calculating reporting period HDD and CDD values.\n\n\nCompute \ndaily_gross_savings\n = \npredicted_baseline_use - actual_daily_use\n for 12 complete calendar months after \nwork_end_date\n for project. For days missing consumption data after the date of the intervention, a baseline mask should exclude those days from consideration as part of a savings calculation.\n\n\nSum  \ndaily_gross_savings\n over the 12 calendar months since \nwork_end_date\n.\n\n\n\n\nYear two weather normalized metered energy savings from 13 to 24 months after site visit.  (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each day starting 13 months after \nwork_end_date\n until 24 calendar months after \nwork_end_date\n using the Stage One model from the baseline period and reporting period weather data. Be sure to use balance point temperatures from the baseline model when calculating reporting period HDD and CDD values.\n\n\nCompute \ndaily_gross_savings\n = \npredicted_baseline_use - actual_daily_use\n for month 13 to month 24 after \nwork_end_date\n for project. For days missing consumption data after the date of the intervention, a baseline mask should exclude those days from consideration as part of a savings calculation.\n\n\nSum  \ndaily_gross_savings\n over the 12 calendar months from 13 months after \nwork_end_date\n to 24 months.\n\n\n\n\nPost-estimation steps and portfolio aggregation\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over portfolios of homes. In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified \nhere\n.",
            "title": "Analysis of Daily Data"
        },
        {
            "location": "/savings-calculations/v1.0/daily/README/#caltrack-site-level-daily-weather-normalized-metered-energy-savings-estimation-technical-guidelines",
            "text": "",
            "title": "CalTRACK Site-level Daily Weather Normalized, Metered Energy Savings Estimation Technical Guidelines"
        },
        {
            "location": "/savings-calculations/v1.0/daily/README/#methodological-overview",
            "text": "Site-level Weather Normalized, Metered Energy Savings using daily billing data (both electricity and gas) will use a two-stage estimation approach that builds on the technical appendix of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, while providing more specific guidance to ensure replicability and address specific methodological issues related to both the data sources and the CalTRACK-specific use cases that are not addressed in prior standards.  The two-stage approach fits two separate parametric models to daily energy use data in both the pre-intervention (baseline) period and the post-intervention (reporting) period using ordinary least squares with the following first stage equation:   UPD_{di} = \\mu_i + \\beta_{Hi}HDD_d + \\beta_{Ci}CDD_d + \\epsilon_{di}   Where:   UPD_{di}  is the total use (therms for gas, kWh for electricity) per day on day,  d , for site,  i    \\mu_i  is the mean use for site,  i    \\beta_{Hi}  is the coefficient for site,  i , of heating degree days   \\beta_{Ci}  is the coefficient for site,  i , of cooling degree days   HDD_d  is the number of heating degree days on day,  d , calculated as  max(heating balance point - average daily temperature at site i, 0)   CDD_d  is the number of cooling degree days on day,  d , calculated as  max(average daily temperature at site i - cooling balance point, 0)   \\epsilon_{di}  is the error term at site,  i , for day,  d   Note : during the beta test we explored the use of robust linear regression instead of ordinary least squares but ultimately decided to use ordinary least squares for the initial CalTRACK use case.  A robust regression may offer some significant advantages, as described  here  along with our reasons for sticking with ordinary least squares, and is worth considering as a future improvement to these methods.  In the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized metered energy savings), or by using current-year weather to project forward baseline period use (current year weather normalized metered energy savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.  We now proceed with a detailed technical treatment of the steps for daily savings estimation.",
            "title": "Methodological Overview"
        },
        {
            "location": "/savings-calculations/v1.0/daily/README/#technical-guidelines-for-implementing-two-stage-estimation-on-daily-electric-and-gas-usage-data-for-caltrack",
            "text": "CalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Preparation technical specification. Starting with the prepared data, site-level daily metered energy savings analysis is performed by implementing the following steps:    Usage data used in the CalTRACK daily analysis will be done on Use Per Day ( UPD ) values from daily AMI usage data.    Stage one modeling will be done sequentially as a joint optimization problem using minimum model qualification criteria to constrain the space of candidate models, then using model selection criteria for choosing the \"best\" among candidate models for savings estimation.    Variable Degree Day Base Temperature Search and Optimization  CalTRACK daily methods will use variable degree day base temperatures. Balance point temperatures will be selected by doing a search over the one or two parameter HDD and CDD models separately using the following grid search criteria:  1) Search range for HDD base temp:  55 degrees F to 65 degrees F  2) Search range for CDD base temp:  65 degrees F to 75 degrees F  3) With the constraint  HDD Base Temp <= CDD Base Temp  4) Grid search step size:  1 degree  Grid Search Data Sufficiency  When searching across balance points, only model those balance points for which there are either:     at least 10 non-zero degree days    a sum of at least 20 degree days    This avoids overfitting in the case where only a few days exist with usage and nonzero degree-days, and the usage happens by chance to be unusually high on those days.  Model Qualification  For each site, the choice must be made between using one of the single parameter models (just  HDD  or  CDD ) or combined models ( HDD  and  CDD ), or the intercept-only model.  This choice is called  model selection .  Before model selection, choose qualifying models in the following way:    For each set of balance points in the grid search, fit the single parameter and combined models.    Qualifying models are those meeting the following constraints:      \\beta_{Hi}, \\beta_{Ci} >= 0      p-values for  \\beta_{Hi}  and   \\beta_{Ci}  are  < 0.1     Model Selection/Optimization  Among qualifying models, the model with the maximum adjusted R-squared will be selected as the best fit model for second-stage savings estimation.  If there are no qualifying models, fit the intercept-only model and use that for second-stage savings estimation.  Second Stage Estimated Quantities  During the second stage, four savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.   Cumulative weather normalized metered energy savings over entire performance period  Normal year annualized weather normalized metered energy savings  Year one annualized weather normalized metered energy savings in the the reporting (post-intervention) period  Year two annualized weather normalized metered energy savings in the the reporting (post-intervention) period   These site-level second stage quantities are calculated as follows:  Cumulative weather normalized metered energy savings over entire performance period (site-level)   Compute  predicted_baseline_use  for each day after  work_end_date  using the Stage One model with the reporting period weather data. Be sure to use balance point temperatures from the baseline model when calculating reporting period HDD and CDD values.  Compute  daily_gross_savings  =  predicted_baseline_use - actual_use  for every day after  work_end_date .  Sum   daily_gross_savings  over every day since  work_end_date .   Normal year annualized weather normalized metered energy savings (site-level)   Compute  predicted_baseline_use  using the Stage One model from the baseline period and degree days from the CZ2010 normal weather year. Be sure to use balance point temperatures from the baseline model when calculating baseline period HDD and CDD values.  Compute  predicted_reporting_use  using the Stage One model from the reporting period and degree days from the CZ2010 normal weather year file. Be sure to use balance point temperatures from the reporting period model when calculating reporting period HDD and CDD values.  Compute  daily_normal_year_gross_savings  =  predicted_baseline_use - predicted_reporting_use  for normal year days  Sum   daily_normal_year_gross_savings  over entire normal year.   Year one weather normalized metered energy savings from 1 to 12 months after site visit.  (site-level)   Compute  predicted_baseline_use  for each day after  work_end_date  until 12 calendar months after  work_end_date  using the Stage One model from the baseline period and reporting period weather data. Be sure to use balance point temperatures from the baseline model when calculating reporting period HDD and CDD values.  Compute  daily_gross_savings  =  predicted_baseline_use - actual_daily_use  for 12 complete calendar months after  work_end_date  for project. For days missing consumption data after the date of the intervention, a baseline mask should exclude those days from consideration as part of a savings calculation.  Sum   daily_gross_savings  over the 12 calendar months since  work_end_date .   Year two weather normalized metered energy savings from 13 to 24 months after site visit.  (site-level)   Compute  predicted_baseline_use  for each day starting 13 months after  work_end_date  until 24 calendar months after  work_end_date  using the Stage One model from the baseline period and reporting period weather data. Be sure to use balance point temperatures from the baseline model when calculating reporting period HDD and CDD values.  Compute  daily_gross_savings  =  predicted_baseline_use - actual_daily_use  for month 13 to month 24 after  work_end_date  for project. For days missing consumption data after the date of the intervention, a baseline mask should exclude those days from consideration as part of a savings calculation.  Sum   daily_gross_savings  over the 12 calendar months from 13 months after  work_end_date  to 24 months.",
            "title": "Technical guidelines for implementing two-stage estimation on daily electric and gas usage data for CalTRACK"
        },
        {
            "location": "/savings-calculations/v1.0/daily/README/#post-estimation-steps-and-portfolio-aggregation",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over portfolios of homes. In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified  here .",
            "title": "Post-estimation steps and portfolio aggregation"
        },
        {
            "location": "/aggregation/v1.0/README/",
            "text": "Aggregating Site-level Weather Normalized Metered Energy Savings and Quantifying Uncertainty in Aggregate Savings Statistics\n\n\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over portfolios of residential single family buildings.\n\n\nPortfolio-level savings statistics are based on aggregations of site-level savings estimates created using the CalTRACK site-level daily weather normalized metered energy savings analysis methods.\n\n\nRecommendations calculating aggregate payable savings for portfolios site-level savings estimates.\n\n\nTotal payable savings.\n For a portfolio of N projects with valid site-level savings estimates generated using the CalTRACK daily analysis method, the CalTRACK working group recommends portfolio-level total payments based on the unweighted sum of all N site-level estimates (in kWh or therms), whether negative or positive, as below:\n\n\n \n\n\nWhere\n\n\n is the savings estimate for the ith site in a portfolio.\n\n\nBecause of the potential for abnormally large savings estimates (either positive or negative) caused by unrelated phenomena or statistical noise to skew portfolio total payable savings, the technical working group also recommends a policy for either aggregators or payors to argue for the exclusion of projects from portfolio totals if they are either above a site-level fractional savings of 50% or below a site-level fractional savings of -50%",
            "title": "Aggregration of Site-level Savings"
        },
        {
            "location": "/aggregation/v1.0/README/#aggregating-site-level-weather-normalized-metered-energy-savings-and-quantifying-uncertainty-in-aggregate-savings-statistics",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over portfolios of residential single family buildings.  Portfolio-level savings statistics are based on aggregations of site-level savings estimates created using the CalTRACK site-level daily weather normalized metered energy savings analysis methods.",
            "title": "Aggregating Site-level Weather Normalized Metered Energy Savings and Quantifying Uncertainty in Aggregate Savings Statistics"
        },
        {
            "location": "/aggregation/v1.0/README/#recommendations-calculating-aggregate-payable-savings-for-portfolios-site-level-savings-estimates",
            "text": "Total payable savings.  For a portfolio of N projects with valid site-level savings estimates generated using the CalTRACK daily analysis method, the CalTRACK working group recommends portfolio-level total payments based on the unweighted sum of all N site-level estimates (in kWh or therms), whether negative or positive, as below:     Where   is the savings estimate for the ith site in a portfolio.  Because of the potential for abnormally large savings estimates (either positive or negative) caused by unrelated phenomena or statistical noise to skew portfolio total payable savings, the technical working group also recommends a policy for either aggregators or payors to argue for the exclusion of projects from portfolio totals if they are either above a site-level fractional savings of 50% or below a site-level fractional savings of -50%",
            "title": "Recommendations calculating aggregate payable savings for portfolios site-level savings estimates."
        }
    ]
}