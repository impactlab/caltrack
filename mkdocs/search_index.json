{
    "docs": [
        {
            "location": "/",
            "text": "Welcome to the CalTRACK Technical Documentation\n\n\nA Shared repository for beta testers of CalTRACK methods\n\n\nAdditional documentation on the CalTRACK process can be found a \ncaltrack.org\n.\n\n\n\n\nThe CalTRACK Beta Test is intended to help test, refine and finalize the technical requirements and methods for CalTRACK. In it, the initial draft requirements for CalTRACK developed by the technical working group will be tested in the field using data from PG&E to empirically verify assumptions made by the technical working group, identify areas of sensitivity, and agree on a first implementable system. Details about the Beta Test plan can can be found here.\n\n\n\n\nCommunication for the project will happen primarily on Slack. Any relevant changes to the technical specification outlined in the CalTRACK docs will be discussed and resolved as Github issues on \nthis repository\n\n\nContributors:\n\n\n\n\nOpen Energy Efficiency\n\n\nEnergySavvy\n\n\nDNV GL",
            "title": "Home"
        },
        {
            "location": "/#welcome-to-the-caltrack-technical-documentation",
            "text": "A Shared repository for beta testers of CalTRACK methods  Additional documentation on the CalTRACK process can be found a  caltrack.org .   The CalTRACK Beta Test is intended to help test, refine and finalize the technical requirements and methods for CalTRACK. In it, the initial draft requirements for CalTRACK developed by the technical working group will be tested in the field using data from PG&E to empirically verify assumptions made by the technical working group, identify areas of sensitivity, and agree on a first implementable system. Details about the Beta Test plan can can be found here.   Communication for the project will happen primarily on Slack. Any relevant changes to the technical specification outlined in the CalTRACK docs will be discussed and resolved as Github issues on  this repository  Contributors:   Open Energy Efficiency  EnergySavvy  DNV GL",
            "title": "Welcome to the CalTRACK Technical Documentation"
        },
        {
            "location": "/guides/v1guide/",
            "text": "Guide to Using CalTRACK v1.0 Monthly Gross Savings Methods\n\n\nThe CalTRACK Version 1.0 specification provides guidance for performing monthly billing analysis for whole home weather normalized gross savings for groups of residential energy efficiency projects.\n\n\nIt includes data requirements and technical specifications for data preparation and cleaning, site-level billing analysis, and aggregation of site-level results.\n\n\nThe complete technical specification for v1 monthly methods is found in four documents\n\n\n\n\nmonthly/data-sources.md\n describes the necessary data requirements for running CalTRACK v1\n\n\nmonthly/data-prep.md\n describes the sequence of steps required for preparing data for analysis\n\n\n/monthly/analysis.md\n describes the methods use for calculating site-level savings using monthly data\n\n\nmonthly/aggregation.md\n describes the methods use for aggregating site-level savings to group or portfolio average and total savings\n\n\n\n\nThe specification is intended to be done in order to ensure consistency and replicability.\n\n\nSupported Use Cases\n\n\nThe CalTRACK v1 monthly billing analysis methods were developed to produce a reliable estimate of basic, weather normalized gross savings at the site level and weighted average gross savings for groups (or portfolios) of projects.\n\n\nThis definition of gross savings was developed with two specific use cases in mind, and was not intended to extend to all potential uses of monthly billing analysis.\n\n\nThe two use cases that CalTRACK v1 is intended to support are:\n\n\n\n\nCalculating \npayable savings\n in the PG&E Residential Third-Party Pay-for-Performance pilot program. In this program, selected third party aggregators (organization providing services that may lead to energy savings) are paid  based on the measured energy use reductions for homes they submit to PG&E as having received their services. Payments to these aggregators will be based on CalTRACK methods. The savings that the utility can claim was delivered as a result of the program will be measured through a separate EM&V process.\n\n\nCalculating \nrealized savings and realization rates\n for third-party software used to predict savings for residential efficiency project for the purposes of determining rebates. Average empirical realization rates by vendor may be used to adjust rebates on an ongoing basis and provide feedback to vendors and contractors on their relative performance.  \n\n\n\n\nNotes on key CalTRACK v1 decisions and their implications\n\n\n\n\nFixed Degree Day Base. While it is more common in industry to use a variable degree day base temperatures in monthly billing analysis, the CalTRACK technical working group decided to use fixed degree day base temperatures. This decision was made after empirical testing of both fixed and variable degree day basis showed that, for a sample of 3000 projects done from 2014-2016 in PG&E territory there was little difference in average savings between the two methods, the use of variable degree days contributed to significant differences in savings among testers. The technical working group made the determination that, since replicability was a priority for the two supported use cases, the added replicability of the fixed degree day approach made it the better choice for CalTRACK v1 methods.\n\n\nInverse Variance Weighted Means for determining aggregate savings. In determining the average savings over groups of homes, inverse variance weighted means offers a way of dealing with the important consideration that not all site-level savings estimates are equally confident. IVWM emphasizes the savings of homes with good site-level model fits, while deemphasizing sites with poor model fits. This approach comes from meta analysis and is the minimum-variance estimator of a group mean under assumptions of conditional independence. However, two challenges arise in applying IVWMs to group savings. 1) The independence assumption may not hold over areas or time periods because of structural correlation in savings. This means it may be underestimating variances due to correlation structure in the errors. Practically, this may introduce bias in the group mean depending on the correlation structure 2) larger homes will tend to have large variances and smaller homes (and gas use which is closer to 0 in many homes), leading to a potential structural underestimate of group average savings because smaller savings will have smaller variances. 3) sites with very low variances (very close to zero) can lead blow up mean savings estimates (dividing by very small numbers) and require addition checks on the final number used for programmatic purposes. Alternative weighting schemes were discussed by the technical working group, but none were ultimately selected due to similar tradeoffs faced by each weighting scheme. Users of the v1 methods should be aware of the ways that IVWMs both solves for and also creates risks to program implementation and chose the right approach and risk mitigation procedures for the program accordingly.\n\n\n\n\nImportant Caveats\n\n\n\n\nThe purpose of CalTRACK is to provide intermediate estimates of gross savings and not replace more detailed impact evaluations which focus on net savings measurement. In addition to excluding factors that are typically included in net savings estimation (selection effects, free ridership), v1 monthly methods omits corrections for population-wide factors that some consider part of gross savings (unobserved weather effects like solar exposure, macroeconomic shocks, etc.). Anyone using CalTRACK v1 methods should be aware that these potential effects on energy use are explicitly not adjusted for in v1 methods, and as a result, expose program participants and aggregators to some additional downside savings measurement risk and utilities to additional upside measurement risk. These measurement risks were weighed against the advantages in simplicity and replicability in deciding on the simple weather normalized savings approach in v1.",
            "title": "Guide to Version 1.0 Monthly Methods"
        },
        {
            "location": "/guides/v1guide/#guide-to-using-caltrack-v10-monthly-gross-savings-methods",
            "text": "The CalTRACK Version 1.0 specification provides guidance for performing monthly billing analysis for whole home weather normalized gross savings for groups of residential energy efficiency projects.  It includes data requirements and technical specifications for data preparation and cleaning, site-level billing analysis, and aggregation of site-level results.  The complete technical specification for v1 monthly methods is found in four documents   monthly/data-sources.md  describes the necessary data requirements for running CalTRACK v1  monthly/data-prep.md  describes the sequence of steps required for preparing data for analysis  /monthly/analysis.md  describes the methods use for calculating site-level savings using monthly data  monthly/aggregation.md  describes the methods use for aggregating site-level savings to group or portfolio average and total savings   The specification is intended to be done in order to ensure consistency and replicability.",
            "title": "Guide to Using CalTRACK v1.0 Monthly Gross Savings Methods"
        },
        {
            "location": "/guides/v1guide/#supported-use-cases",
            "text": "The CalTRACK v1 monthly billing analysis methods were developed to produce a reliable estimate of basic, weather normalized gross savings at the site level and weighted average gross savings for groups (or portfolios) of projects.  This definition of gross savings was developed with two specific use cases in mind, and was not intended to extend to all potential uses of monthly billing analysis.  The two use cases that CalTRACK v1 is intended to support are:   Calculating  payable savings  in the PG&E Residential Third-Party Pay-for-Performance pilot program. In this program, selected third party aggregators (organization providing services that may lead to energy savings) are paid  based on the measured energy use reductions for homes they submit to PG&E as having received their services. Payments to these aggregators will be based on CalTRACK methods. The savings that the utility can claim was delivered as a result of the program will be measured through a separate EM&V process.  Calculating  realized savings and realization rates  for third-party software used to predict savings for residential efficiency project for the purposes of determining rebates. Average empirical realization rates by vendor may be used to adjust rebates on an ongoing basis and provide feedback to vendors and contractors on their relative performance.",
            "title": "Supported Use Cases"
        },
        {
            "location": "/guides/v1guide/#notes-on-key-caltrack-v1-decisions-and-their-implications",
            "text": "Fixed Degree Day Base. While it is more common in industry to use a variable degree day base temperatures in monthly billing analysis, the CalTRACK technical working group decided to use fixed degree day base temperatures. This decision was made after empirical testing of both fixed and variable degree day basis showed that, for a sample of 3000 projects done from 2014-2016 in PG&E territory there was little difference in average savings between the two methods, the use of variable degree days contributed to significant differences in savings among testers. The technical working group made the determination that, since replicability was a priority for the two supported use cases, the added replicability of the fixed degree day approach made it the better choice for CalTRACK v1 methods.  Inverse Variance Weighted Means for determining aggregate savings. In determining the average savings over groups of homes, inverse variance weighted means offers a way of dealing with the important consideration that not all site-level savings estimates are equally confident. IVWM emphasizes the savings of homes with good site-level model fits, while deemphasizing sites with poor model fits. This approach comes from meta analysis and is the minimum-variance estimator of a group mean under assumptions of conditional independence. However, two challenges arise in applying IVWMs to group savings. 1) The independence assumption may not hold over areas or time periods because of structural correlation in savings. This means it may be underestimating variances due to correlation structure in the errors. Practically, this may introduce bias in the group mean depending on the correlation structure 2) larger homes will tend to have large variances and smaller homes (and gas use which is closer to 0 in many homes), leading to a potential structural underestimate of group average savings because smaller savings will have smaller variances. 3) sites with very low variances (very close to zero) can lead blow up mean savings estimates (dividing by very small numbers) and require addition checks on the final number used for programmatic purposes. Alternative weighting schemes were discussed by the technical working group, but none were ultimately selected due to similar tradeoffs faced by each weighting scheme. Users of the v1 methods should be aware of the ways that IVWMs both solves for and also creates risks to program implementation and chose the right approach and risk mitigation procedures for the program accordingly.",
            "title": "Notes on key CalTRACK v1 decisions and their implications"
        },
        {
            "location": "/guides/v1guide/#important-caveats",
            "text": "The purpose of CalTRACK is to provide intermediate estimates of gross savings and not replace more detailed impact evaluations which focus on net savings measurement. In addition to excluding factors that are typically included in net savings estimation (selection effects, free ridership), v1 monthly methods omits corrections for population-wide factors that some consider part of gross savings (unobserved weather effects like solar exposure, macroeconomic shocks, etc.). Anyone using CalTRACK v1 methods should be aware that these potential effects on energy use are explicitly not adjusted for in v1 methods, and as a result, expose program participants and aggregators to some additional downside savings measurement risk and utilities to additional upside measurement risk. These measurement risks were weighed against the advantages in simplicity and replicability in deciding on the simple weather normalized savings approach in v1.",
            "title": "Important Caveats"
        },
        {
            "location": "/guides/v1.1guide/",
            "text": "",
            "title": "Guide to Version 1.1 Daily Methods"
        },
        {
            "location": "/monthly/data-sources/",
            "text": "Data Sources for CalTRACK Beta Test\n\n\nTwo major types of data files are supplied for the CalTRACK Beta: project data and consumption data. This data is linked with \"cross-reference\" files that define the mapping between ID columns in the two types of files.\n\n\nThere are two types of project files, which have slightly different column types--\nAHU\n and \nAHUP\n--requiring different logic for determining baseline and reporting period dates.\n\n\nConsumption data is further broken down into five file types: 15 minutely electricity, hourly electricity, daily natural gas, monthly electricity, and monthly natural gas.\n\n\nThe beta test set uses the following files:\n\n\n\n\n\n\nProject:\n\n\nCalTRACK (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n\n\nCalTRACK (AHU) from 1_1_14__6_30_15_v2_FINAL_090816.csv\n\n\nCalTRACK (AHU) from 7_1_15__6_30_16_v2_FINAL_090816.csv\n\n\n\n\n\n\nConsumption:\n\n\n\n\n15 minutely electricity: \nIDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv\n\n\nHourly electricity: \nIDA.60MIN.SMY1.EES25162-EHUP.20160719161716\n\n\nDaily natural gas: \nEES25162_gasdy_160720.csv\n\n\nMonthly electricity: \nEES25162.ERESBL13.XPT...\n\n\nMonthly natural gas: \nEES25162.GRESBL13.XPT...\n\n\n\n\n\n\n\n\nCross-reference\n\n\n\n\nElectricity: \nEES25162_ELECINTV_XREF.csv\n\n\nNatural Gas: \nEES25162_GASINTV_XREF.csv\n\n\n\n\n\n\n\n\nThe columns of interest in these files are as follows:\n\n\nProject AHUP\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nApplication No.\n\n\nProject identifier\n\n\n\n\n\n\nElectric Service ID\n\n\nID used for matching with consumption files\n\n\n\n\n\n\nGas Service ID\n\n\nID used for matching with consumption files\n\n\n\n\n\n\nFull Application Submitted\n\n\nBest proxy date for \"Work Finished\"\n\n\n\n\n\n\nFull Application Returned\n\n\nIf populated, the project got returned for correction.\n\n\n\n\n\n\nWork Start Date\n\n\nDate retrofit started, \nalways empty\n\n\n\n\n\n\nWork Finish Date\n\n\nDate retrofit ended, \nalways empty\n\n\n\n\n\n\nBuilding ZIP Code\n\n\n\n\n\n\n\n\n\n\nProject AHU\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nApplication No.\n\n\nProject identifier\n\n\n\n\n\n\nElectric Service ID\n\n\nID used for matching with consumption files\n\n\n\n\n\n\nGas Service ID\n\n\nID used for matching with consumption files\n\n\n\n\n\n\nInitial Submission Date\n\n\nDate of submission of energy retrofit project paperwork (after work completed)\n\n\n\n\n\n\nWork Start Date\n\n\nDate retrofit started\n\n\n\n\n\n\nWork Finish Date\n\n\nDate retrofit ended\n\n\n\n\n\n\nBuilding ZIP Code\n\n\n\n\n\n\n\n\n\n\nConsumption\n\n\nElectricity\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSPID\n\n\nService Point ID - identifies the physical meter\n\n\n\n\n\n\nSA\n\n\nService Agreement ID - generated when a customer signs a service agreement. Can be many SAs for a single SPID. Corresponds to \nElectric Service ID\n in project files.\n\n\n\n\n\n\nUOM\n\n\nUnit of Measure (KWH or THERM)\n\n\n\n\n\n\nDIR\n\n\nDirection of electricity flow (D=delivered, R=received)\n\n\n\n\n\n\nDATE\n\n\nDay for this row of consumption data\n\n\n\n\n\n\nRS\n\n\nRate schedule of the associated SA_ID (ignored)\n\n\n\n\n\n\nAPCT\n\n\nThe actual percent of intervals are \u201cGood\u201d vs \u201cEstimated\u201d. (ignored)\n\n\n\n\n\n\nNAICS\n\n\nAssociated with activity at the premise, only for non-residential (ignored)\n\n\n\n\n\n\n00:15, etc\n\n\nConsumption data for that interval\n\n\n\n\n\n\n\n\nThere may be rows with non-zero consumption in both the R and D direction at the same timestamp (e.g. the customer both consumed power from the grid and delivered power back to the grid over the time interval).\n\n\nNatural Gas\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nService Point\n\n\nService Point ID - identifies the physical meter. Corresponds to \nsp_id\n in cross-reference table.\n\n\n\n\n\n\nMeasurement Date\n\n\n\n\n\n\n\n\nTherms per day\n\n\n\n\n\n\n\n\n\n\nMonthly Consumption\n\n\nElectricity\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSA_ID\n\n\nService Agreement ID for cross-reference\n\n\n\n\n\n\nCDT__\ni\n (\ni\n [1,12])\n\n\nCurrent date the meter was read in SAS format\n\n\n\n\n\n\nPDT__\ni\n (\ni\n [1,12])\n\n\nPrevious date the meter was read\n\n\n\n\n\n\nKWH__\ni\n (\ni\n [1,12])\n\n\nUsage (KWH)\n\n\n\n\n\n\n\n\nAll other columns are ignored.\n\n\nSAS formatted dates count the number of days since Jan 1, 1960.\n\n\nDetails on rate schedules: https://www.pge.com/tariffs/ERS.SHTML\n(Currently unused but might impact \ninterpretation\n in the future.)\n\n\nNatural Gas\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nSA_ID\n\n\nService Agreement ID for cross-reference\n\n\n\n\n\n\nCDT__\ni\n (\ni\n [1,12])\n\n\nCurrent date the meter was read in SAS format\n\n\n\n\n\n\nPDT__\ni\n (\ni\n [1,12])\n\n\nPrevious date the meter was read\n\n\n\n\n\n\nTHM__\ni\n (\ni\n [1,12])\n\n\nUsage (THM)\n\n\n\n\n\n\n\n\nSee notes for monthly electricity consumption above for further details.\n\n\nCross-reference\n\n\nBoth types of cross-reference files contain the same columns of interest.\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nsa_id\n\n\nCorresponds to \nElectric Service ID\n or \nGas Service ID\n in projects file\n\n\n\n\n\n\nsp_id\n\n\nCorresponds to \nSPID\n in electricity consumption file and \nService Point\n in natural gas file\n\n\n\n\n\n\n\n\nOutput data format\n\n\nThe cleaned data should be is as follows:\n\n\nProjects\n\n\nAHU\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nproject_id\n\n\nProject file, column \nApplication No.\n\n\n\n\n\n\nzipcode\n\n\nProject file, column \nBuilding ZIP Code\n\n\n\n\n\n\nbaseline_period_end\n\n\nColumn \nWork Start Date\n unless empty, then column \nInitial Approval Date\n\n\n\n\n\n\nreporting_period_start\n\n\nColumn \nWork Finish Date\n unless empty, then column \nInitial Submission Date\n\n\n\n\n\n\n\n\nAHUP\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nproject_id\n\n\nProject file, column \nApplication No.\n\n\n\n\n\n\nzipcode\n\n\nProject file, column \nBuilding ZIP Code\n\n\n\n\n\n\nbaseline_period_end\n\n\nColumn \nNotice to Proceed Issued\n (Proxy for Work Start Date)\n\n\n\n\n\n\nreporting_period_start\n\n\nIf \nFull Application Returned\n is empty, column \nFull Application Submitted\n, otherwise column \nFull Application Started\n (Proxy for Work Finish Date)\n\n\n\n\n\n\n\n\nConsumption\n\n\nElectricity\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nproject_id\n\n\nColumn \nApplication No.\n in project file. Use the consumption cross-reference file to map the \nSPID\n column to \nElectric Service ID\n in the projects file. \nThere may be more than one matching project row\n \u2013 TBD how to handle this [1]\n\n\n\n\n\n\nstart\n\n\ncolumn \nDATE\n + column header for each time chunk\n\n\n\n\n\n\ninterpretation\n\n\nELECTRICITY_CONSUMPTION_SUPPLIED\n (\nE_C_S\n) for D direction. \nELECTRICITY_ON_SITE_GENERATION_UNCONSUMED\n (\nE_OSG_U\n) for R direction\n\n\n\n\n\n\nvalue\n\n\nValue of cell.\n\n\n\n\n\n\nestimated\n\n\nFalse\n\n\n\n\n\n\nlabel\n\n\nSA\n + \"-\" + \nSPID\n + \"-\" + \nDIR\n\n\n\n\n\n\nunit\n\n\nKWH\n\n\n\n\n\n\n\n\n[1] Only a single consumption trace matches multiple projects in the beta test data set.\n\n\nNatural Gas\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nproject_id\n\n\nColumn \nApplication No.\n in project file. Use the consumption cross-reference file to map the \nService Point\n column to \nGas Service ID\n in the projects file.\n\n\n\n\n\n\nstart\n\n\ncolumn \nMeasurement Date\n\n\n\n\n\n\ninterpretation\n\n\nNATURAL_GAS_CONSUMPTION_SUPPLIED\n (\nNG_C_S\n)\n\n\n\n\n\n\nvalue\n\n\nColumn \nTherms per Day\n\n\n\n\n\n\nestimated\n\n\nFalse\n\n\n\n\n\n\nlabel\n\n\nService Point\n\n\n\n\n\n\nunit\n\n\nTHM\n\n\n\n\n\n\n\n\nMonthly Consumption\n\n\nElectricity\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nproject_id\n\n\nColumn \nSA_ID\n corresponds to \nElectric Service ID\n in the projects file.\n\n\n\n\n\n\nstart\n\n\nparse column CDT__\ni\n for each time chunk\n\n\n\n\n\n\ninterpretation\n\n\nELECTRICITY_CONSUMPTION_SUPPLIED\n (\nE_C_S\n)\n\n\n\n\n\n\nvalue\n\n\nKWH__\ni\n\n\n\n\n\n\nestimated\n\n\nFalse\n\n\n\n\n\n\nlabel\n\n\nSA_ID\n\n\n\n\n\n\nunit\n\n\nKWH\n\n\n\n\n\n\n\n\nNatural Gas\n\n\n\n\n\n\n\n\nField\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nproject_id\n\n\nColumn \nSA_ID\n corresponds to \nGas Service ID\n in the projects file.\n\n\n\n\n\n\nstart\n\n\nparse column CDT__\ni\n for each time chunk\n\n\n\n\n\n\ninterpretation\n\n\nNATURAL_GAS_CONSUMPTION_SUPPLIED\n (\nNG_C_S\n)\n\n\n\n\n\n\nvalue\n\n\nTHN__\ni\n\n\n\n\n\n\nestimated\n\n\nFalse\n\n\n\n\n\n\nlabel\n\n\nmonthly-\nSA_ID\n\n\n\n\n\n\nunit\n\n\nTHM\n\n\n\n\n\n\n\n\nWeather\n\n\nThere are three weather source files necessary for the beta test.\n\n\n\n\nCZ2010 weather normals for 86 stations in California\n\n\nMapping of zip codes to weather stations\n\n\nHourly weather station data pulled from the NOAA ISD weather data using USAF",
            "title": "Data Sources for Monthly Methods"
        },
        {
            "location": "/monthly/data-sources/#data-sources-for-caltrack-beta-test",
            "text": "Two major types of data files are supplied for the CalTRACK Beta: project data and consumption data. This data is linked with \"cross-reference\" files that define the mapping between ID columns in the two types of files.  There are two types of project files, which have slightly different column types-- AHU  and  AHUP --requiring different logic for determining baseline and reporting period dates.  Consumption data is further broken down into five file types: 15 minutely electricity, hourly electricity, daily natural gas, monthly electricity, and monthly natural gas.  The beta test set uses the following files:    Project:  CalTRACK (AHUP) from 1_1_14__6_30_15_v2_FINAL_090816.csv  CalTRACK (AHU) from 1_1_14__6_30_15_v2_FINAL_090816.csv  CalTRACK (AHU) from 7_1_15__6_30_16_v2_FINAL_090816.csv    Consumption:   15 minutely electricity:  IDA.15MIN.SMY1.EES25162-EHUP.20160719161716.csv  Hourly electricity:  IDA.60MIN.SMY1.EES25162-EHUP.20160719161716  Daily natural gas:  EES25162_gasdy_160720.csv  Monthly electricity:  EES25162.ERESBL13.XPT...  Monthly natural gas:  EES25162.GRESBL13.XPT...     Cross-reference   Electricity:  EES25162_ELECINTV_XREF.csv  Natural Gas:  EES25162_GASINTV_XREF.csv     The columns of interest in these files are as follows:  Project AHUP     Column Name  Description      Application No.  Project identifier    Electric Service ID  ID used for matching with consumption files    Gas Service ID  ID used for matching with consumption files    Full Application Submitted  Best proxy date for \"Work Finished\"    Full Application Returned  If populated, the project got returned for correction.    Work Start Date  Date retrofit started,  always empty    Work Finish Date  Date retrofit ended,  always empty    Building ZIP Code      Project AHU     Column Name  Description      Application No.  Project identifier    Electric Service ID  ID used for matching with consumption files    Gas Service ID  ID used for matching with consumption files    Initial Submission Date  Date of submission of energy retrofit project paperwork (after work completed)    Work Start Date  Date retrofit started    Work Finish Date  Date retrofit ended    Building ZIP Code      Consumption  Electricity     Column Name  Description      SPID  Service Point ID - identifies the physical meter    SA  Service Agreement ID - generated when a customer signs a service agreement. Can be many SAs for a single SPID. Corresponds to  Electric Service ID  in project files.    UOM  Unit of Measure (KWH or THERM)    DIR  Direction of electricity flow (D=delivered, R=received)    DATE  Day for this row of consumption data    RS  Rate schedule of the associated SA_ID (ignored)    APCT  The actual percent of intervals are \u201cGood\u201d vs \u201cEstimated\u201d. (ignored)    NAICS  Associated with activity at the premise, only for non-residential (ignored)    00:15, etc  Consumption data for that interval     There may be rows with non-zero consumption in both the R and D direction at the same timestamp (e.g. the customer both consumed power from the grid and delivered power back to the grid over the time interval).  Natural Gas     Column Name  Description      Service Point  Service Point ID - identifies the physical meter. Corresponds to  sp_id  in cross-reference table.    Measurement Date     Therms per day      Monthly Consumption  Electricity     Column Name  Description      SA_ID  Service Agreement ID for cross-reference    CDT__ i  ( i  [1,12])  Current date the meter was read in SAS format    PDT__ i  ( i  [1,12])  Previous date the meter was read    KWH__ i  ( i  [1,12])  Usage (KWH)     All other columns are ignored.  SAS formatted dates count the number of days since Jan 1, 1960.  Details on rate schedules: https://www.pge.com/tariffs/ERS.SHTML\n(Currently unused but might impact  interpretation  in the future.)  Natural Gas     Column Name  Description      SA_ID  Service Agreement ID for cross-reference    CDT__ i  ( i  [1,12])  Current date the meter was read in SAS format    PDT__ i  ( i  [1,12])  Previous date the meter was read    THM__ i  ( i  [1,12])  Usage (THM)     See notes for monthly electricity consumption above for further details.  Cross-reference  Both types of cross-reference files contain the same columns of interest.     Column Name  Description      sa_id  Corresponds to  Electric Service ID  or  Gas Service ID  in projects file    sp_id  Corresponds to  SPID  in electricity consumption file and  Service Point  in natural gas file",
            "title": "Data Sources for CalTRACK Beta Test"
        },
        {
            "location": "/monthly/data-sources/#output-data-format",
            "text": "The cleaned data should be is as follows:  Projects  AHU     Field  Value      project_id  Project file, column  Application No.    zipcode  Project file, column  Building ZIP Code    baseline_period_end  Column  Work Start Date  unless empty, then column  Initial Approval Date    reporting_period_start  Column  Work Finish Date  unless empty, then column  Initial Submission Date     AHUP     Field  Value      project_id  Project file, column  Application No.    zipcode  Project file, column  Building ZIP Code    baseline_period_end  Column  Notice to Proceed Issued  (Proxy for Work Start Date)    reporting_period_start  If  Full Application Returned  is empty, column  Full Application Submitted , otherwise column  Full Application Started  (Proxy for Work Finish Date)     Consumption  Electricity     Field  Value      project_id  Column  Application No.  in project file. Use the consumption cross-reference file to map the  SPID  column to  Electric Service ID  in the projects file.  There may be more than one matching project row  \u2013 TBD how to handle this [1]    start  column  DATE  + column header for each time chunk    interpretation  ELECTRICITY_CONSUMPTION_SUPPLIED  ( E_C_S ) for D direction.  ELECTRICITY_ON_SITE_GENERATION_UNCONSUMED  ( E_OSG_U ) for R direction    value  Value of cell.    estimated  False    label  SA  + \"-\" +  SPID  + \"-\" +  DIR    unit  KWH     [1] Only a single consumption trace matches multiple projects in the beta test data set.  Natural Gas     Field  Value      project_id  Column  Application No.  in project file. Use the consumption cross-reference file to map the  Service Point  column to  Gas Service ID  in the projects file.    start  column  Measurement Date    interpretation  NATURAL_GAS_CONSUMPTION_SUPPLIED  ( NG_C_S )    value  Column  Therms per Day    estimated  False    label  Service Point    unit  THM     Monthly Consumption  Electricity     Field  Value      project_id  Column  SA_ID  corresponds to  Electric Service ID  in the projects file.    start  parse column CDT__ i  for each time chunk    interpretation  ELECTRICITY_CONSUMPTION_SUPPLIED  ( E_C_S )    value  KWH__ i    estimated  False    label  SA_ID    unit  KWH     Natural Gas     Field  Value      project_id  Column  SA_ID  corresponds to  Gas Service ID  in the projects file.    start  parse column CDT__ i  for each time chunk    interpretation  NATURAL_GAS_CONSUMPTION_SUPPLIED  ( NG_C_S )    value  THN__ i    estimated  False    label  monthly- SA_ID    unit  THM",
            "title": "Output data format"
        },
        {
            "location": "/monthly/data-sources/#weather",
            "text": "There are three weather source files necessary for the beta test.   CZ2010 weather normals for 86 stations in California  Mapping of zip codes to weather stations  Hourly weather station data pulled from the NOAA ISD weather data using USAF",
            "title": "Weather"
        },
        {
            "location": "/monthly/data-prep/",
            "text": "CalTRACK v1 Monthly Billing Analysis Data Preparation Guidelines\n\n\nThe CalTRACK Beta test worked primarily with hourly usage data, even for monthly billing analysis, and as a result did not formally test data preparation guidelines for monthly billing analysis. Because of group members\u2019 extensive experience working with monthly billing data, the working group recommends the following processes be followed when preparing monthly consumption, weather, and project data for performing the monthly billing analysis specified in the CalTRACK v1 monthly methods.\n\n\nData Preparation Overview\n\n\nA full accounting of the data cleaning and processing steps that were required for the purposes of the Beta test can be found here. General guidance suggests that data cleaning processes should be well documented and reviewed. There are countless small decisions that must be made as edge cases in the data arise. Thorough documentation ensures that evaluators understand the implications of these choices. Below are guidelines and a general process for addressing the most common issues that arise during data cleaning efforts for monthly billing analysis, based on the experience of the Beta testers doing prior billing analyses as well as lessons learned during the CalTRACK testing process. We recommend doing them in the order they appear because we found through testing that the final combined dataset you end up with is highly sensitive to the order of data preparation steps.\n\n\nThe CalTRACK data preparations guidelines for monthly billing analysis consist of the following steps:\n\n\n\n\nProject data preparation\n\n\nGenerate necessary project fields from raw project data\n\n\nDeal with missing and miscoded values\n\n\nDeduplicate project records\n\n\n\n\n\n\nWeather data preparation\n\n\nMonthly electric and gas use data preparation\n\n\nLink project and electric use files\n\n\nLinked project+electric use data preparation\n\n\nDeduplicate records based on combined attributes\n\n\nDrop observations not meeting data sufficiency requirements\n\n\n\n\n\n\nLink project records and gas use files\n\n\nLinked project+gas use data preparation\n\n\nLink weather data and project records\n\n\nFinal combined data sufficiency checks\n\n\n\n\n1. Project Data Preparation\n\n\nThe minimum field requirements for project data under the CalTRACK monthly specification are outlined here. Notably, a prepared project file should consist of one row per project, with a unique ID that can be used to link to gas and/or electric usage data, project start and stop dates, and zip code for the site. The following data cleaning steps for project data are meant to ensure that the prepared project file meets these field requirements and uniqueness constraints.\n\n\nCreating Work Start and Work End dates from raw project data\n\n\nAccurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, we have observed considerable variation in database records identifying dates associated with project start and project completion.\nIn general, our guidance is to try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), we recommend identifying an average time to completion.\nFor the Beta test data, we worked with the program implementer to find the best proxy for work start and work finish dates. An initial version of the project data required estimation of some dates, but an updated version contained a complete set of work start and stop dates for all of the projects. Specifically, The work start date and work end date fields for projects done before July 1st, 2016 may require using column mappings for proxy fields. For projects started after July 1, 2016, CalTRACK implementations should use official work start date and work end date fields provided by aggregators instead of the proxy fields.\n\n\nDealing with miscoded dates\n\n\nImplausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window\nImplausible month and year values should be flagged and that home not included in estimation.\n\n\nDeduplicate project records\n\n\nIf a home appears multiple times within a project database, and the project dates are the same the most complete record for that home should be used\nIf a home appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.\n\n\n2. Weather Data Preparation\n\n\nFor CalTRACK monthly billing analysis, the weather data requirements are detailed here. For monthly analysis, since the daily average temperature data from a nearby weather station is used to create values for the number of heating degree days (below 60F) and cooling degree days (above 70F) in each billing period, the primary consideration in preparing the data is how to deal with missing values.\n\n\nDealing with missing values\n\n\nWeather data is notoriously incomplete, especially at the granular sub-daily level. Some weather stations generally fail to report data, other weather stations are simply inconsistent in reporting data. This becomes an issue when trying to match projects to their local weather conditions. If a nearby non-reporting weather station is selected, the savings model will fail. If the project is connected to a nearby intermittently reporting weather station, the model will suffer. Additionally, if a project is connected to a weather station that experiences a significantly different local micro-climate, the model will suffer.\n* We recommend that for monthly billing analysis daily average temperature values that are missing not be imputed, but rather count against a site in meeting data sufficiency requirements (detailed at the end of the document).\n\n\n3. Monthly electric and gas use data preparation\n\n\nDealing with missing values in monthly usage data\n\n\nUsage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with \u201cestimated\u201d reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.\n\n For the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the use per day for that period\n\n Missing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements\n\n The working group does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.\n\n If flags exist for estimated values, they are counted as missing and count against the site\u2019s data sufficiency criteria detailed later in this guidance.\n\n\nDealing with extreme values in usage data\n\n\nOccasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels). We offer the following guidance:\n* Negative values for monthly use should be treated as missing and count against sufficiency criterion. Negative values in monthly data may also be a valid sign of possible solar/net metering and should be flagged for verification.\n\n\n4. Link project records and usage files\n\n\nOnce project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. We recommend using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, we do not offer specific guidance.\n* For the purposes of the Beta test, projects were matched to consumption files using a cross reference file supplied by the program administrator.\n\n\nUnmatched data should be excluded from analysis.\n* For the purposes of the Beta test, projects that were unmatched to usage data were listed in CalTRACK for data integrity reporting, but were not included in any estimation procedures and did not have estimated savings.\n\n\n5. Linked project+use data preparation\n\n\nDeduplicate records based on combined attributes\n\n\n\n\nIf two duplicate records have identical consumption traces and date ranges, drop one at random\n\n\nIf two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. * If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.\n\n\nIf the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.\n\n\n\n\nDrop records not meeting data sufficiency requirements\n\n\nCalculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.\n\n 12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months\n\n Post retrofit data sufficiency for estimation will be dealt with in post-estimation model fit criterion\n* Total annual savings estimates will require 12 months post-retrofit\n\n\nDrop project records with unsupported characteristics\n\n\n\n\nDrop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. However, if you only have access to billing data, we recommend working with the utility to get flags for accounts that have net metering present so they can be excluded from the analysis.\n\n\n\n\n6. Link weather data and project records\n\n\nWeather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects\n\n\n\n\nFor the purposes of the Beta test, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files.\n\n\n\n\n7. Final combined data sufficiency checks\n\n\n\n\nBilling periods (the period between bill start date and bill end date in the monthly usage data) with more than 10% missing days of weather data will be thrown out and count against the required number of billing period observations\n\n\nAny projects with fewer than 12 months pre and 12 months post are not included in the analysis",
            "title": "Data Preparation for Monthly Methods"
        },
        {
            "location": "/monthly/data-prep/#caltrack-v1-monthly-billing-analysis-data-preparation-guidelines",
            "text": "The CalTRACK Beta test worked primarily with hourly usage data, even for monthly billing analysis, and as a result did not formally test data preparation guidelines for monthly billing analysis. Because of group members\u2019 extensive experience working with monthly billing data, the working group recommends the following processes be followed when preparing monthly consumption, weather, and project data for performing the monthly billing analysis specified in the CalTRACK v1 monthly methods.",
            "title": "CalTRACK v1 Monthly Billing Analysis Data Preparation Guidelines"
        },
        {
            "location": "/monthly/data-prep/#data-preparation-overview",
            "text": "A full accounting of the data cleaning and processing steps that were required for the purposes of the Beta test can be found here. General guidance suggests that data cleaning processes should be well documented and reviewed. There are countless small decisions that must be made as edge cases in the data arise. Thorough documentation ensures that evaluators understand the implications of these choices. Below are guidelines and a general process for addressing the most common issues that arise during data cleaning efforts for monthly billing analysis, based on the experience of the Beta testers doing prior billing analyses as well as lessons learned during the CalTRACK testing process. We recommend doing them in the order they appear because we found through testing that the final combined dataset you end up with is highly sensitive to the order of data preparation steps.  The CalTRACK data preparations guidelines for monthly billing analysis consist of the following steps:   Project data preparation  Generate necessary project fields from raw project data  Deal with missing and miscoded values  Deduplicate project records    Weather data preparation  Monthly electric and gas use data preparation  Link project and electric use files  Linked project+electric use data preparation  Deduplicate records based on combined attributes  Drop observations not meeting data sufficiency requirements    Link project records and gas use files  Linked project+gas use data preparation  Link weather data and project records  Final combined data sufficiency checks",
            "title": "Data Preparation Overview"
        },
        {
            "location": "/monthly/data-prep/#1-project-data-preparation",
            "text": "The minimum field requirements for project data under the CalTRACK monthly specification are outlined here. Notably, a prepared project file should consist of one row per project, with a unique ID that can be used to link to gas and/or electric usage data, project start and stop dates, and zip code for the site. The following data cleaning steps for project data are meant to ensure that the prepared project file meets these field requirements and uniqueness constraints.",
            "title": "1. Project Data Preparation"
        },
        {
            "location": "/monthly/data-prep/#creating-work-start-and-work-end-dates-from-raw-project-data",
            "text": "Accurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, we have observed considerable variation in database records identifying dates associated with project start and project completion.\nIn general, our guidance is to try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), we recommend identifying an average time to completion.\nFor the Beta test data, we worked with the program implementer to find the best proxy for work start and work finish dates. An initial version of the project data required estimation of some dates, but an updated version contained a complete set of work start and stop dates for all of the projects. Specifically, The work start date and work end date fields for projects done before July 1st, 2016 may require using column mappings for proxy fields. For projects started after July 1, 2016, CalTRACK implementations should use official work start date and work end date fields provided by aggregators instead of the proxy fields.",
            "title": "Creating Work Start and Work End dates from raw project data"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-miscoded-dates",
            "text": "Implausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window\nImplausible month and year values should be flagged and that home not included in estimation.",
            "title": "Dealing with miscoded dates"
        },
        {
            "location": "/monthly/data-prep/#deduplicate-project-records",
            "text": "If a home appears multiple times within a project database, and the project dates are the same the most complete record for that home should be used\nIf a home appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.",
            "title": "Deduplicate project records"
        },
        {
            "location": "/monthly/data-prep/#2-weather-data-preparation",
            "text": "For CalTRACK monthly billing analysis, the weather data requirements are detailed here. For monthly analysis, since the daily average temperature data from a nearby weather station is used to create values for the number of heating degree days (below 60F) and cooling degree days (above 70F) in each billing period, the primary consideration in preparing the data is how to deal with missing values.",
            "title": "2. Weather Data Preparation"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-missing-values",
            "text": "Weather data is notoriously incomplete, especially at the granular sub-daily level. Some weather stations generally fail to report data, other weather stations are simply inconsistent in reporting data. This becomes an issue when trying to match projects to their local weather conditions. If a nearby non-reporting weather station is selected, the savings model will fail. If the project is connected to a nearby intermittently reporting weather station, the model will suffer. Additionally, if a project is connected to a weather station that experiences a significantly different local micro-climate, the model will suffer.\n* We recommend that for monthly billing analysis daily average temperature values that are missing not be imputed, but rather count against a site in meeting data sufficiency requirements (detailed at the end of the document).",
            "title": "Dealing with missing values"
        },
        {
            "location": "/monthly/data-prep/#3-monthly-electric-and-gas-use-data-preparation",
            "text": "",
            "title": "3. Monthly electric and gas use data preparation"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-missing-values-in-monthly-usage-data",
            "text": "Usage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with \u201cestimated\u201d reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.  For the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the use per day for that period  Missing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements  The working group does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.  If flags exist for estimated values, they are counted as missing and count against the site\u2019s data sufficiency criteria detailed later in this guidance.",
            "title": "Dealing with missing values in monthly usage data"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-extreme-values-in-usage-data",
            "text": "Occasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels). We offer the following guidance:\n* Negative values for monthly use should be treated as missing and count against sufficiency criterion. Negative values in monthly data may also be a valid sign of possible solar/net metering and should be flagged for verification.",
            "title": "Dealing with extreme values in usage data"
        },
        {
            "location": "/monthly/data-prep/#4-link-project-records-and-usage-files",
            "text": "Once project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. We recommend using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, we do not offer specific guidance.\n* For the purposes of the Beta test, projects were matched to consumption files using a cross reference file supplied by the program administrator.  Unmatched data should be excluded from analysis.\n* For the purposes of the Beta test, projects that were unmatched to usage data were listed in CalTRACK for data integrity reporting, but were not included in any estimation procedures and did not have estimated savings.",
            "title": "4. Link project records and usage files"
        },
        {
            "location": "/monthly/data-prep/#5-linked-projectuse-data-preparation",
            "text": "",
            "title": "5. Linked project+use data preparation"
        },
        {
            "location": "/monthly/data-prep/#deduplicate-records-based-on-combined-attributes",
            "text": "If two duplicate records have identical consumption traces and date ranges, drop one at random  If two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. * If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.  If the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.",
            "title": "Deduplicate records based on combined attributes"
        },
        {
            "location": "/monthly/data-prep/#drop-records-not-meeting-data-sufficiency-requirements",
            "text": "Calculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.  12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months  Post retrofit data sufficiency for estimation will be dealt with in post-estimation model fit criterion\n* Total annual savings estimates will require 12 months post-retrofit",
            "title": "Drop records not meeting data sufficiency requirements"
        },
        {
            "location": "/monthly/data-prep/#drop-project-records-with-unsupported-characteristics",
            "text": "Drop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. However, if you only have access to billing data, we recommend working with the utility to get flags for accounts that have net metering present so they can be excluded from the analysis.",
            "title": "Drop project records with unsupported characteristics"
        },
        {
            "location": "/monthly/data-prep/#6-link-weather-data-and-project-records",
            "text": "Weather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects   For the purposes of the Beta test, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files.",
            "title": "6. Link weather data and project records"
        },
        {
            "location": "/monthly/data-prep/#7-final-combined-data-sufficiency-checks",
            "text": "Billing periods (the period between bill start date and bill end date in the monthly usage data) with more than 10% missing days of weather data will be thrown out and count against the required number of billing period observations  Any projects with fewer than 12 months pre and 12 months post are not included in the analysis",
            "title": "7. Final combined data sufficiency checks"
        },
        {
            "location": "/monthly/analysis/",
            "text": "CalTRACK Site-level Monthly Gross Savings Estimation Technical Guideline\n\n\n\n\nMethodological Overview\n\n\nSite-level gross savings using monthly billing data (both electricity and gas) will use a two-stage estimation approach that closely follows methodological recommendations in the technical appendices of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, with some modifications and more specific guidance developed through empirical testing to ensure consistency and replicability of results.\n\n\nThe idea behind two-stage site-level models is to model the energy use of each house before and after\n\n\nMore formally, the two-stage approach first fits \ntwo\n separate parametric models to daily average energy use, one on the pre-intervention (baseline) period and one on the post-intervention (reporting) period for a single site using an ordinary least squares regression of the general form:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\nWhere\n\n\n\n\nUPD_{mi}\n is average use (gas in therms, electricity in kWh) per day during billing period \nm\n for site \ni\n.\n\n\n\n\n\\mu_i\n is the mean use for site \ni\n, or intercept.\n\n\n\n\n\\beta_{Hi}\n is the coefficient site \ni\n on average heating degree days per day.\n\n\n\n\n\\beta_{Ci}\n is the coefficient or site \ni\n on average cooling degree days per day.\n\n\n\n\nH_m\n is the average number of heating degree days per day in billing period \nm\n, which is a function of a fixed base temperature, the average daily temperatures from the weather station matched to site \ni\n during the billing period \nm\n, and the number of days in billing period \nm\n with matched usage and weather data for site \ni\n.\n\n\n\n\nC_m\n is the average number of cooling degree days per day in month \nm\n, which is a function of a selected base temperature, the average daily temperatures from the weather station matched to site \ni\n during month \nm\n, and the number of days in month \nm\n with matched usage and weather data for site \ni\n.\n\n\n\n\n\\epsilon_{mi}\n is the site specific error term for a given month.\n\n\nIn the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized gross savings), or by using current-year weather to project forward baseline period use (current year weather normalized gross savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.\n\n\nThis site-level two-stage approach without the use of a comparison group, while having significant limitations and tradeoffs, was decided by the technical working group to be appropriate for the two main use cases for CalTRACK, which emphasize effects on the grid and feedback to software vendors, rather than causal programatic effects. In addition to its long history of use in the EM&V literature, it draws on a methodological foundation developed in the more general literature on piecewise linear regression or segmented regression for policy analysis and effect estimates that is used in fields as divers as public health, medical research, and econometrics.\n\n\nWe now proceed with a detailed technical treatment of the steps for monthly savings estimation.\n\n\nTechnical guidelines for implementing two-stage estimation on monthly electric and gas usage data for CalTRACK\n\n\nCalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Cleaning and Integration technical specification. Starting with the prepared data, site-level monthly gross savings analysis is performed by implementing the following steps:\n\n\n1. Generate Use Per Day values and separate usage data into a pre- and a post-intervention data series\n\n\nThe CalTRACK monthly gross savings analysis uses average use per day (\nUPD\n) values for each month by taking the bill-period usage values, then dividing by the number of days in that bill period, as follows:\n\n\n\n\nUPD_m = \\frac{1}{n_{U_d}} * \\sum{U_d}\n\n\n\n\nWhere\n\n\n\n\nUPD_m\n is the average use per day for a given month \nm\n\n\n\n\n\\sum{U_d}\n is the sum of all daily use values \nU_d\n for a given month `m\u2019\n\n\n\n\nn_{U_d}\n is the total number of daily use values provided in the usage series that are between the first calendar day of month \nm\n and the last calendar day of month \nm\n\n\nNote: If daily use data for gas or electric is not available, monthly billing data can be used for the monthly billing analysis. However, modifications of the denominators for average use per day and for average HDD and CDD per day are necessary.\n\n\nNow split the series of \nUPD_m\n values into pre- and post-intervention periods according to the following rules:\n\n\nPre-intervention period\n: all \nUPD_m\n values from the beginning of the series up to the the complete billing month prior to the \nwork_start_date\n. The month containing \nwork_start_date\n is excluded from this series.\n\n\nPost-intervention period\n: all \nUPD_m\n values from the first billing month after the \nwork_end_date\n to the end of the series.\n\n\nFinal data sufficiency qualification check\n: All qualifying sites must have at least 12 months of contiguous $UPD_m$ values in the pre-intervention series and at least 12 months of contiguous post-intervention \nUPD_m\n values starting with the month after \nwork_end_date\n.\n\n\nAll sites not meeting these minimum data requirements are thrown out of the analysis\n\n\n2. Set fixed degree day base temperature and calculated HDD and CDD\n\n\nNext you calculate total HDD and CDD for the each billing period in the series. CalTRACK will use a fixed degree day base for monthly billing analysis. The following balance point temperatures will be use:\n\n\nHDD base temp: 60 F\n\n\nCDD base temp: 70 F\n\n\nHDD and CDD values are calculated as follows\n\n\n\n\nHDD_m = \\frac{1}{n_{U_d}} * \\sum{ \\max(60 - T_{ave}, 0) }\n\n\n\n\nWhere\n\n\n\n\nHDD_m\n = Average heating degree days per day for billing period \nm\n\n\n\n\nn_{U_d}\n = the number of days with both weather and usage data\n\n\n\n\n\\sum\n = the sum of the degree  over each day \nd\n in billing period \nm\n\n\n\n\n\\max\n = the maximum of the two values in ()\n\n\n\n\nT_{ave}\n = the average temperature for day \nd\n\n\nAnd\n\n\n\n\nCDD_m = \\frac{1}{n_{U_d}} * \\sum{ max(ave_temp_d - 70, 0) }\n\n\n\n\nWhere\n\n\n\n\nCDD_m\n = Cooling degree days for billing period \nm\n\n\n\n\nn_{U_d}\n = the number of days with both weather and usage data\n\n\n\n\n\\sum\n = the sum of values in {} over each day \nd\n in billing period \nm\n\n\n\n\n\\max\n = the maximum of the two values in ()\n\n\n\n\nT_{ave}\n = the average temperature for day \nd\n\n\nDaily average temperatures are taken from the GSOD average data temperature dataset provided by NOAA\n\n\n3. Fit All Candidate Models and Apply Qualification Criteria\n\n\nFor each site, all allowable models will be run as candidate models and then have minimum fitness criteria set for qualification.\n\n\nFor CalTRACK electric monthly savings analysis, the following candidate models are fit:\n\n\n\n\n UPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\n\n\n UPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi} \n\n\n\n\n\n\n UPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\n\n\n UPD_{mi} = \\mu_i + \\epsilon_{mi} \n\n\n\n\nwith the constraints\n\n\n\n\n\\beta_{H} > 0\n\n\n\n\n\n\n\\beta_{C} > 0\n\n\n\n\n\n\n\\mu_i > 0\n\n\n\n\nFor electric, qualifying models for selection must have each parameter estimate meet the minimum significance criteria of $p < 0.1$ and are strictly positive. All qualifying models are considered for final model selection.\n\n\nFor CalTRACK gas monthly savings analysis, the following candidate models are fit:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi} \n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\epsilon_{mi} \n\n\n\n\nwith the constraints\n\n\n\n\n\\beta_{H} > 0\n\n\n\n\n\n\n\\mu_i > 0\n\n\n\n\nIf each parameter estimate meets minimum significance criteria (p < 0.1) and are strictly positive, then the model is a qualifying model for inclusion in model selection.\n\n\n4. Select the best for pre-intervenion and post-intervention periods for use in second-stage savings estimation\n\n\nAll qualifying pre-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.\n\n\nFor the monthly billing analysis, because we are using fixed degree days instead of variable degree days, adjusted R-squared will be defined as\n\n\n\n\n adjR^2 = 1 - \\frac{SS_{res}/df_e}{SS_{tot}/df_t} \n\n\n\n\nWhere\n\n\n\n\n SS_{res} \n is the sum of squares of residuals\n\n\n\n\n df_e \n is the degrees of freedom of the estimate of the underlying population error variance, and is calculated using \nn-p-1\n, where \nn\n is the number of observations in the sample used to estimate the model and \np\n is the number of explanatory variables, not including the constant term and not including degree day base temperature as a parameter because it\u2019s fixed\n\n\n\n\n SS_{tot} \n is the total sum of squares\n\n\n\n\n df_t \n is the degrees of freedom of the estimate of the population variance of the dependent variable, and is calculated as \nn-1\n, were \nn\n is the size of the sample use to estimate the model\n\n\nAll qualifying post-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.\n\n\n5. Estimate second-stage gross savings quantities based on selected first stage pre- and post-intervention models\n\n\nDuring the second stage, up to five savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.\n\n\nCumulative gross savings over entire performance period\nYear one annualized actual gross savings in the the reporting (post-intervention) period\nYear two annualized actual gross savings in the the reporting (post-intervention) period\nYear one annualized gross savings in the normal year\nYear two annualized gross savings in the normal year\n\n\nThese site-level second stage quantities are calculated as follows:\n\n\nCumulative gross savings over entire performance period (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period after \nwork_end_date\n using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for every complete billing periods after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over every complete billing period since \nwork_end_date\n.\n\n\n\n\nYear one gross savings from 1 to 12 months after site visit. (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period after \nwork_end_date\n until 12 billing periods after \nwork_end_date\n  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for 12 complete billing periods after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over the 12 billing periods since \nwork_end_date\n.\n\n\n\n\nYear two gross savings from 13 to 24 months after site visit. (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period starting 13 months after \nwork_end_date\n until 24 billing periods after \nwork_end_date\n  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for month 13 to month 24 after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over the 12 billing periods from 13 months after \nwork_end_date\n to 24 months.\n\n\n\n\nYear one site-level annualized gross savings in the normal year\n\n\n\n\nCompute \npredicted_baseline_monthly_use\n using the stage one model from the baseline period and average degree days from the CZ2010 normal weather year. Use the full month of available values when calculating the average degree days per billing period for the normal year.\n\n\nCompute \npredicted_reporting_monthly_use\n using a \nstage one\n model fit to only the first 12 months of post-intervention values and degree days from the CZ2010 normal weather year file. Use the full month of available values when calculating the average degree days per billing period for the normal year.\n\n\nCompute \nmonthly_normal_year_gross_savings\n = \npredicted_baseline_monthly_use - predicted_reporting_monthly_use\n for normal year months\n\n\nSum  \nmonthly_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nYear two site-level annualized gross savings in the normal year\n\n\n\n\nCompute \npredicted_baseline_monthly_use\n using the stage one model from the baseline period and degree days from the CZ2010 normal weather year.\n\n\nCompute \npredicted_reporting_monthly_use\n using a \nstage one\n model fit to only the 13th-24th months of post-intervention values and degree days from the CZ2010 normal weather year file for the relevant months.\n\n\nCompute \nmonthly_normal_year_gross_savings\n = \npredicted_baseline_monthly_use - predicted_reporting_monthly_use\n for each normal year month.\n\n\nSum  \nmonthly_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nPost-estimation steps and portfolio aggregation\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over \nportfolios of homes\n. In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified \nhere\n.",
            "title": "Analysis of Monthly Data"
        },
        {
            "location": "/monthly/analysis/#caltrack-site-level-monthly-gross-savings-estimation-technical-guideline",
            "text": "",
            "title": "CalTRACK Site-level Monthly Gross Savings Estimation Technical Guideline"
        },
        {
            "location": "/monthly/analysis/#methodological-overview",
            "text": "Site-level gross savings using monthly billing data (both electricity and gas) will use a two-stage estimation approach that closely follows methodological recommendations in the technical appendices of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, with some modifications and more specific guidance developed through empirical testing to ensure consistency and replicability of results.  The idea behind two-stage site-level models is to model the energy use of each house before and after  More formally, the two-stage approach first fits  two  separate parametric models to daily average energy use, one on the pre-intervention (baseline) period and one on the post-intervention (reporting) period for a single site using an ordinary least squares regression of the general form:   UPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi}    Where   UPD_{mi}  is average use (gas in therms, electricity in kWh) per day during billing period  m  for site  i .   \\mu_i  is the mean use for site  i , or intercept.   \\beta_{Hi}  is the coefficient site  i  on average heating degree days per day.   \\beta_{Ci}  is the coefficient or site  i  on average cooling degree days per day.   H_m  is the average number of heating degree days per day in billing period  m , which is a function of a fixed base temperature, the average daily temperatures from the weather station matched to site  i  during the billing period  m , and the number of days in billing period  m  with matched usage and weather data for site  i .   C_m  is the average number of cooling degree days per day in month  m , which is a function of a selected base temperature, the average daily temperatures from the weather station matched to site  i  during month  m , and the number of days in month  m  with matched usage and weather data for site  i .   \\epsilon_{mi}  is the site specific error term for a given month.  In the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized gross savings), or by using current-year weather to project forward baseline period use (current year weather normalized gross savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.  This site-level two-stage approach without the use of a comparison group, while having significant limitations and tradeoffs, was decided by the technical working group to be appropriate for the two main use cases for CalTRACK, which emphasize effects on the grid and feedback to software vendors, rather than causal programatic effects. In addition to its long history of use in the EM&V literature, it draws on a methodological foundation developed in the more general literature on piecewise linear regression or segmented regression for policy analysis and effect estimates that is used in fields as divers as public health, medical research, and econometrics.  We now proceed with a detailed technical treatment of the steps for monthly savings estimation.",
            "title": "Methodological Overview"
        },
        {
            "location": "/monthly/analysis/#technical-guidelines-for-implementing-two-stage-estimation-on-monthly-electric-and-gas-usage-data-for-caltrack",
            "text": "CalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Cleaning and Integration technical specification. Starting with the prepared data, site-level monthly gross savings analysis is performed by implementing the following steps:",
            "title": "Technical guidelines for implementing two-stage estimation on monthly electric and gas usage data for CalTRACK"
        },
        {
            "location": "/monthly/analysis/#1-generate-use-per-day-values-and-separate-usage-data-into-a-pre-and-a-post-intervention-data-series",
            "text": "The CalTRACK monthly gross savings analysis uses average use per day ( UPD ) values for each month by taking the bill-period usage values, then dividing by the number of days in that bill period, as follows:   UPD_m = \\frac{1}{n_{U_d}} * \\sum{U_d}   Where   UPD_m  is the average use per day for a given month  m   \\sum{U_d}  is the sum of all daily use values  U_d  for a given month `m\u2019   n_{U_d}  is the total number of daily use values provided in the usage series that are between the first calendar day of month  m  and the last calendar day of month  m  Note: If daily use data for gas or electric is not available, monthly billing data can be used for the monthly billing analysis. However, modifications of the denominators for average use per day and for average HDD and CDD per day are necessary.  Now split the series of  UPD_m  values into pre- and post-intervention periods according to the following rules:  Pre-intervention period : all  UPD_m  values from the beginning of the series up to the the complete billing month prior to the  work_start_date . The month containing  work_start_date  is excluded from this series.  Post-intervention period : all  UPD_m  values from the first billing month after the  work_end_date  to the end of the series.  Final data sufficiency qualification check : All qualifying sites must have at least 12 months of contiguous $UPD_m$ values in the pre-intervention series and at least 12 months of contiguous post-intervention  UPD_m  values starting with the month after  work_end_date .  All sites not meeting these minimum data requirements are thrown out of the analysis",
            "title": "1. Generate Use Per Day values and separate usage data into a pre- and a post-intervention data series"
        },
        {
            "location": "/monthly/analysis/#2-set-fixed-degree-day-base-temperature-and-calculated-hdd-and-cdd",
            "text": "Next you calculate total HDD and CDD for the each billing period in the series. CalTRACK will use a fixed degree day base for monthly billing analysis. The following balance point temperatures will be use:  HDD base temp: 60 F  CDD base temp: 70 F  HDD and CDD values are calculated as follows   HDD_m = \\frac{1}{n_{U_d}} * \\sum{ \\max(60 - T_{ave}, 0) }   Where   HDD_m  = Average heating degree days per day for billing period  m   n_{U_d}  = the number of days with both weather and usage data   \\sum  = the sum of the degree  over each day  d  in billing period  m   \\max  = the maximum of the two values in ()   T_{ave}  = the average temperature for day  d  And   CDD_m = \\frac{1}{n_{U_d}} * \\sum{ max(ave_temp_d - 70, 0) }   Where   CDD_m  = Cooling degree days for billing period  m   n_{U_d}  = the number of days with both weather and usage data   \\sum  = the sum of values in {} over each day  d  in billing period  m   \\max  = the maximum of the two values in ()   T_{ave}  = the average temperature for day  d  Daily average temperatures are taken from the GSOD average data temperature dataset provided by NOAA",
            "title": "2. Set fixed degree day base temperature and calculated HDD and CDD"
        },
        {
            "location": "/monthly/analysis/#3-fit-all-candidate-models-and-apply-qualification-criteria",
            "text": "For each site, all allowable models will be run as candidate models and then have minimum fitness criteria set for qualification.  For CalTRACK electric monthly savings analysis, the following candidate models are fit:    UPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi}      UPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi}      UPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi}      UPD_{mi} = \\mu_i + \\epsilon_{mi}    with the constraints   \\beta_{H} > 0    \\beta_{C} > 0    \\mu_i > 0   For electric, qualifying models for selection must have each parameter estimate meet the minimum significance criteria of $p < 0.1$ and are strictly positive. All qualifying models are considered for final model selection.  For CalTRACK gas monthly savings analysis, the following candidate models are fit:   UPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi}     UPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi}     UPD_{mi} = \\mu_i + \\epsilon_{mi}    with the constraints   \\beta_{H} > 0    \\mu_i > 0   If each parameter estimate meets minimum significance criteria (p < 0.1) and are strictly positive, then the model is a qualifying model for inclusion in model selection.",
            "title": "3. Fit All Candidate Models and Apply Qualification Criteria"
        },
        {
            "location": "/monthly/analysis/#4-select-the-best-for-pre-intervenion-and-post-intervention-periods-for-use-in-second-stage-savings-estimation",
            "text": "All qualifying pre-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.  For the monthly billing analysis, because we are using fixed degree days instead of variable degree days, adjusted R-squared will be defined as    adjR^2 = 1 - \\frac{SS_{res}/df_e}{SS_{tot}/df_t}    Where    SS_{res}   is the sum of squares of residuals    df_e   is the degrees of freedom of the estimate of the underlying population error variance, and is calculated using  n-p-1 , where  n  is the number of observations in the sample used to estimate the model and  p  is the number of explanatory variables, not including the constant term and not including degree day base temperature as a parameter because it\u2019s fixed    SS_{tot}   is the total sum of squares    df_t   is the degrees of freedom of the estimate of the population variance of the dependent variable, and is calculated as  n-1 , were  n  is the size of the sample use to estimate the model  All qualifying post-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.",
            "title": "4. Select the best for pre-intervenion and post-intervention periods for use in second-stage savings estimation"
        },
        {
            "location": "/monthly/analysis/#5-estimate-second-stage-gross-savings-quantities-based-on-selected-first-stage-pre-and-post-intervention-models",
            "text": "During the second stage, up to five savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.  Cumulative gross savings over entire performance period\nYear one annualized actual gross savings in the the reporting (post-intervention) period\nYear two annualized actual gross savings in the the reporting (post-intervention) period\nYear one annualized gross savings in the normal year\nYear two annualized gross savings in the normal year  These site-level second stage quantities are calculated as follows:",
            "title": "5. Estimate second-stage gross savings quantities based on selected first stage pre- and post-intervention models"
        },
        {
            "location": "/monthly/analysis/#cumulative-gross-savings-over-entire-performance-period-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period after  work_end_date  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for every complete billing periods after  work_end_date  for project  Sum   monthly_gross_savings  over every complete billing period since  work_end_date .",
            "title": "Cumulative gross savings over entire performance period (site-level)"
        },
        {
            "location": "/monthly/analysis/#year-one-gross-savings-from-1-to-12-months-after-site-visit-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period after  work_end_date  until 12 billing periods after  work_end_date   using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for 12 complete billing periods after  work_end_date  for project  Sum   monthly_gross_savings  over the 12 billing periods since  work_end_date .",
            "title": "Year one gross savings from 1 to 12 months after site visit. (site-level)"
        },
        {
            "location": "/monthly/analysis/#year-two-gross-savings-from-13-to-24-months-after-site-visit-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period starting 13 months after  work_end_date  until 24 billing periods after  work_end_date   using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for month 13 to month 24 after  work_end_date  for project  Sum   monthly_gross_savings  over the 12 billing periods from 13 months after  work_end_date  to 24 months.",
            "title": "Year two gross savings from 13 to 24 months after site visit. (site-level)"
        },
        {
            "location": "/monthly/analysis/#year-one-site-level-annualized-gross-savings-in-the-normal-year",
            "text": "Compute  predicted_baseline_monthly_use  using the stage one model from the baseline period and average degree days from the CZ2010 normal weather year. Use the full month of available values when calculating the average degree days per billing period for the normal year.  Compute  predicted_reporting_monthly_use  using a  stage one  model fit to only the first 12 months of post-intervention values and degree days from the CZ2010 normal weather year file. Use the full month of available values when calculating the average degree days per billing period for the normal year.  Compute  monthly_normal_year_gross_savings  =  predicted_baseline_monthly_use - predicted_reporting_monthly_use  for normal year months  Sum   monthly_normal_year_gross_savings  over entire normal year.",
            "title": "Year one site-level annualized gross savings in the normal year"
        },
        {
            "location": "/monthly/analysis/#year-two-site-level-annualized-gross-savings-in-the-normal-year",
            "text": "Compute  predicted_baseline_monthly_use  using the stage one model from the baseline period and degree days from the CZ2010 normal weather year.  Compute  predicted_reporting_monthly_use  using a  stage one  model fit to only the 13th-24th months of post-intervention values and degree days from the CZ2010 normal weather year file for the relevant months.  Compute  monthly_normal_year_gross_savings  =  predicted_baseline_monthly_use - predicted_reporting_monthly_use  for each normal year month.  Sum   monthly_normal_year_gross_savings  over entire normal year.",
            "title": "Year two site-level annualized gross savings in the normal year"
        },
        {
            "location": "/monthly/analysis/#post-estimation-steps-and-portfolio-aggregation",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over  portfolios of homes . In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified  here .",
            "title": "Post-estimation steps and portfolio aggregation"
        },
        {
            "location": "/monthly/aggregation/",
            "text": "Technical Specification for Aggregating Site-level Gross Savings and Quantifying Uncertainty in Aggregate Savings Statistics\n\n\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over \nportfolios of homes\n.\n\n\nPortfolio-level savings statistics are based on aggregations of site-level savings gross savings estimates created using the CalTRACK site-level monthly gross savings analysis methods.\n\n\nBecause all site-level savings quantities generated using CalTRACK's technical specifications are based on time series predictions, portfolio-level savings statistics primarily use prediction errors to estimate of site-level uncertainty, and calculate portfolio-level averages using inverse variance weighted means to get a consistent estimator of mean portfolio-level savings.\n\n\nMonthly Savings Estimate Aggregation Procedure\n\n\nThe main portfolio-level statistics of interest for CalTRACK are:\n\n\n\n\nWeighted mean annualized gross savings\n\n\nVariance annualized gross savings\n\n\nAnnualized gross savings prediction intervals (+/- 95%)\n\n\nUnweighted total annualized gross savings\n\n\nWeighted mean cumulative gross savings\n\n\nCumulative gross savings prediction intervals (+/-95%)\n\n\nUnweighted total cumulative gross savings\n\n\nWeighted mean year-one gross savings\n\n\nYear-one gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-one gross savings\n\n\nWeighted mean year-two gross savings\n\n\nYear-two gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-two gross savings\n\n\n\n\nSteps for calculating aggregate uncertainty and aggregate means.\n\n\nWhile a detailed treatment of how to calculate each of these quantities is included below, the main formulations are below:\n\n\n\n\nCalculate the site-level Mean Squared Error (MSE) as an unbias estimator of the variance of the model errors, $s^2$ :\n\n\n\n\n\n\ns^2 = \\sum{\\frac{\\hat{u}_i^2}{N\u2212k}}\n\n\n\n\n\n\nCalculate the site-level savings variance using in prediction error as an consistent estimator using the MSE, $s^2$, and variance in the out-of-sample data, $x_0$:\n\n\n\n\n\n\n\\hat{V}_s = s^2*x_0*(X'X)^{\u22121} * x_0' + s^2\n\n\n\n\n\n\nCalculate portfolio site-level inverse variance weighted mean savings using the savings variance and the following equation:\n\n\n\n\n\n\nPrepared Summary Statistics for Aggregation Comparison\n\n\nTo ensure that the CalTRACK analysis specification can produce consistent results, each beta tester will generate a set of aggregate statistics on each of the above site-level savings estimates that can be shared with the larger group through csvs saved to this repository.\n\n\nThere will be one savings summary file generated by each Beta Tester. Each file will be a .csv and will have the following general format:\n\n\n\n\n\n\n\n\nSummary Stat\n\n\nValue\n\n\n\n\n\n\n\n\n\n\nNumber of sites included in aggregation\n\n\n4321\n\n\n\n\n\n\nIVW mean annualized gross savings\n\n\n123\n\n\n\n\n\n\nPorfolio forecast variance\n\n\n4156\n\n\n\n\n\n\n\n\nCombined Project Data Summary File\n\n\nOutput Filename: \nmonthly_billing_analysis_savings_portfolio_aggregation_NAME_OF_TESTER.csv\n\n\nIncluded Summary statistics for Portfolios of Sites\n\n\n\n\nWeighted mean annualized gross savings\n\n\nVariance annualized gross savings\n\n\nAnnualized gross savings prediction intervals (+/- 95%)\n\n\nUnweighted total annualized gross savings\n\n\nWeighted mean cumulative gross savings\n\n\nCumulative gross savings prediction intervals (+/-95%)\n\n\nUnweighted total cumulative gross savings\n\n\nWeighted mean year-one gross savings\n\n\nYear-one gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-one gross savings\n\n\nWeighted mean year-two gross savings\n\n\nYear-two gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-two gross savings\n\n\n\n\nCalculating site-level prediction intervals\n\n\nFor simplicity, and keeping with convention in the industry, site-level variance estimates based on ordinary least squares regressions will use OLS prediction error as the estimator for savings variance. Prediction error is calculated as follows:\n\n\nTake the stage one regression model with N observations and k regressors:\n\n\n\n\ny = X\\beta + u\n\n\n\n\nGiven a vector (or matrix) $x_0$ of post-intervention (reporting) period degree day covariates, the predicted value for  observation would be\n\n\n\n\nE[y|x_0] = \\hat{y}_0 = x_0\\beta\n\n\n\n\nA consistent estimator of the variance of this prediction is\n\n\n\n\n\\hat{V}_p = s^2*x_0*(X'X)^{\u22121} * x_0\n\n\n\n\nwhere\n\n\n\n\ns^2 = \\sum{\\frac{\\hat{u}_i^2}{(N-k)}}\n\n\n\n\nand \nX\n is the matrix of stage one covariates.\n\n\nThe forecast error for a particular $y_0$ is\n\n\n\n\n\\hat{e} = y_0 \u2212 \\hat{y}_0= x_0\\beta + u_0 \u2212 \\hat{y}_0\n\n\n\n\nThe zero covariance between $u_0$ and $\\hat{\u03b2}$ implies that\n\n\n\n\nVar[\\hat{e}] = Var[\\hat{y}_0] + Var[u_0]\n\n\n\n\nand a consistent estimator of that is\n\n\n\n\n\\hat{V}_s=s^2*x_0*(X'X)^{\u22121} * x_0' + s^2\n\n\n\n\nThe \n1\u2212\\alpha\n site-level confidence interval will be:\n\n\n\n\ny_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_p)^.5\n\n\n\n\nThe \n1\u2212\u03b1\n confidence interval on the savings will be wider, based on the estimated savings variance:\n\n\n\n\ny_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_s)^.5\n\n\n\n\nCalculating Inverse-variance Weighted Portfolio Savings Means for Monthly Savings Analysis\n\n\nUsing site-level forecast variance as the consistent estimator of site-level gross savings estimation, CalTRACK will calculate the inverse-variance weighted mean for each portfolio according to the following equation:\n\n\n\n\n\\hat{y} = \\frac{\\sum_i{y_i/ \\sigma_i^2}}{\\sum_i{1/ \\sigma^2_i}}\n\n\n\n\nCalculating uncertainty for daily and hourly methods\n\n\nWhile sampling methods would actually be preferable for characterizing the posterior distribution of savings estimates using higher-frequency AMI data, due to lack of adoption of Bayesian methods in industry and increased computational complexity, we propose CalTRACK use more frequently adopted.\n\n\nThe two primary considerations for higher-frequency savings models are the need to take into account stronger autocorrelation and increased model specification error.\n\n\nM & V standards for industrial savings estimation, which has been dealing with AMI data longer, provides useful guidance for dealing with these two considerations. Following ASHRAE Guideline 14-2002, and augmenting work done by the NW SEM Collaborative, we propose the following method:\n\n\nFractional Savings uncertainty calculation\n\n\nBecause variances are larger in larger homes, normalizing levels of uncertainty using fractional savings uncertainty is an important aggregate metric, both for model comparison and selection, as well as final output. CalTRACK will compute the Fractional Savings Uncertainty at the site level based on the following equation:\n\n\n\n\nWhere\n\n\n$CV$ is the coefficient of variance on the savings mean using prediction errors specified above\n$t$ is the relevant t-statistic for the desired level of confidence\n$F$ is the relevant F-statistic given degrees of freedom for the selected model\n\n\nCalculating 95% confidence intervals using fractional savings uncertainty\n\n\nTo calculate confidence intervals using the following equation:\n\n\n\n\nCI(95) = +/- (FSU * 1.96) * 100\n\n\n\n\nNote on the lack of comparison group adjustments in CalTRACK technical specification\n\n\nWhile the technical working group acknowledged the potential use of comparison groups in gross savings estimation to correct for population-wide exogenous effects on use, after extensive debate, it was decided that the CalTRACK use cases (pay-for-performance in particular) required the ability for non-utility actors to be able to estimate savings without access to comparison group data. While several promising ideas were developed through the technical working group process about how to address this issue (utilities publishing public adjustment factors based on pre-tabilated comparison groups for example), there were serious concern about feasbility in time for early 2017 roll out of the P4P pilot. As a result, the issue of transparent and replicable comparison group adjustments as part of CalTRACK methods was left for the next version of CalTRACK technical specifications.",
            "title": "Aggregration of Site-level Savings"
        },
        {
            "location": "/monthly/aggregation/#technical-specification-for-aggregating-site-level-gross-savings-and-quantifying-uncertainty-in-aggregate-savings-statistics",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over  portfolios of homes .  Portfolio-level savings statistics are based on aggregations of site-level savings gross savings estimates created using the CalTRACK site-level monthly gross savings analysis methods.  Because all site-level savings quantities generated using CalTRACK's technical specifications are based on time series predictions, portfolio-level savings statistics primarily use prediction errors to estimate of site-level uncertainty, and calculate portfolio-level averages using inverse variance weighted means to get a consistent estimator of mean portfolio-level savings.",
            "title": "Technical Specification for Aggregating Site-level Gross Savings and Quantifying Uncertainty in Aggregate Savings Statistics"
        },
        {
            "location": "/monthly/aggregation/#monthly-savings-estimate-aggregation-procedure",
            "text": "The main portfolio-level statistics of interest for CalTRACK are:   Weighted mean annualized gross savings  Variance annualized gross savings  Annualized gross savings prediction intervals (+/- 95%)  Unweighted total annualized gross savings  Weighted mean cumulative gross savings  Cumulative gross savings prediction intervals (+/-95%)  Unweighted total cumulative gross savings  Weighted mean year-one gross savings  Year-one gross savings prediction intervals (+/-95%)  Unweighted total year-one gross savings  Weighted mean year-two gross savings  Year-two gross savings prediction intervals (+/-95%)  Unweighted total year-two gross savings",
            "title": "Monthly Savings Estimate Aggregation Procedure"
        },
        {
            "location": "/monthly/aggregation/#steps-for-calculating-aggregate-uncertainty-and-aggregate-means",
            "text": "While a detailed treatment of how to calculate each of these quantities is included below, the main formulations are below:   Calculate the site-level Mean Squared Error (MSE) as an unbias estimator of the variance of the model errors, $s^2$ :    s^2 = \\sum{\\frac{\\hat{u}_i^2}{N\u2212k}}    Calculate the site-level savings variance using in prediction error as an consistent estimator using the MSE, $s^2$, and variance in the out-of-sample data, $x_0$:    \\hat{V}_s = s^2*x_0*(X'X)^{\u22121} * x_0' + s^2    Calculate portfolio site-level inverse variance weighted mean savings using the savings variance and the following equation:",
            "title": "Steps for calculating aggregate uncertainty and aggregate means."
        },
        {
            "location": "/monthly/aggregation/#prepared-summary-statistics-for-aggregation-comparison",
            "text": "To ensure that the CalTRACK analysis specification can produce consistent results, each beta tester will generate a set of aggregate statistics on each of the above site-level savings estimates that can be shared with the larger group through csvs saved to this repository.  There will be one savings summary file generated by each Beta Tester. Each file will be a .csv and will have the following general format:     Summary Stat  Value      Number of sites included in aggregation  4321    IVW mean annualized gross savings  123    Porfolio forecast variance  4156",
            "title": "Prepared Summary Statistics for Aggregation Comparison"
        },
        {
            "location": "/monthly/aggregation/#combined-project-data-summary-file",
            "text": "Output Filename:  monthly_billing_analysis_savings_portfolio_aggregation_NAME_OF_TESTER.csv",
            "title": "Combined Project Data Summary File"
        },
        {
            "location": "/monthly/aggregation/#included-summary-statistics-for-portfolios-of-sites",
            "text": "Weighted mean annualized gross savings  Variance annualized gross savings  Annualized gross savings prediction intervals (+/- 95%)  Unweighted total annualized gross savings  Weighted mean cumulative gross savings  Cumulative gross savings prediction intervals (+/-95%)  Unweighted total cumulative gross savings  Weighted mean year-one gross savings  Year-one gross savings prediction intervals (+/-95%)  Unweighted total year-one gross savings  Weighted mean year-two gross savings  Year-two gross savings prediction intervals (+/-95%)  Unweighted total year-two gross savings",
            "title": "Included Summary statistics for Portfolios of Sites"
        },
        {
            "location": "/monthly/aggregation/#calculating-site-level-prediction-intervals",
            "text": "For simplicity, and keeping with convention in the industry, site-level variance estimates based on ordinary least squares regressions will use OLS prediction error as the estimator for savings variance. Prediction error is calculated as follows:  Take the stage one regression model with N observations and k regressors:   y = X\\beta + u   Given a vector (or matrix) $x_0$ of post-intervention (reporting) period degree day covariates, the predicted value for  observation would be   E[y|x_0] = \\hat{y}_0 = x_0\\beta   A consistent estimator of the variance of this prediction is   \\hat{V}_p = s^2*x_0*(X'X)^{\u22121} * x_0   where   s^2 = \\sum{\\frac{\\hat{u}_i^2}{(N-k)}}   and  X  is the matrix of stage one covariates.  The forecast error for a particular $y_0$ is   \\hat{e} = y_0 \u2212 \\hat{y}_0= x_0\\beta + u_0 \u2212 \\hat{y}_0   The zero covariance between $u_0$ and $\\hat{\u03b2}$ implies that   Var[\\hat{e}] = Var[\\hat{y}_0] + Var[u_0]   and a consistent estimator of that is   \\hat{V}_s=s^2*x_0*(X'X)^{\u22121} * x_0' + s^2   The  1\u2212\\alpha  site-level confidence interval will be:   y_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_p)^.5   The  1\u2212\u03b1  confidence interval on the savings will be wider, based on the estimated savings variance:   y_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_s)^.5",
            "title": "Calculating site-level prediction intervals"
        },
        {
            "location": "/monthly/aggregation/#calculating-inverse-variance-weighted-portfolio-savings-means-for-monthly-savings-analysis",
            "text": "Using site-level forecast variance as the consistent estimator of site-level gross savings estimation, CalTRACK will calculate the inverse-variance weighted mean for each portfolio according to the following equation:   \\hat{y} = \\frac{\\sum_i{y_i/ \\sigma_i^2}}{\\sum_i{1/ \\sigma^2_i}}",
            "title": "Calculating Inverse-variance Weighted Portfolio Savings Means for Monthly Savings Analysis"
        },
        {
            "location": "/monthly/aggregation/#calculating-uncertainty-for-daily-and-hourly-methods",
            "text": "While sampling methods would actually be preferable for characterizing the posterior distribution of savings estimates using higher-frequency AMI data, due to lack of adoption of Bayesian methods in industry and increased computational complexity, we propose CalTRACK use more frequently adopted.  The two primary considerations for higher-frequency savings models are the need to take into account stronger autocorrelation and increased model specification error.  M & V standards for industrial savings estimation, which has been dealing with AMI data longer, provides useful guidance for dealing with these two considerations. Following ASHRAE Guideline 14-2002, and augmenting work done by the NW SEM Collaborative, we propose the following method:",
            "title": "Calculating uncertainty for daily and hourly methods"
        },
        {
            "location": "/monthly/aggregation/#fractional-savings-uncertainty-calculation",
            "text": "Because variances are larger in larger homes, normalizing levels of uncertainty using fractional savings uncertainty is an important aggregate metric, both for model comparison and selection, as well as final output. CalTRACK will compute the Fractional Savings Uncertainty at the site level based on the following equation:   Where  $CV$ is the coefficient of variance on the savings mean using prediction errors specified above\n$t$ is the relevant t-statistic for the desired level of confidence\n$F$ is the relevant F-statistic given degrees of freedom for the selected model",
            "title": "Fractional Savings uncertainty calculation"
        },
        {
            "location": "/monthly/aggregation/#calculating-95-confidence-intervals-using-fractional-savings-uncertainty",
            "text": "To calculate confidence intervals using the following equation:   CI(95) = +/- (FSU * 1.96) * 100",
            "title": "Calculating 95% confidence intervals using fractional savings uncertainty"
        },
        {
            "location": "/monthly/aggregation/#note-on-the-lack-of-comparison-group-adjustments-in-caltrack-technical-specification",
            "text": "While the technical working group acknowledged the potential use of comparison groups in gross savings estimation to correct for population-wide exogenous effects on use, after extensive debate, it was decided that the CalTRACK use cases (pay-for-performance in particular) required the ability for non-utility actors to be able to estimate savings without access to comparison group data. While several promising ideas were developed through the technical working group process about how to address this issue (utilities publishing public adjustment factors based on pre-tabilated comparison groups for example), there were serious concern about feasbility in time for early 2017 roll out of the P4P pilot. As a result, the issue of transparent and replicable comparison group adjustments as part of CalTRACK methods was left for the next version of CalTRACK technical specifications.",
            "title": "Note on the lack of comparison group adjustments in CalTRACK technical specification"
        }
    ]
}