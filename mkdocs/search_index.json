{
    "docs": [
        {
            "location": "/",
            "text": "CalTRACK Technical Documentation\n\n\nThis site represents the official technical documentation for CalTRACK, a set of open methods developed and tested through a multi-stakeholder process for estimating gross savings for residential energy efficiency programs in California.\n\n\nA full process history and related resources can be found on the \nCalTRACK\n website.\n\n\nInitial draft requirements for CalTRACK were developed by the CalTRACK technical working group and tested using data from PG&E to empirically verify assumptions and identify areas of sensitivity, the modify publish official versions of the methods through an open source process. Details about the CalTRACK technical working group processes can be found on the \nCalTRACK\n website.\n\n\nCommunication for CalTRACK methods development happens primarily through \nGithub issues\n and using a community communication tool called Slack. The source code for this documentation, as well as results from testing, discussion, and guidance for contribution can be found on the \nCalTRACK Github repository\n\n\n\n\nCalTRACK Working Group Contributors:\n\n\nLeif Magnuson - PG&E\n\n\nAndy Fessel - PG&E\n\n\nBrian A. Smith - PG&E\n\n\nCharlene Chi-Johnston - PG&E\n\n\nRichard Ridge, PhD - PG&E\n\n\nMatt Golden - Open Energy Efficiency\n\n\nMatt Gee - Open Energy Efficiency\n\n\nMcGee Young - Open Energy Efficiency\n\n\nJarred Metoyer - DNVGL\n\n\nJonathan Farland - DNVGL\n\n\nJake Oster -  EnergySavvy\n\n\nJohn Backus Mayes - EnergySavvy\n\n\nBlake Hough - EnergySavvy\n\n\nBen Polly - NREL\n\n\nBeth Reid - Olivine\n\n\nCynthia Swaim - Sempra Utilities\n\n\nDenise Parker - SoCal Edison\n\n\nGamaliel Lodge - Optimiser Energy\n\n\nLisa Schmidt - Home Energy Analyzer\n\n\nMartha Brook - CEC\n\n\nRobert Hansen - CPUC\n\n\nRyan Bullard - SoCal Edison\n\n\nTorsten Glidden - Build it Green\n\n\nAlfredo Gutierrez - ICF\n\n\n\n\nProject Lead Technical Consultants:\n\n\nOpen Energy Efficiency\n\n\nthe Open Energy Efficiency team has provided technical support to the the CalTRACK effort under contract with PG&E since 2012. The core methods that became CalTRACK were initially defined during the Advanced Home Upgrade Software Initiative process, then developed into the OpenEEmeter open source code with support of the California Energy Commission. These methods were then further refined and tested in the final beta phase of this effort, resulting in the CalTRACK v1.0 Methods.",
            "title": "Home"
        },
        {
            "location": "/#caltrack-technical-documentation",
            "text": "This site represents the official technical documentation for CalTRACK, a set of open methods developed and tested through a multi-stakeholder process for estimating gross savings for residential energy efficiency programs in California.  A full process history and related resources can be found on the  CalTRACK  website.  Initial draft requirements for CalTRACK were developed by the CalTRACK technical working group and tested using data from PG&E to empirically verify assumptions and identify areas of sensitivity, the modify publish official versions of the methods through an open source process. Details about the CalTRACK technical working group processes can be found on the  CalTRACK  website.  Communication for CalTRACK methods development happens primarily through  Github issues  and using a community communication tool called Slack. The source code for this documentation, as well as results from testing, discussion, and guidance for contribution can be found on the  CalTRACK Github repository   CalTRACK Working Group Contributors:  Leif Magnuson - PG&E  Andy Fessel - PG&E  Brian A. Smith - PG&E  Charlene Chi-Johnston - PG&E  Richard Ridge, PhD - PG&E  Matt Golden - Open Energy Efficiency  Matt Gee - Open Energy Efficiency  McGee Young - Open Energy Efficiency  Jarred Metoyer - DNVGL  Jonathan Farland - DNVGL  Jake Oster -  EnergySavvy  John Backus Mayes - EnergySavvy  Blake Hough - EnergySavvy  Ben Polly - NREL  Beth Reid - Olivine  Cynthia Swaim - Sempra Utilities  Denise Parker - SoCal Edison  Gamaliel Lodge - Optimiser Energy  Lisa Schmidt - Home Energy Analyzer  Martha Brook - CEC  Robert Hansen - CPUC  Ryan Bullard - SoCal Edison  Torsten Glidden - Build it Green  Alfredo Gutierrez - ICF   Project Lead Technical Consultants:  Open Energy Efficiency  the Open Energy Efficiency team has provided technical support to the the CalTRACK effort under contract with PG&E since 2012. The core methods that became CalTRACK were initially defined during the Advanced Home Upgrade Software Initiative process, then developed into the OpenEEmeter open source code with support of the California Energy Commission. These methods were then further refined and tested in the final beta phase of this effort, resulting in the CalTRACK v1.0 Methods.",
            "title": "CalTRACK Technical Documentation"
        },
        {
            "location": "/guides/v1guide/",
            "text": "Using the CalTRACK v1.0 Normalized Metered Monthly Gross Savings Methods\n\n\nThe CalTRACK Version 1.0 specification provides guidance for performing monthly billing analysis for whole home weather normalized gross savings for groups of residential energy efficiency projects.\n\n\nIt includes data requirements and technical specifications for data preparation and cleaning, site-level billing analysis, and aggregation of site-level results.\n\n\nThe complete technical specification for v1 monthly methods is found in four documents\n\n\n\n\n/monthly/data-sources.md\n describes the necessary data requirements for running CalTRACK v1\n\n\n/monthly/data-prep.md\n describes the sequence of steps required for preparing data for analysis\n\n\n/monthly/analysis.md\n describes the methods use for calculating site-level savings using monthly data\n\n\n/monthly/aggregation.md\n describes the methods use for aggregating site-level savings to group or portfolio average and total savings\n\n\n\n\nThe specification is intended to be done in order to ensure consistency and replicability.\n\n\nSupported Use Cases\n\n\nThe CalTRACK v1 monthly billing analysis methods were developed to produce a reliable estimate of basic, weather normalized gross savings at the site level and weighted average gross savings for groups (or portfolios) of projects.\n\n\nThis definition of gross savings was developed with two specific use cases in mind, and was not intended to extend to all potential uses of monthly billing analysis.\n\n\nThe two use cases that CalTRACK v1 is intended to support are:\n\n\n\n\nCalculating \npayable savings\n in the PG&E Residential Third-Party Pay-for-Performance pilot program. In this program, selected third party aggregators (organization providing services that may lead to energy savings) are paid  based on the measured energy use reductions for homes they submit to PG&E as having received their services. Payments to these aggregators will be based on CalTRACK methods. The savings that the utility can claim was delivered as a result of the program will be measured through a separate EM&V process.\n\n\nCalculating \nrealized savings and realization rates\n for third-party software used to predict savings for residential efficiency project for the purposes of determining rebates. Average empirical realization rates by vendor may be used to adjust rebates on an ongoing basis and provide feedback to vendors and contractors on their relative performance.  \n\n\n\n\nNotes on key CalTRACK v1 decisions and their implications\n\n\n\n\nFixed Degree Day Base. While it is more common in industry to use a variable degree day base temperatures in monthly billing analysis, the CalTRACK technical working group decided to use fixed degree day base temperatures. This decision was made after empirical testing of both fixed and variable degree day basis showed that, for a sample of 3000 projects done from 2014-2016 in PG&E territory there was little difference in average savings between the two methods, the use of variable degree days contributed to significant differences in savings among testers. The technical working group made the determination that, since replicability was a priority for the two supported use cases, the added replicability of the fixed degree day approach made it the better choice for CalTRACK v1 methods.\n\n\nInverse Variance Weighted Means for determining aggregate savings. In determining the average savings over groups of homes, inverse variance weighted means offers a way of dealing with the important consideration that not all site-level savings estimates are equally confident. IVWM emphasizes the savings of homes with good site-level model fits, while deemphasizing sites with poor model fits. This approach comes from meta analysis and is the minimum-variance estimator of a group mean under assumptions of conditional independence. However, two challenges arise in applying IVWMs to group savings. 1) The independence assumption may not hold over areas or time periods because of structural correlation in savings. This means it may be underestimating variances due to correlation structure in the errors. Practically, this may introduce bias in the group mean depending on the correlation structure 2) larger homes will tend to have large variances and smaller homes (and gas use which is closer to 0 in many homes), leading to a potential structural underestimate of group average savings because smaller savings will have smaller variances. 3) sites with very low variances (very close to zero) can lead blow up mean savings estimates (dividing by very small numbers) and require addition checks on the final number used for programmatic purposes. Alternative weighting schemes were discussed by the technical working group, but none were ultimately selected due to similar tradeoffs faced by each weighting scheme. Users of the v1 methods should be aware of the ways that IVWMs both solves for and also creates risks to program implementation and chose the right approach and risk mitigation procedures for the program accordingly.\n\n\n\n\nFurther Considerations\n\n\nThe purpose of CalTRACK is to provides an estimate of weather normalized gross savings and is not a replacement for net savings measurement arrived at through impact evaluations.\n\n\nBoth aggregator and utility users of CalTRACK should be aware that the CalTRACK methods do not apply corrections for exogenous changes such as economic conditions, energy costs, unobserved weather effects, and other factors that may impact consumption patterns and savings at a population level.\n\n\nHowever, savings from treatment groups as well as control groups (once identified) can be calculated using CalTRACK methods.\n\n\nDiscussions\n\n\n\n\nProject Plan and Technical Requirements Working Group Document\n\n\nHomes with Solar, EVs, etc.\n\n\nMissing and anomalous data\n\n\nZip Code Weather Station mapping\n\n\nData prep\n\n\nMonthly Data Requirements Specification\n\n\nAggregation rules\n\n\nFuture Participant Adjustments\n\n\nFixed or variable degree days",
            "title": "Guide to Version 1.0 Monthly Methods"
        },
        {
            "location": "/guides/v1guide/#using-the-caltrack-v10-normalized-metered-monthly-gross-savings-methods",
            "text": "The CalTRACK Version 1.0 specification provides guidance for performing monthly billing analysis for whole home weather normalized gross savings for groups of residential energy efficiency projects.  It includes data requirements and technical specifications for data preparation and cleaning, site-level billing analysis, and aggregation of site-level results.  The complete technical specification for v1 monthly methods is found in four documents   /monthly/data-sources.md  describes the necessary data requirements for running CalTRACK v1  /monthly/data-prep.md  describes the sequence of steps required for preparing data for analysis  /monthly/analysis.md  describes the methods use for calculating site-level savings using monthly data  /monthly/aggregation.md  describes the methods use for aggregating site-level savings to group or portfolio average and total savings   The specification is intended to be done in order to ensure consistency and replicability.",
            "title": "Using the CalTRACK v1.0 Normalized Metered Monthly Gross Savings Methods"
        },
        {
            "location": "/guides/v1guide/#supported-use-cases",
            "text": "The CalTRACK v1 monthly billing analysis methods were developed to produce a reliable estimate of basic, weather normalized gross savings at the site level and weighted average gross savings for groups (or portfolios) of projects.  This definition of gross savings was developed with two specific use cases in mind, and was not intended to extend to all potential uses of monthly billing analysis.  The two use cases that CalTRACK v1 is intended to support are:   Calculating  payable savings  in the PG&E Residential Third-Party Pay-for-Performance pilot program. In this program, selected third party aggregators (organization providing services that may lead to energy savings) are paid  based on the measured energy use reductions for homes they submit to PG&E as having received their services. Payments to these aggregators will be based on CalTRACK methods. The savings that the utility can claim was delivered as a result of the program will be measured through a separate EM&V process.  Calculating  realized savings and realization rates  for third-party software used to predict savings for residential efficiency project for the purposes of determining rebates. Average empirical realization rates by vendor may be used to adjust rebates on an ongoing basis and provide feedback to vendors and contractors on their relative performance.",
            "title": "Supported Use Cases"
        },
        {
            "location": "/guides/v1guide/#notes-on-key-caltrack-v1-decisions-and-their-implications",
            "text": "Fixed Degree Day Base. While it is more common in industry to use a variable degree day base temperatures in monthly billing analysis, the CalTRACK technical working group decided to use fixed degree day base temperatures. This decision was made after empirical testing of both fixed and variable degree day basis showed that, for a sample of 3000 projects done from 2014-2016 in PG&E territory there was little difference in average savings between the two methods, the use of variable degree days contributed to significant differences in savings among testers. The technical working group made the determination that, since replicability was a priority for the two supported use cases, the added replicability of the fixed degree day approach made it the better choice for CalTRACK v1 methods.  Inverse Variance Weighted Means for determining aggregate savings. In determining the average savings over groups of homes, inverse variance weighted means offers a way of dealing with the important consideration that not all site-level savings estimates are equally confident. IVWM emphasizes the savings of homes with good site-level model fits, while deemphasizing sites with poor model fits. This approach comes from meta analysis and is the minimum-variance estimator of a group mean under assumptions of conditional independence. However, two challenges arise in applying IVWMs to group savings. 1) The independence assumption may not hold over areas or time periods because of structural correlation in savings. This means it may be underestimating variances due to correlation structure in the errors. Practically, this may introduce bias in the group mean depending on the correlation structure 2) larger homes will tend to have large variances and smaller homes (and gas use which is closer to 0 in many homes), leading to a potential structural underestimate of group average savings because smaller savings will have smaller variances. 3) sites with very low variances (very close to zero) can lead blow up mean savings estimates (dividing by very small numbers) and require addition checks on the final number used for programmatic purposes. Alternative weighting schemes were discussed by the technical working group, but none were ultimately selected due to similar tradeoffs faced by each weighting scheme. Users of the v1 methods should be aware of the ways that IVWMs both solves for and also creates risks to program implementation and chose the right approach and risk mitigation procedures for the program accordingly.",
            "title": "Notes on key CalTRACK v1 decisions and their implications"
        },
        {
            "location": "/guides/v1guide/#further-considerations",
            "text": "The purpose of CalTRACK is to provides an estimate of weather normalized gross savings and is not a replacement for net savings measurement arrived at through impact evaluations.  Both aggregator and utility users of CalTRACK should be aware that the CalTRACK methods do not apply corrections for exogenous changes such as economic conditions, energy costs, unobserved weather effects, and other factors that may impact consumption patterns and savings at a population level.  However, savings from treatment groups as well as control groups (once identified) can be calculated using CalTRACK methods.",
            "title": "Further Considerations"
        },
        {
            "location": "/guides/v1guide/#discussions",
            "text": "Project Plan and Technical Requirements Working Group Document  Homes with Solar, EVs, etc.  Missing and anomalous data  Zip Code Weather Station mapping  Data prep  Monthly Data Requirements Specification  Aggregation rules  Future Participant Adjustments  Fixed or variable degree days",
            "title": "Discussions"
        },
        {
            "location": "/monthly/data-sources/",
            "text": "Data Sources for CalTRACK Monthly Methods\n\n\nThree types of data files are required to run the CalTRACK monthly methods: project data, energy consumption data, and weather data. These data must be linked with cross-reference files that define the mapping between ID columns in each of the data source types (Projects ID to Usage ID & Project ID to Weather Station ID).\n\n\nThis documentation is intended to provide general guidance on these three data sources for use in implementing CalTRACK methods. You can find a more detailed description of the specific project, usage, weather, and cross-reference files used in CalTRACK methods testing \nhere\n\n\nProject Data\n\n\nWhile project data can be incredibly rich and incredibly varied, the CalTRACK methods aim to define a minimal set of data fields on projects necessary to perform CalTRACK analysis. Thankfully, this set is comparatively small. To perform CalTRACK analysis, you need to be able to uniquely identify a project, identify the location of the project, and the timing of the efficiency investment or intervention We recommend your project data take on the general form:\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nProjectID\n\n\nA unique identifier for projects in the aggregator's database that can be used to link with additional project-specific information if desired\n\n\n\n\n\n\nElectric Account ID\n\n\nID used for uniquely matching with electric consumption files\n\n\n\n\n\n\nGas Account ID\n\n\nID used for uniquely matching with gas consumption files\n\n\n\n\n\n\nWork Start Date\n\n\nPreferably the date actual work on the retrofit started, not the date that the application was made or approved\n\n\n\n\n\n\nWork Finish Date\n\n\nPreferably the date that actual work on the retrofit or intervention, not the date that the reimbursement was filed or approved\n\n\n\n\n\n\nBuilding ZIP Code\n\n\nThe minimal geographic identifier for matching a site to a weather station\n\n\n\n\n\n\n\n\nConsumption\n\n\nWhile consumption data comes in a variety of frequencies (15 minute, Hourly, Daily, or Billing Period) and formats depending on the utility, the CalTRACK v1 monthly methods are only for monthly billing data, which typically, but not always, represents cumulative usage over periods of around month in length. The ideal consumption data file will have the following minimal fields:\n\n\nMonthly Consumption\n\n\nElectricity\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAccount ID\n\n\nUnique ID for the customer that is also included in the cross-reference file for linking to projects\n\n\n\n\n\n\nCurrent meter read or billing date\n\n\nCurrent date the meter was read format\n\n\n\n\n\n\nPast meter read or billing date\n\n\nPrevious date the meter was read\n\n\n\n\n\n\nKWH\n\n\nTotal Usage (KWH) for the period spanning the two meter read dates in the row\n\n\n\n\n\n\nEstimated Flag\n\n\nA flag for indicating whether the KHW value was an estimated value or actual meter read\n\n\n\n\n\n\n\n\nNatural Gas\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nAccount ID\n\n\nUnique ID for the customer that is also included in the cross-reference file for linking to projects\n\n\n\n\n\n\nCurrent meter read or billing date\n\n\nCurrent date the meter was read format\n\n\n\n\n\n\nPast meter read or billing date\n\n\nPrevious date the meter was read\n\n\n\n\n\n\nTHM\n\n\nTotal Usage (Therms) for the period spanning the two meter read dates in the row\n\n\n\n\n\n\nEstimated Flag\n\n\nA flag for indicating whether the THM value was an estimated value or actual meter read\n\n\n\n\n\n\n\n\nConsumption files can, as was the case for the CalTRACK test data, also be formatted as cumulative values over the course of the year and require differencinfg between periods in order to create the dataset required for CalTRACK data-prep.\n\n\nCross-reference files\n\n\nBoth types of cross-reference files contain the same columns of interest.\n\n\n\n\n\n\n\n\nColumn Name\n\n\nDescription\n\n\n\n\n\n\n\n\n\n\nProject ID\n\n\nA unique identifier for projects in the aggregators project database.\n\n\n\n\n\n\nUsage Record ID\n\n\nThis typically corresponds to a meter ID, account ID, or service point ID used to uniquely identify a usage trace with a customer in the utility's usage database. There are often separate IDs for gas and electric\n\n\n\n\n\n\nPremise ID\n\n\n(Optional) This typically corresponds to a unique premise can can be necessary for combining multiple usage records into a since premise-level record in the event that households have multiple meters for one fuel type, or usage IDs change when the same customer enters into a new service agreement with the utility\n\n\n\n\n\n\n\n\nWeather\n\n\nThere are three weather source files necessary for the CalTRACK v1 Monthly Methods.\n\n\n\n\nCZ2010 weather normals for 86 stations in California\n\n\n\n\nWhile the TMY3 temperature normals are more commonly used in industry, for regulatory reasons, the CZ2010 dataset needs to be use for CalTRACK. This was a dataset developed for the CEC by White Box consulting.\n\n\n\n\n\n\nMapping of zip codes to weather stations provided by the CEC as the canonical weather station mapping for California\n\nThis mapping was generated by White Box consulting for the CEC and was augmented my the team at DNV-GL to ensure coverage for missing zip codes.\n\n\n\n\n\n\nDaily Average Temperature Data taken from the Quality Controlled Local Climatological Data provided by NOAA\n\nThis dataset consists of over 40 fields, but all the relevant fields for CalTRACK methods are in the first 8 fields.\n\n\n\n\n\n\nWBAN|YearMonthDay|Tmax|TmaxFlag|Tmin|TminFlag|Tavg|TavgFlag|\n\n\nFor the purpose of CalTRACK analysis, we use the \nTavg\n field to calculate average HDD and CDD for billing periods using a fixed degree day base. This is outlined in detail in the \ndata-prep\n guidelines.\n\n\nWhile there is a web-based data extraction tool, we recommend using their \nFTP site\n for bulk download of the weather data by month. The relevant file used for CalTRACK is the \nYYYYMMdaily.txt\n file.",
            "title": "Data Sources for Monthly Methods"
        },
        {
            "location": "/monthly/data-sources/#data-sources-for-caltrack-monthly-methods",
            "text": "Three types of data files are required to run the CalTRACK monthly methods: project data, energy consumption data, and weather data. These data must be linked with cross-reference files that define the mapping between ID columns in each of the data source types (Projects ID to Usage ID & Project ID to Weather Station ID).  This documentation is intended to provide general guidance on these three data sources for use in implementing CalTRACK methods. You can find a more detailed description of the specific project, usage, weather, and cross-reference files used in CalTRACK methods testing  here  Project Data  While project data can be incredibly rich and incredibly varied, the CalTRACK methods aim to define a minimal set of data fields on projects necessary to perform CalTRACK analysis. Thankfully, this set is comparatively small. To perform CalTRACK analysis, you need to be able to uniquely identify a project, identify the location of the project, and the timing of the efficiency investment or intervention We recommend your project data take on the general form:     Column Name  Description      ProjectID  A unique identifier for projects in the aggregator's database that can be used to link with additional project-specific information if desired    Electric Account ID  ID used for uniquely matching with electric consumption files    Gas Account ID  ID used for uniquely matching with gas consumption files    Work Start Date  Preferably the date actual work on the retrofit started, not the date that the application was made or approved    Work Finish Date  Preferably the date that actual work on the retrofit or intervention, not the date that the reimbursement was filed or approved    Building ZIP Code  The minimal geographic identifier for matching a site to a weather station     Consumption  While consumption data comes in a variety of frequencies (15 minute, Hourly, Daily, or Billing Period) and formats depending on the utility, the CalTRACK v1 monthly methods are only for monthly billing data, which typically, but not always, represents cumulative usage over periods of around month in length. The ideal consumption data file will have the following minimal fields:  Monthly Consumption  Electricity     Column Name  Description      Account ID  Unique ID for the customer that is also included in the cross-reference file for linking to projects    Current meter read or billing date  Current date the meter was read format    Past meter read or billing date  Previous date the meter was read    KWH  Total Usage (KWH) for the period spanning the two meter read dates in the row    Estimated Flag  A flag for indicating whether the KHW value was an estimated value or actual meter read     Natural Gas     Column Name  Description      Account ID  Unique ID for the customer that is also included in the cross-reference file for linking to projects    Current meter read or billing date  Current date the meter was read format    Past meter read or billing date  Previous date the meter was read    THM  Total Usage (Therms) for the period spanning the two meter read dates in the row    Estimated Flag  A flag for indicating whether the THM value was an estimated value or actual meter read     Consumption files can, as was the case for the CalTRACK test data, also be formatted as cumulative values over the course of the year and require differencinfg between periods in order to create the dataset required for CalTRACK data-prep.  Cross-reference files  Both types of cross-reference files contain the same columns of interest.     Column Name  Description      Project ID  A unique identifier for projects in the aggregators project database.    Usage Record ID  This typically corresponds to a meter ID, account ID, or service point ID used to uniquely identify a usage trace with a customer in the utility's usage database. There are often separate IDs for gas and electric    Premise ID  (Optional) This typically corresponds to a unique premise can can be necessary for combining multiple usage records into a since premise-level record in the event that households have multiple meters for one fuel type, or usage IDs change when the same customer enters into a new service agreement with the utility",
            "title": "Data Sources for CalTRACK Monthly Methods"
        },
        {
            "location": "/monthly/data-sources/#weather",
            "text": "There are three weather source files necessary for the CalTRACK v1 Monthly Methods.   CZ2010 weather normals for 86 stations in California   While the TMY3 temperature normals are more commonly used in industry, for regulatory reasons, the CZ2010 dataset needs to be use for CalTRACK. This was a dataset developed for the CEC by White Box consulting.    Mapping of zip codes to weather stations provided by the CEC as the canonical weather station mapping for California \nThis mapping was generated by White Box consulting for the CEC and was augmented my the team at DNV-GL to ensure coverage for missing zip codes.    Daily Average Temperature Data taken from the Quality Controlled Local Climatological Data provided by NOAA \nThis dataset consists of over 40 fields, but all the relevant fields for CalTRACK methods are in the first 8 fields.    WBAN|YearMonthDay|Tmax|TmaxFlag|Tmin|TminFlag|Tavg|TavgFlag|  For the purpose of CalTRACK analysis, we use the  Tavg  field to calculate average HDD and CDD for billing periods using a fixed degree day base. This is outlined in detail in the  data-prep  guidelines.  While there is a web-based data extraction tool, we recommend using their  FTP site  for bulk download of the weather data by month. The relevant file used for CalTRACK is the  YYYYMMdaily.txt  file.",
            "title": "Weather"
        },
        {
            "location": "/monthly/data-prep/",
            "text": "Monthly Billing Analysis Data Preparation\n\n\nCalTRACK employs the following processes when preparing monthly consumption, weather, and project data for performing the monthly billing analysis specified in the CalTRACK v1 monthly methods.\n\n\nData Preparation Overview\n\n\nThere are countless small decisions that must be made as edge cases in the data arise. Thorough documentation ensures that evaluators understand the implications of these choices. Below are guidelines and a general process for addressing the most common issues that arise during data cleaning efforts for monthly billing analysis. It is recommended conduct these steps in the order they appear because the final combined dataset is highly sensitive to the order of data preparation steps.\n\n\nThe CalTRACK data preparations guidelines for monthly billing analysis consist of the following steps:\n\n\n\n\nProject data preparation\n\n\nGenerate necessary project fields from raw project data\n\n\nDeal with missing and miscoded values\n\n\nDeduplicate project records\n\n\n\n\n\n\nWeather data preparation\n\n\nMonthly electric and gas use data preparation\n\n\nLink project and electric use files\n\n\nLinked project+electric use data preparation\n\n\nDeduplicate records based on combined attributes\n\n\nDrop observations not meeting data sufficiency requirements\n\n\n\n\n\n\nLink project records and gas use files\n\n\nLinked project+gas use data preparation\n\n\nLink weather data and project records\n\n\nFinal combined data sufficiency checks\n\n\n\n\n1. Project Data Preparation\n\n\nThe minimum field requirements for project data under the CalTRACK monthly specification are outlined [here] (https://github.com/impactlab/caltrack/blob/master/docs/monthly/data-sources.md). Notably, a prepared project file should consist of one row per project, with a unique ID that can be used to link to gas and/or electric usage data, project start and stop dates, and zip code for the site. The following data cleaning steps for project data are meant to ensure that the prepared project file meets these field requirements and uniqueness constraints.\n\n\nCreating Work Start and Work End dates from raw project data\n\n\nAccurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, considerable variation may occur in database records identifying dates associated with project start and project completion.\nIn general, users should try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), It is recommended that users identify an average time to completion.\nCalTRACK implementations should use official work start date and work end date fields provided by aggregators rather then proxy fields when available.\n\n\nDealing with miscoded dates\n\n\nImplausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window\nImplausible month and year values should be flagged and that home not included in estimation.\n\n\nDeduplicate project records\n\n\nIf a building appears multiple times within a project database, and the project dates are the same the most complete record for that building should be used\nIf a building appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.\n\n\n2. Weather Data Preparation\n\n\nFor CalTRACK monthly billing analysis, the weather data requirements are straightforward. For monthly analysis, since the daily average temperature data from a nearby weather station is used to create values for the number of heating degree days (below 60F) and cooling degree days (above 70F) in each billing period, the primary consideration in preparing the data is how to deal with missing values.\nAdditional weather data can be found [here] (https://github.com/impactlab/caltrack/blob/master/docs/monthly/data-sources.md#weather)\nFor further discussions regarding weather data, see issues #10, #16. \n\n\nDealing with missing values\n\n\nWeather data is notoriously incomplete, especially at the granular sub-daily level. Some weather stations generally fail to report data, other weather stations are simply inconsistent in reporting data. This becomes an issue when trying to match projects to their local weather conditions. If a nearby non-reporting weather station is selected, the savings model will fail. If the project is connected to a nearby intermittently reporting weather station, the model will suffer. Additionally, if a project is connected to a weather station that experiences a significantly different local micro-climate, the model will suffer.\n* It is recommended that for monthly billing analysis daily average temperature values that are missing not be imputed, but rather count against a site in meeting data sufficiency requirements (detailed at the end of the document).\n\n\n3. Monthly electric and gas use data preparation\n\n\nDealing with missing values in monthly usage data\n\n\nUsage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with \u201cestimated\u201d reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.\n\n For the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the use per day for that period.\n\n Missing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements.\n\n CalTRACK does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.\n\n If flags exist for estimated values, they are counted as missing and count against the site\u2019s data sufficiency criteria detailed later in this guidance.\n\n\nDealing with extreme values in usage data\n\n\nOccasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels) and should be handled based on the following guidance:\n* Negative values for monthly use should be treated as missing and count against sufficiency criterion. Negative values in monthly data may also be a valid sign of possible solar/net metering and should be flagged for verification.\n\n\n4. Link project records and usage files\n\n\nOnce project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. CalTRACK recommends using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, CalTRACK does not offer specific guidance.\n\n\nUnmatched data should be excluded from analysis.\n\n\n5. Linked project+use data preparation\n\n\nDeduplicate records based on combined attributes\n\n\n\n\nIf two duplicate records have identical consumption traces and date ranges, drop one at random\n\n\nIf two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. * If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.\n\n\nIf the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.\n\n\n\n\nDrop records not meeting data sufficiency requirements\n\n\nCalculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.\n\n 12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months\n\n Post retrofit data sufficiency for estimation will be dealt with in [post-estimation model fit criterion] (https://github.com/impactlab/caltrack/blob/master/docs/monthly/analysis.md#3-fit-all-candidate-models-and-apply-qualification-criteria)\n* Total annual savings estimates will require 12 months post-retrofit\n\n\nDrop project records with unsupported characteristics\n\n\n\n\nDrop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. However, if you only have access to billing data, CalTRACK recommends working with the utility to get flags for accounts that have net metering present so they can be excluded from the analysis.\n\n\nFuture efforts may provide the ability to access sub-meter data that may allow for backing out onsite generation and storage to arrive at savings.\n\n\n\n\n6. Link weather data and project records\n\n\nWeather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects\n\n\n\n\nFor California, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files. Clean versions of these files can be found \nhere\n.\n\n\n\n\n7. Final combined data sufficiency checks\n\n\n\n\nBilling periods (the period between bill start date and bill end date in the monthly usage data) with more than 10% missing days of weather data will be thrown out and count against the required number of billing period observations\n\n\nAny projects with fewer than 12 months pre and 12 months post are not included in the analysis",
            "title": "Data Preparation for Monthly Methods"
        },
        {
            "location": "/monthly/data-prep/#monthly-billing-analysis-data-preparation",
            "text": "CalTRACK employs the following processes when preparing monthly consumption, weather, and project data for performing the monthly billing analysis specified in the CalTRACK v1 monthly methods.",
            "title": "Monthly Billing Analysis Data Preparation"
        },
        {
            "location": "/monthly/data-prep/#data-preparation-overview",
            "text": "There are countless small decisions that must be made as edge cases in the data arise. Thorough documentation ensures that evaluators understand the implications of these choices. Below are guidelines and a general process for addressing the most common issues that arise during data cleaning efforts for monthly billing analysis. It is recommended conduct these steps in the order they appear because the final combined dataset is highly sensitive to the order of data preparation steps.  The CalTRACK data preparations guidelines for monthly billing analysis consist of the following steps:   Project data preparation  Generate necessary project fields from raw project data  Deal with missing and miscoded values  Deduplicate project records    Weather data preparation  Monthly electric and gas use data preparation  Link project and electric use files  Linked project+electric use data preparation  Deduplicate records based on combined attributes  Drop observations not meeting data sufficiency requirements    Link project records and gas use files  Linked project+gas use data preparation  Link weather data and project records  Final combined data sufficiency checks",
            "title": "Data Preparation Overview"
        },
        {
            "location": "/monthly/data-prep/#1-project-data-preparation",
            "text": "The minimum field requirements for project data under the CalTRACK monthly specification are outlined [here] (https://github.com/impactlab/caltrack/blob/master/docs/monthly/data-sources.md). Notably, a prepared project file should consist of one row per project, with a unique ID that can be used to link to gas and/or electric usage data, project start and stop dates, and zip code for the site. The following data cleaning steps for project data are meant to ensure that the prepared project file meets these field requirements and uniqueness constraints.",
            "title": "1. Project Data Preparation"
        },
        {
            "location": "/monthly/data-prep/#creating-work-start-and-work-end-dates-from-raw-project-data",
            "text": "Accurately identifying baseline and reporting periods is important for reducing the modeling error associated with a savings calculation. However, considerable variation may occur in database records identifying dates associated with project start and project completion.\nIn general, users should try to identify the fields in a project record that most closely match the actual work start and work completion dates. In the absence of either of these fields (that is, if a project record only contains one or the other set of dates), It is recommended that users identify an average time to completion.\nCalTRACK implementations should use official work start date and work end date fields provided by aggregators rather then proxy fields when available.",
            "title": "Creating Work Start and Work End dates from raw project data"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-miscoded-dates",
            "text": "Implausible day values (>31) should be coded as the beginning of month if project start date and end of month if project end date so that the entire month is included in the intervention window\nImplausible month and year values should be flagged and that home not included in estimation.",
            "title": "Dealing with miscoded dates"
        },
        {
            "location": "/monthly/data-prep/#deduplicate-project-records",
            "text": "If a building appears multiple times within a project database, and the project dates are the same the most complete record for that building should be used\nIf a building appears multiple times within a project database and the project dates differ because there are multiple measures installed associated with the same incentive program, the start date of the intervention should be the earliest of the project start dates across projects and the end date for the intervention should be the latest of the project end dates.",
            "title": "Deduplicate project records"
        },
        {
            "location": "/monthly/data-prep/#2-weather-data-preparation",
            "text": "For CalTRACK monthly billing analysis, the weather data requirements are straightforward. For monthly analysis, since the daily average temperature data from a nearby weather station is used to create values for the number of heating degree days (below 60F) and cooling degree days (above 70F) in each billing period, the primary consideration in preparing the data is how to deal with missing values.\nAdditional weather data can be found [here] (https://github.com/impactlab/caltrack/blob/master/docs/monthly/data-sources.md#weather)\nFor further discussions regarding weather data, see issues #10, #16.",
            "title": "2. Weather Data Preparation"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-missing-values",
            "text": "Weather data is notoriously incomplete, especially at the granular sub-daily level. Some weather stations generally fail to report data, other weather stations are simply inconsistent in reporting data. This becomes an issue when trying to match projects to their local weather conditions. If a nearby non-reporting weather station is selected, the savings model will fail. If the project is connected to a nearby intermittently reporting weather station, the model will suffer. Additionally, if a project is connected to a weather station that experiences a significantly different local micro-climate, the model will suffer.\n* It is recommended that for monthly billing analysis daily average temperature values that are missing not be imputed, but rather count against a site in meeting data sufficiency requirements (detailed at the end of the document).",
            "title": "Dealing with missing values"
        },
        {
            "location": "/monthly/data-prep/#3-monthly-electric-and-gas-use-data-preparation",
            "text": "",
            "title": "3. Monthly electric and gas use data preparation"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-missing-values-in-monthly-usage-data",
            "text": "Usage data generally undergoes significant cleaning prior to release to program administrators or the general public. There are generally three types of missing usage data. First, monthly billing data will be populated with \u201cestimated\u201d reads, when the utility has imputed a likely consumption amount for the month for the purposes of billing, but has not actually recorded a meter reading. Second, there are gaps in AMI meter data, where there may have been a hardware failure or another similar type of infrastructure breakdown where the data was not recorded. Finally, there is the issue of data that goes missing in the process of transferring to program evaluators (in the CalTrack Beta test, two of the zip files holding monthly billing data were corrupted and unreadable). Each of these issues represents a unique challenge and must be dealt with independently.  For the case of missing values where the cumulative value is in the following period (as in an estimated read), the cumulative number of days between the two periods will be used to generate the use per day for that period.  Missing usage values with no cumulative amount in the following period (such as missing AMI data) will be counted against data sufficiency requirements.  CalTRACK does not offer firm guidance on auditing data sets for completeness, however, a data audit was conducted for the purposes of the Beta test and was found to have identified several missing data issues that would not have otherwise been identified. Thus, a data audit is generally recommended.  If flags exist for estimated values, they are counted as missing and count against the site\u2019s data sufficiency criteria detailed later in this guidance.",
            "title": "Dealing with missing values in monthly usage data"
        },
        {
            "location": "/monthly/data-prep/#dealing-with-extreme-values-in-usage-data",
            "text": "Occasionally, the project or consumption data may contain extreme values that are likely the result of a data error, but may also be an indicator of another factor (such as the presence of solar panels) and should be handled based on the following guidance:\n* Negative values for monthly use should be treated as missing and count against sufficiency criterion. Negative values in monthly data may also be a valid sign of possible solar/net metering and should be flagged for verification.",
            "title": "Dealing with extreme values in usage data"
        },
        {
            "location": "/monthly/data-prep/#4-link-project-records-and-usage-files",
            "text": "Once project, consumption, and weather data have met all of their respective requirements, the data must be matched in order for a savings estimation to be performed. CalTRACK recommends using a key such as a utility account number that will clearly match a given project with a given meter. However, we also recognize that in certain cases, a project may encompass more than one meter or utility account. In these cases, CalTRACK does not offer specific guidance.  Unmatched data should be excluded from analysis.",
            "title": "4. Link project records and usage files"
        },
        {
            "location": "/monthly/data-prep/#5-linked-projectuse-data-preparation",
            "text": "",
            "title": "5. Linked project+use data preparation"
        },
        {
            "location": "/monthly/data-prep/#deduplicate-records-based-on-combined-attributes",
            "text": "If two duplicate records have identical consumption traces and date ranges, drop one at random  If two duplicate records have identical consumption traces but different date ranges select the more complete record having more dates. * If the dates are contiguous, or there are overlapping dates with the same usage values, combine the two traces into a single trace.  If the records have the same date ranges, but different usage values, the project should be flagged and the record excluded from the sample.",
            "title": "Deduplicate records based on combined attributes"
        },
        {
            "location": "/monthly/data-prep/#drop-records-not-meeting-data-sufficiency-requirements",
            "text": "Calculating energy efficiency savings requires a sufficient observation period of energy usage prior to and after an intervention. Generally, annualized models require at least 12 months of usage data on each side of an intervention in order to accurately calculate energy savings. Some models may be able to calculate energy savings with fewer than 12 months of data in the reporting period.  12 complete months pre-retrofit for monthly billing data to qualify for estimation or 24 months with up to 2 missing values from different, non-contiguous months  Post retrofit data sufficiency for estimation will be dealt with in [post-estimation model fit criterion] (https://github.com/impactlab/caltrack/blob/master/docs/monthly/analysis.md#3-fit-all-candidate-models-and-apply-qualification-criteria)\n* Total annual savings estimates will require 12 months post-retrofit",
            "title": "Drop records not meeting data sufficiency requirements"
        },
        {
            "location": "/monthly/data-prep/#drop-project-records-with-unsupported-characteristics",
            "text": "Drop homes with known PV or EV added 12 months prior to or up to 12 months after the intervention. During the CalTRACK beta test, these homes were identified from the presence of reverse flow in the AMI data and/or indications of net metering in the cross reference tables. However, if you only have access to billing data, CalTRACK recommends working with the utility to get flags for accounts that have net metering present so they can be excluded from the analysis.  Future efforts may provide the ability to access sub-meter data that may allow for backing out onsite generation and storage to arrive at savings.",
            "title": "Drop project records with unsupported characteristics"
        },
        {
            "location": "/monthly/data-prep/#6-link-weather-data-and-project-records",
            "text": "Weather station mapping requires locating the station nearest to the project. Each project file should contain a zip code that allows matching weather stations to projects   For California, weather station mapping was done using the 86 station standard mapping of zip code to CZ2010 weather files. Clean versions of these files can be found  here .",
            "title": "6. Link weather data and project records"
        },
        {
            "location": "/monthly/data-prep/#7-final-combined-data-sufficiency-checks",
            "text": "Billing periods (the period between bill start date and bill end date in the monthly usage data) with more than 10% missing days of weather data will be thrown out and count against the required number of billing period observations  Any projects with fewer than 12 months pre and 12 months post are not included in the analysis",
            "title": "7. Final combined data sufficiency checks"
        },
        {
            "location": "/monthly/analysis/",
            "text": "CalTRACK Site-level Monthly Gross Savings Estimation Technical Guideline\n\n\n\n\nMethodological Overview\n\n\nSite-level gross savings using monthly billing data (both electricity and gas) will use a two-stage estimation approach that closely follows methodological recommendations in the technical appendices of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, with some modifications and more specific guidance developed through empirical testing to ensure consistency and replicability of results.\n\n\nThe idea behind two-stage site-level models is to model the energy use of each house before and after\n\n\nMore formally, the two-stage approach first fits \ntwo\n separate parametric models to daily average energy use, one on the pre-intervention (baseline) period and one on the post-intervention (reporting) period for a single site using an ordinary least squares regression of the general form:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\nWhere\n\n\n\n\nUPD_{mi}\n is average use (gas in therms, electricity in kWh) per day during billing period \nm\n for site \ni\n.\n\n\n\n\n\\mu_i\n is the mean use for site \ni\n, or intercept.\n\n\n\n\n\\beta_{Hi}\n is the coefficient site \ni\n on average heating degree days per day.\n\n\n\n\n\\beta_{Ci}\n is the coefficient or site \ni\n on average cooling degree days per day.\n\n\n\n\nH_m\n is the average number of heating degree days per day in billing period \nm\n, which is a function of a fixed base temperature, the average daily temperatures from the weather station matched to site \ni\n during the billing period \nm\n, and the number of days in billing period \nm\n with matched usage and weather data for site \ni\n.\n\n\n\n\nC_m\n is the average number of cooling degree days per day in month \nm\n, which is a function of a selected base temperature, the average daily temperatures from the weather station matched to site \ni\n during month \nm\n, and the number of days in month \nm\n with matched usage and weather data for site \ni\n.\n\n\n\n\n\\epsilon_{mi}\n is the site specific error term for a given month.\n\n\nIn the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized gross savings), or by using current-year weather to project forward baseline period use (current year weather normalized gross savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.\n\n\nThis site-level two-stage approach without the use of a comparison group, while having significant limitations and tradeoffs, was decided by the technical working group to be appropriate for the two main use cases for CalTRACK, which emphasize effects on the grid and feedback to software vendors, rather than causal programatic effects. In addition to its long history of use in the EM&V literature, it draws on a methodological foundation developed in the more general literature on piecewise linear regression or segmented regression for policy analysis and effect estimates that is used in fields as divers as public health, medical research, and econometrics.\n\n\nWe now proceed with a detailed technical treatment of the steps for monthly savings estimation.\n\n\nTechnical guidelines for implementing two-stage estimation on monthly electric and gas usage data for CalTRACK\n\n\nCalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Cleaning and Integration technical specification. Starting with the prepared data, site-level monthly gross savings analysis is performed by implementing the following steps:\n\n\n1. Generate Use Per Day values and separate usage data into a pre- and a post-intervention data series\n\n\nThe CalTRACK monthly gross savings analysis uses average use per day (\nUPD\n) values for each month by taking the bill-period usage values, then dividing by the number of days in that bill period, as follows:\n\n\n\n\nUPD_m = \\frac{1}{n_{U_d}} * \\sum{U_d}\n\n\n\n\nWhere\n\n\n\n\nUPD_m\n is the average use per day for a given month \nm\n\n\n\n\n\\sum{U_d}\n is the sum of all daily use values \nU_d\n for a given month `m\u2019\n\n\n\n\nn_{U_d}\n is the total number of daily use values provided in the usage series that are between the first calendar day of month \nm\n and the last calendar day of month \nm\n\n\nNote: If daily use data for gas or electric is not available, monthly billing data can be used for the monthly billing analysis. However, modifications of the denominators for average use per day and for average HDD and CDD per day are necessary.\n\n\nNow split the series of \nUPD_m\n values into pre- and post-intervention periods according to the following rules:\n\n\nPre-intervention period\n: all \nUPD_m\n values from the beginning of the series up to the the complete billing month prior to the \nwork_start_date\n. The month containing \nwork_start_date\n is excluded from this series.\n\n\nPost-intervention period\n: all \nUPD_m\n values from the first billing month after the \nwork_end_date\n to the end of the series.\n\n\nFinal data sufficiency qualification check\n: All qualifying sites must have at least 12 months of contiguous $UPD_m$ values in the pre-intervention series and at least 12 months of contiguous post-intervention \nUPD_m\n values starting with the month after \nwork_end_date\n.\n\n\nAll sites not meeting these minimum data requirements are thrown out of the analysis\n\n\n2. Set fixed degree day base temperature and calculated HDD and CDD\n\n\nNext you calculate total HDD and CDD for the each billing period in the series. CalTRACK will use a fixed degree day base for monthly billing analysis. The following balance point temperatures will be use:\n\n\nHDD base temp: 60 F\n\n\nCDD base temp: 70 F\n\n\nHDD and CDD values are calculated as follows\n\n\n\n\nHDD_m = \\frac{1}{n_{U_d}} * \\sum{ \\max(60 - T_{ave}, 0) }\n\n\n\n\nWhere\n\n\n\n\nHDD_m\n = Average heating degree days per day for billing period \nm\n\n\n\n\nn_{U_d}\n = the number of days with both weather and usage data\n\n\n\n\n\\sum\n = the sum of the degree  over each day \nd\n in billing period \nm\n\n\n\n\n\\max\n = the maximum of the two values in ()\n\n\n\n\nT_{ave}\n = the average temperature for day \nd\n\n\nAnd\n\n\n\n\nCDD_m = \\frac{1}{n_{U_d}} * \\sum{ max(ave_temp_d - 70, 0) }\n\n\n\n\nWhere\n\n\n\n\nCDD_m\n = Cooling degree days for billing period \nm\n\n\n\n\nn_{U_d}\n = the number of days with both weather and usage data\n\n\n\n\n\\sum\n = the sum of values in {} over each day \nd\n in billing period \nm\n\n\n\n\n\\max\n = the maximum of the two values in ()\n\n\n\n\nT_{ave}\n = the average temperature for day \nd\n\n\nDaily average temperatures are taken from the GSOD average data temperature dataset provided by NOAA\n\n\n3. Fit All Candidate Models and Apply Qualification Criteria\n\n\nFor each site, all allowable models will be run as candidate models and then have minimum fitness criteria set for qualification.\n\n\nFor CalTRACK electric monthly savings analysis, the following candidate models are fit:\n\n\n\n\n UPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\n\n\n UPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi} \n\n\n\n\n\n\n UPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\n\n\n UPD_{mi} = \\mu_i + \\epsilon_{mi} \n\n\n\n\nwith the constraints\n\n\n\n\n\\beta_{H} > 0\n\n\n\n\n\n\n\\beta_{C} > 0\n\n\n\n\n\n\n\\mu_i > 0\n\n\n\n\nFor electric, qualifying models for selection must have each parameter estimate meet the minimum significance criteria of $p < 0.1$ and are strictly positive. All qualifying models are considered for final model selection.\n\n\nFor CalTRACK gas monthly savings analysis, the following candidate models are fit:\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi} \n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi} \n\n\n\n\n\n\nUPD_{mi} = \\mu_i + \\epsilon_{mi} \n\n\n\n\nwith the constraints\n\n\n\n\n\\beta_{H} > 0\n\n\n\n\n\n\n\\mu_i > 0\n\n\n\n\nIf each parameter estimate meets minimum significance criteria (p < 0.1) and are strictly positive, then the model is a qualifying model for inclusion in model selection.\n\n\n4. Select the best for pre-intervenion and post-intervention periods for use in second-stage savings estimation\n\n\nAll qualifying pre-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.\n\n\nFor the monthly billing analysis, because we are using fixed degree days instead of variable degree days, adjusted R-squared will be defined as\n\n\n\n\n adjR^2 = 1 - \\frac{SS_{res}/df_e}{SS_{tot}/df_t} \n\n\n\n\nWhere\n\n\n\n\n SS_{res} \n is the sum of squares of residuals\n\n\n\n\n df_e \n is the degrees of freedom of the estimate of the underlying population error variance, and is calculated using \nn-p-1\n, where \nn\n is the number of observations in the sample used to estimate the model and \np\n is the number of explanatory variables, not including the constant term and not including degree day base temperature as a parameter because it\u2019s fixed\n\n\n\n\n SS_{tot} \n is the total sum of squares\n\n\n\n\n df_t \n is the degrees of freedom of the estimate of the population variance of the dependent variable, and is calculated as \nn-1\n, were \nn\n is the size of the sample use to estimate the model\n\n\nAll qualifying post-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.\n\n\n5. Estimate second-stage gross savings quantities based on selected first stage pre- and post-intervention models\n\n\nDuring the second stage, up to five savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.\n\n\nCumulative gross savings over entire performance period\nYear one annualized actual gross savings in the the reporting (post-intervention) period\nYear two annualized actual gross savings in the the reporting (post-intervention) period\nYear one annualized gross savings in the normal year\nYear two annualized gross savings in the normal year\n\n\nThese site-level second stage quantities are calculated as follows:\n\n\nCumulative gross savings over entire performance period (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period after \nwork_end_date\n using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for every complete billing periods after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over every complete billing period since \nwork_end_date\n.\n\n\n\n\nYear one gross savings from 1 to 12 months after site visit. (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period after \nwork_end_date\n until 12 billing periods after \nwork_end_date\n  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for 12 complete billing periods after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over the 12 billing periods since \nwork_end_date\n.\n\n\n\n\nYear two gross savings from 13 to 24 months after site visit. (site-level)\n\n\n\n\nCompute \npredicted_baseline_use\n for each complete billing period starting 13 months after \nwork_end_date\n until 24 billing periods after \nwork_end_date\n  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.\n\n\nCompute \nmonthly_gross_savings\n = \npredicted_baseline_monthly_use - actual_monthly_use\n for month 13 to month 24 after \nwork_end_date\n for project\n\n\nSum  \nmonthly_gross_savings\n over the 12 billing periods from 13 months after \nwork_end_date\n to 24 months.\n\n\n\n\nYear one site-level annualized gross savings in the normal year\n\n\n\n\nCompute \npredicted_baseline_monthly_use\n using the stage one model from the baseline period and average degree days from the CZ2010 normal weather year. Use the full month of available values when calculating the average degree days per billing period for the normal year.\n\n\nCompute \npredicted_reporting_monthly_use\n using a \nstage one\n model fit to only the first 12 months of post-intervention values and degree days from the CZ2010 normal weather year file. Use the full month of available values when calculating the average degree days per billing period for the normal year.\n\n\nCompute \nmonthly_normal_year_gross_savings\n = \npredicted_baseline_monthly_use - predicted_reporting_monthly_use\n for normal year months\n\n\nSum  \nmonthly_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nYear two site-level annualized gross savings in the normal year\n\n\n\n\nCompute \npredicted_baseline_monthly_use\n using the stage one model from the baseline period and degree days from the CZ2010 normal weather year.\n\n\nCompute \npredicted_reporting_monthly_use\n using a \nstage one\n model fit to only the 13th-24th months of post-intervention values and degree days from the CZ2010 normal weather year file for the relevant months.\n\n\nCompute \nmonthly_normal_year_gross_savings\n = \npredicted_baseline_monthly_use - predicted_reporting_monthly_use\n for each normal year month.\n\n\nSum  \nmonthly_normal_year_gross_savings\n over entire normal year.\n\n\n\n\nPost-estimation steps and portfolio aggregation\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over \nportfolios of homes\n. In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified \nhere\n.",
            "title": "Analysis of Monthly Data"
        },
        {
            "location": "/monthly/analysis/#caltrack-site-level-monthly-gross-savings-estimation-technical-guideline",
            "text": "",
            "title": "CalTRACK Site-level Monthly Gross Savings Estimation Technical Guideline"
        },
        {
            "location": "/monthly/analysis/#methodological-overview",
            "text": "Site-level gross savings using monthly billing data (both electricity and gas) will use a two-stage estimation approach that closely follows methodological recommendations in the technical appendices of the Uniform Methods Project for Whole Home Building Analysis and the California Evaluation Project, with some modifications and more specific guidance developed through empirical testing to ensure consistency and replicability of results.  The idea behind two-stage site-level models is to model the energy use of each house before and after  More formally, the two-stage approach first fits  two  separate parametric models to daily average energy use, one on the pre-intervention (baseline) period and one on the post-intervention (reporting) period for a single site using an ordinary least squares regression of the general form:   UPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi}    Where   UPD_{mi}  is average use (gas in therms, electricity in kWh) per day during billing period  m  for site  i .   \\mu_i  is the mean use for site  i , or intercept.   \\beta_{Hi}  is the coefficient site  i  on average heating degree days per day.   \\beta_{Ci}  is the coefficient or site  i  on average cooling degree days per day.   H_m  is the average number of heating degree days per day in billing period  m , which is a function of a fixed base temperature, the average daily temperatures from the weather station matched to site  i  during the billing period  m , and the number of days in billing period  m  with matched usage and weather data for site  i .   C_m  is the average number of cooling degree days per day in month  m , which is a function of a selected base temperature, the average daily temperatures from the weather station matched to site  i  during month  m , and the number of days in month  m  with matched usage and weather data for site  i .   \\epsilon_{mi}  is the site specific error term for a given month.  In the second stage, using parameter estimates from the first stage equation, weather normalized savings for both the baseline period and reporting period can be computed by using corresponding temperature normals for the relevant time period (typical year weather normalized gross savings), or by using current-year weather to project forward baseline period use (current year weather normalized gross savings) and differencing between baseline and reporting period estimated or actual use, depending on the quantity of interest.  This site-level two-stage approach without the use of a comparison group, while having significant limitations and tradeoffs, was decided by the technical working group to be appropriate for the two main use cases for CalTRACK, which emphasize effects on the grid and feedback to software vendors, rather than causal programatic effects. In addition to its long history of use in the EM&V literature, it draws on a methodological foundation developed in the more general literature on piecewise linear regression or segmented regression for policy analysis and effect estimates that is used in fields as divers as public health, medical research, and econometrics.  We now proceed with a detailed technical treatment of the steps for monthly savings estimation.",
            "title": "Methodological Overview"
        },
        {
            "location": "/monthly/analysis/#technical-guidelines-for-implementing-two-stage-estimation-on-monthly-electric-and-gas-usage-data-for-caltrack",
            "text": "CalTRACK savings estimation begins with gas and electric usage data, project data, and weather data that have been cleaned and combined according to the Data Cleaning and Integration technical specification. Starting with the prepared data, site-level monthly gross savings analysis is performed by implementing the following steps:",
            "title": "Technical guidelines for implementing two-stage estimation on monthly electric and gas usage data for CalTRACK"
        },
        {
            "location": "/monthly/analysis/#1-generate-use-per-day-values-and-separate-usage-data-into-a-pre-and-a-post-intervention-data-series",
            "text": "The CalTRACK monthly gross savings analysis uses average use per day ( UPD ) values for each month by taking the bill-period usage values, then dividing by the number of days in that bill period, as follows:   UPD_m = \\frac{1}{n_{U_d}} * \\sum{U_d}   Where   UPD_m  is the average use per day for a given month  m   \\sum{U_d}  is the sum of all daily use values  U_d  for a given month `m\u2019   n_{U_d}  is the total number of daily use values provided in the usage series that are between the first calendar day of month  m  and the last calendar day of month  m  Note: If daily use data for gas or electric is not available, monthly billing data can be used for the monthly billing analysis. However, modifications of the denominators for average use per day and for average HDD and CDD per day are necessary.  Now split the series of  UPD_m  values into pre- and post-intervention periods according to the following rules:  Pre-intervention period : all  UPD_m  values from the beginning of the series up to the the complete billing month prior to the  work_start_date . The month containing  work_start_date  is excluded from this series.  Post-intervention period : all  UPD_m  values from the first billing month after the  work_end_date  to the end of the series.  Final data sufficiency qualification check : All qualifying sites must have at least 12 months of contiguous $UPD_m$ values in the pre-intervention series and at least 12 months of contiguous post-intervention  UPD_m  values starting with the month after  work_end_date .  All sites not meeting these minimum data requirements are thrown out of the analysis",
            "title": "1. Generate Use Per Day values and separate usage data into a pre- and a post-intervention data series"
        },
        {
            "location": "/monthly/analysis/#2-set-fixed-degree-day-base-temperature-and-calculated-hdd-and-cdd",
            "text": "Next you calculate total HDD and CDD for the each billing period in the series. CalTRACK will use a fixed degree day base for monthly billing analysis. The following balance point temperatures will be use:  HDD base temp: 60 F  CDD base temp: 70 F  HDD and CDD values are calculated as follows   HDD_m = \\frac{1}{n_{U_d}} * \\sum{ \\max(60 - T_{ave}, 0) }   Where   HDD_m  = Average heating degree days per day for billing period  m   n_{U_d}  = the number of days with both weather and usage data   \\sum  = the sum of the degree  over each day  d  in billing period  m   \\max  = the maximum of the two values in ()   T_{ave}  = the average temperature for day  d  And   CDD_m = \\frac{1}{n_{U_d}} * \\sum{ max(ave_temp_d - 70, 0) }   Where   CDD_m  = Cooling degree days for billing period  m   n_{U_d}  = the number of days with both weather and usage data   \\sum  = the sum of values in {} over each day  d  in billing period  m   \\max  = the maximum of the two values in ()   T_{ave}  = the average temperature for day  d  Daily average temperatures are taken from the GSOD average data temperature dataset provided by NOAA",
            "title": "2. Set fixed degree day base temperature and calculated HDD and CDD"
        },
        {
            "location": "/monthly/analysis/#3-fit-all-candidate-models-and-apply-qualification-criteria",
            "text": "For each site, all allowable models will be run as candidate models and then have minimum fitness criteria set for qualification.  For CalTRACK electric monthly savings analysis, the following candidate models are fit:    UPD_{mi} = \\mu_i + \\beta_{Hi}H_m + \\beta_{Ci}C_m +  \\epsilon_{mi}      UPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi}      UPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi}      UPD_{mi} = \\mu_i + \\epsilon_{mi}    with the constraints   \\beta_{H} > 0    \\beta_{C} > 0    \\mu_i > 0   For electric, qualifying models for selection must have each parameter estimate meet the minimum significance criteria of $p < 0.1$ and are strictly positive. All qualifying models are considered for final model selection.  For CalTRACK gas monthly savings analysis, the following candidate models are fit:   UPD_{mi} = \\mu_i + \\beta_{Hi}H_m +  \\epsilon_{mi}     UPD_{mi} = \\mu_i + \\beta_{Ci}C_m +  \\epsilon_{mi}     UPD_{mi} = \\mu_i + \\epsilon_{mi}    with the constraints   \\beta_{H} > 0    \\mu_i > 0   If each parameter estimate meets minimum significance criteria (p < 0.1) and are strictly positive, then the model is a qualifying model for inclusion in model selection.",
            "title": "3. Fit All Candidate Models and Apply Qualification Criteria"
        },
        {
            "location": "/monthly/analysis/#4-select-the-best-for-pre-intervenion-and-post-intervention-periods-for-use-in-second-stage-savings-estimation",
            "text": "All qualifying pre-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.  For the monthly billing analysis, because we are using fixed degree days instead of variable degree days, adjusted R-squared will be defined as    adjR^2 = 1 - \\frac{SS_{res}/df_e}{SS_{tot}/df_t}    Where    SS_{res}   is the sum of squares of residuals    df_e   is the degrees of freedom of the estimate of the underlying population error variance, and is calculated using  n-p-1 , where  n  is the number of observations in the sample used to estimate the model and  p  is the number of explanatory variables, not including the constant term and not including degree day base temperature as a parameter because it\u2019s fixed    SS_{tot}   is the total sum of squares    df_t   is the degrees of freedom of the estimate of the population variance of the dependent variable, and is calculated as  n-1 , were  n  is the size of the sample use to estimate the model  All qualifying post-intervention models are compared to each other and among qualifying models, the model with the maximum adjusted R-squared will be selected for second-stage savings estimation.",
            "title": "4. Select the best for pre-intervenion and post-intervention periods for use in second-stage savings estimation"
        },
        {
            "location": "/monthly/analysis/#5-estimate-second-stage-gross-savings-quantities-based-on-selected-first-stage-pre-and-post-intervention-models",
            "text": "During the second stage, up to five savings quantities will be estimated for each site that meets the minimum data sufficiency criteria for that savings statistic.  Cumulative gross savings over entire performance period\nYear one annualized actual gross savings in the the reporting (post-intervention) period\nYear two annualized actual gross savings in the the reporting (post-intervention) period\nYear one annualized gross savings in the normal year\nYear two annualized gross savings in the normal year  These site-level second stage quantities are calculated as follows:",
            "title": "5. Estimate second-stage gross savings quantities based on selected first stage pre- and post-intervention models"
        },
        {
            "location": "/monthly/analysis/#cumulative-gross-savings-over-entire-performance-period-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period after  work_end_date  using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for every complete billing periods after  work_end_date  for project  Sum   monthly_gross_savings  over every complete billing period since  work_end_date .",
            "title": "Cumulative gross savings over entire performance period (site-level)"
        },
        {
            "location": "/monthly/analysis/#year-one-gross-savings-from-1-to-12-months-after-site-visit-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period after  work_end_date  until 12 billing periods after  work_end_date   using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for 12 complete billing periods after  work_end_date  for project  Sum   monthly_gross_savings  over the 12 billing periods since  work_end_date .",
            "title": "Year one gross savings from 1 to 12 months after site visit. (site-level)"
        },
        {
            "location": "/monthly/analysis/#year-two-gross-savings-from-13-to-24-months-after-site-visit-site-level",
            "text": "Compute  predicted_baseline_use  for each complete billing period starting 13 months after  work_end_date  until 24 billing periods after  work_end_date   using parameter estimates from the stage one model from the pre-intervention (baseline) period model and the associated average degree days for each month in the post-intervention (reporting) period, ensuring that the same degree day values calculated for stage one model fits are use in stage two estimation.  Compute  monthly_gross_savings  =  predicted_baseline_monthly_use - actual_monthly_use  for month 13 to month 24 after  work_end_date  for project  Sum   monthly_gross_savings  over the 12 billing periods from 13 months after  work_end_date  to 24 months.",
            "title": "Year two gross savings from 13 to 24 months after site visit. (site-level)"
        },
        {
            "location": "/monthly/analysis/#year-one-site-level-annualized-gross-savings-in-the-normal-year",
            "text": "Compute  predicted_baseline_monthly_use  using the stage one model from the baseline period and average degree days from the CZ2010 normal weather year. Use the full month of available values when calculating the average degree days per billing period for the normal year.  Compute  predicted_reporting_monthly_use  using a  stage one  model fit to only the first 12 months of post-intervention values and degree days from the CZ2010 normal weather year file. Use the full month of available values when calculating the average degree days per billing period for the normal year.  Compute  monthly_normal_year_gross_savings  =  predicted_baseline_monthly_use - predicted_reporting_monthly_use  for normal year months  Sum   monthly_normal_year_gross_savings  over entire normal year.",
            "title": "Year one site-level annualized gross savings in the normal year"
        },
        {
            "location": "/monthly/analysis/#year-two-site-level-annualized-gross-savings-in-the-normal-year",
            "text": "Compute  predicted_baseline_monthly_use  using the stage one model from the baseline period and degree days from the CZ2010 normal weather year.  Compute  predicted_reporting_monthly_use  using a  stage one  model fit to only the 13th-24th months of post-intervention values and degree days from the CZ2010 normal weather year file for the relevant months.  Compute  monthly_normal_year_gross_savings  =  predicted_baseline_monthly_use - predicted_reporting_monthly_use  for each normal year month.  Sum   monthly_normal_year_gross_savings  over entire normal year.",
            "title": "Year two site-level annualized gross savings in the normal year"
        },
        {
            "location": "/monthly/analysis/#post-estimation-steps-and-portfolio-aggregation",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over  portfolios of homes . In order to do that, the above site-level savings quantities must be aggregated to get portfolio-level totals, means, and variances. Taking the site-level estimates, CalTRACK then performs a set of aggregation steps that are specified  here .",
            "title": "Post-estimation steps and portfolio aggregation"
        },
        {
            "location": "/monthly/aggregation/",
            "text": "Aggregating Site-level Gross Savings and Quantifying Uncertainty in Aggregate Savings Statistics\n\n\n\n\nThe goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over \nportfolios of residential single family buildings\n.\n\n\nPortfolio-level savings statistics are based on aggregations of site-level savings gross savings estimates created using the CalTRACK site-level monthly gross savings analysis methods.\n\n\nBecause all site-level savings quantities generated using CalTRACK's technical specifications are based on time series predictions, portfolio-level savings statistics primarily use prediction errors to estimate of site-level uncertainty, and calculate portfolio-level averages using inverse variance weighted means to get a consistent estimator of mean portfolio-level savings.\n\n\nMonthly Savings Estimate Aggregation Procedure\n\n\nThe main portfolio-level statistics of interest for CalTRACK are:\n\n\n\n\nWeighted mean annualized gross savings\n\n\nVariance annualized gross savings\n\n\nAnnualized gross savings prediction intervals (+/- 95%)\n\n\nUnweighted total annualized gross savings\n\n\nWeighted mean cumulative gross savings\n\n\nCumulative gross savings prediction intervals (+/-95%)\n\n\nUnweighted total cumulative gross savings\n\n\nWeighted mean year-one gross savings\n\n\nYear-one gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-one gross savings\n\n\nWeighted mean year-two gross savings\n\n\nYear-two gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-two gross savings\n\n\n\n\nSteps for calculating aggregate uncertainty and aggregate means.\n\n\nWhile a detailed treatment of how to calculate each of these quantities is included below, the main formulations are below:\n\n\n\n\nCalculate the site-level Mean Squared Error (MSE) as an unbiased estimator of the variance of the model errors, \ns^2\n :\n\n\n\n\n\n\ns^2 = \\sum{\\frac{\\hat{u}_i^2}{N\u2212k}}\n\n\n\n\n\n\nCalculate the site-level savings variance using in prediction error as an consistent estimator using the MSE, $s^2$, and variance in the out-of-sample data, $x_0$:\n\n\n\n\n\n\n\\hat{V}_s = s^2*x_0*(X'X)^{\u22121} * x_0' + s^2\n\n\n\n\n\n\nCalculate portfolio site-level inverse variance weighted mean savings using the savings variance and the following equation:\n\n\n\n\n\n\nIncluded Summary statistics for Portfolios of Sites\n\n\n\n\nWeighted mean annualized gross savings\n\n\nVariance annualized gross savings\n\n\nAnnualized gross savings prediction intervals (+/- 95%)\n\n\nUnweighted total annualized gross savings\n\n\nWeighted mean cumulative gross savings\n\n\nCumulative gross savings prediction intervals (+/-95%)\n\n\nUnweighted total cumulative gross savings\n\n\nWeighted mean year-one gross savings\n\n\nYear-one gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-one gross savings\n\n\nWeighted mean year-two gross savings\n\n\nYear-two gross savings prediction intervals (+/-95%)\n\n\nUnweighted total year-two gross savings\n\n\n\n\nCalculating site-level prediction intervals\n\n\nFor simplicity, and keeping with convention in the industry, site-level variance estimates based on ordinary least squares regressions will use OLS prediction error as the estimator for savings variance. Prediction error is calculated as follows:\n\n\nTake the stage one regression model with N observations and k regressors:\n\n\n\n\ny = X\\beta + u\n\n\n\n\nGiven a vector (or matrix) \nx_0\n of post-intervention (reporting) period degree day covariates, the predicted value for  observation would be\n\n\n\n\nE[y|x_0] = \\hat{y}_0 = x_0\\beta\n\n\n\n\nA consistent estimator of the variance of this prediction is\n\n\n\n\n\\hat{V}_p = s^2*x_0*(X'X)^{\u22121} * x_0\n\n\n\n\nwhere\n\n\n\n\ns^2 = \\sum{\\frac{\\hat{u}_i^2}{(N-k)}}\n\n\n\n\nand \nX\n is the matrix of stage one covariates.\n\n\nThe forecast error for a particular $y_0$ is\n\n\n\n\n\\hat{e} = y_0 \u2212 \\hat{y}_0= x_0\\beta + u_0 \u2212 \\hat{y}_0\n\n\n\n\nThe zero covariance between $u_0$ and $\\hat{\u03b2}$ implies that\n\n\n\n\nVar[\\hat{e}] = Var[\\hat{y}_0] + Var[u_0]\n\n\n\n\nand a consistent estimator of that is\n\n\n\n\n\\hat{V}_s=s^2*x_0*(X'X)^{\u22121} * x_0' + s^2\n\n\n\n\nThe \n1\u2212\\alpha\n site-level confidence interval will be:\n\n\n\n\ny_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_p)^.5\n\n\n\n\nThe \n1\u2212\u03b1\n confidence interval on the savings will be wider, based on the estimated savings variance:\n\n\n\n\ny_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_s)^.5\n\n\n\n\nCalculating Inverse-variance Weighted Portfolio Savings Means for Monthly Savings Analysis\n\n\nUsing site-level forecast variance as the consistent estimator of site-level gross savings estimation, CalTRACK calculates the inverse-variance weighted mean for each portfolio according to the following equation:\n\n\n\n\n\\hat{y} = \\frac{\\sum_i{y_i/ \\sigma_i^2}}{\\sum_i{1/ \\sigma^2_i}}\n\n\n\n\nFractional Savings uncertainty calculation\n\n\nBecause variances are larger in larger homes, normalizing levels of uncertainty using fractional savings uncertainty is an important aggregate metric, both for model comparison and selection, as well as final output. CalTRACK will compute the Fractional Savings Uncertainty at the site level based on the following equation:\n\n\n\n\nWhere\n\n\n\n\nCV\n is the coefficient of variance on the savings mean using prediction errors specified above\n\nt\n is the relevant t-statistic for the desired level of confidence\n\nF\n is the relevant F-statistic given degrees of freedom for the selected model\n\n\nCalculating 95% confidence intervals using fractional savings uncertainty\n\n\nTo calculate confidence intervals using the following equation:\n\n\n\n\nCI(95) = +/- (FSU * 1.96) * 100\n\n\n\n\nNote on the lack of comparison group adjustments in v1 Monthly CalTRACK technical specification\n\n\nWhile the technical working group acknowledged the potential use of comparison groups in gross savings estimation to correct for population-wide exogenous effects on use, after extensive debate, it was decided that the CalTRACK use cases (pay-for-performance in particular) required the ability for non-utility actors to be able to estimate savings without access to comparison group data. While several ideas were developed through the technical working group process about how to address this issue, there were serious concern about feasibility and the issue was tabled for future versions of CalTRACK.",
            "title": "Aggregration of Site-level Savings"
        },
        {
            "location": "/monthly/aggregation/#aggregating-site-level-gross-savings-and-quantifying-uncertainty-in-aggregate-savings-statistics",
            "text": "The goal of CalTRACK is to develop replicable, consistent, and methodologically defensible estimators of savings over  portfolios of residential single family buildings .  Portfolio-level savings statistics are based on aggregations of site-level savings gross savings estimates created using the CalTRACK site-level monthly gross savings analysis methods.  Because all site-level savings quantities generated using CalTRACK's technical specifications are based on time series predictions, portfolio-level savings statistics primarily use prediction errors to estimate of site-level uncertainty, and calculate portfolio-level averages using inverse variance weighted means to get a consistent estimator of mean portfolio-level savings.",
            "title": "Aggregating Site-level Gross Savings and Quantifying Uncertainty in Aggregate Savings Statistics"
        },
        {
            "location": "/monthly/aggregation/#monthly-savings-estimate-aggregation-procedure",
            "text": "The main portfolio-level statistics of interest for CalTRACK are:   Weighted mean annualized gross savings  Variance annualized gross savings  Annualized gross savings prediction intervals (+/- 95%)  Unweighted total annualized gross savings  Weighted mean cumulative gross savings  Cumulative gross savings prediction intervals (+/-95%)  Unweighted total cumulative gross savings  Weighted mean year-one gross savings  Year-one gross savings prediction intervals (+/-95%)  Unweighted total year-one gross savings  Weighted mean year-two gross savings  Year-two gross savings prediction intervals (+/-95%)  Unweighted total year-two gross savings",
            "title": "Monthly Savings Estimate Aggregation Procedure"
        },
        {
            "location": "/monthly/aggregation/#steps-for-calculating-aggregate-uncertainty-and-aggregate-means",
            "text": "While a detailed treatment of how to calculate each of these quantities is included below, the main formulations are below:   Calculate the site-level Mean Squared Error (MSE) as an unbiased estimator of the variance of the model errors,  s^2  :    s^2 = \\sum{\\frac{\\hat{u}_i^2}{N\u2212k}}    Calculate the site-level savings variance using in prediction error as an consistent estimator using the MSE, $s^2$, and variance in the out-of-sample data, $x_0$:    \\hat{V}_s = s^2*x_0*(X'X)^{\u22121} * x_0' + s^2    Calculate portfolio site-level inverse variance weighted mean savings using the savings variance and the following equation:",
            "title": "Steps for calculating aggregate uncertainty and aggregate means."
        },
        {
            "location": "/monthly/aggregation/#included-summary-statistics-for-portfolios-of-sites",
            "text": "Weighted mean annualized gross savings  Variance annualized gross savings  Annualized gross savings prediction intervals (+/- 95%)  Unweighted total annualized gross savings  Weighted mean cumulative gross savings  Cumulative gross savings prediction intervals (+/-95%)  Unweighted total cumulative gross savings  Weighted mean year-one gross savings  Year-one gross savings prediction intervals (+/-95%)  Unweighted total year-one gross savings  Weighted mean year-two gross savings  Year-two gross savings prediction intervals (+/-95%)  Unweighted total year-two gross savings",
            "title": "Included Summary statistics for Portfolios of Sites"
        },
        {
            "location": "/monthly/aggregation/#calculating-site-level-prediction-intervals",
            "text": "For simplicity, and keeping with convention in the industry, site-level variance estimates based on ordinary least squares regressions will use OLS prediction error as the estimator for savings variance. Prediction error is calculated as follows:  Take the stage one regression model with N observations and k regressors:   y = X\\beta + u   Given a vector (or matrix)  x_0  of post-intervention (reporting) period degree day covariates, the predicted value for  observation would be   E[y|x_0] = \\hat{y}_0 = x_0\\beta   A consistent estimator of the variance of this prediction is   \\hat{V}_p = s^2*x_0*(X'X)^{\u22121} * x_0   where   s^2 = \\sum{\\frac{\\hat{u}_i^2}{(N-k)}}   and  X  is the matrix of stage one covariates.  The forecast error for a particular $y_0$ is   \\hat{e} = y_0 \u2212 \\hat{y}_0= x_0\\beta + u_0 \u2212 \\hat{y}_0   The zero covariance between $u_0$ and $\\hat{\u03b2}$ implies that   Var[\\hat{e}] = Var[\\hat{y}_0] + Var[u_0]   and a consistent estimator of that is   \\hat{V}_s=s^2*x_0*(X'X)^{\u22121} * x_0' + s^2   The  1\u2212\\alpha  site-level confidence interval will be:   y_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_p)^.5   The  1\u2212\u03b1  confidence interval on the savings will be wider, based on the estimated savings variance:   y_0 \u00b1 t_(1\u2212\\alpha/2) * (\\hat{V}_s)^.5",
            "title": "Calculating site-level prediction intervals"
        },
        {
            "location": "/monthly/aggregation/#calculating-inverse-variance-weighted-portfolio-savings-means-for-monthly-savings-analysis",
            "text": "Using site-level forecast variance as the consistent estimator of site-level gross savings estimation, CalTRACK calculates the inverse-variance weighted mean for each portfolio according to the following equation:   \\hat{y} = \\frac{\\sum_i{y_i/ \\sigma_i^2}}{\\sum_i{1/ \\sigma^2_i}}",
            "title": "Calculating Inverse-variance Weighted Portfolio Savings Means for Monthly Savings Analysis"
        },
        {
            "location": "/monthly/aggregation/#fractional-savings-uncertainty-calculation",
            "text": "Because variances are larger in larger homes, normalizing levels of uncertainty using fractional savings uncertainty is an important aggregate metric, both for model comparison and selection, as well as final output. CalTRACK will compute the Fractional Savings Uncertainty at the site level based on the following equation:   Where   CV  is the coefficient of variance on the savings mean using prediction errors specified above t  is the relevant t-statistic for the desired level of confidence F  is the relevant F-statistic given degrees of freedom for the selected model",
            "title": "Fractional Savings uncertainty calculation"
        },
        {
            "location": "/monthly/aggregation/#calculating-95-confidence-intervals-using-fractional-savings-uncertainty",
            "text": "To calculate confidence intervals using the following equation:   CI(95) = +/- (FSU * 1.96) * 100",
            "title": "Calculating 95% confidence intervals using fractional savings uncertainty"
        },
        {
            "location": "/monthly/aggregation/#note-on-the-lack-of-comparison-group-adjustments-in-v1-monthly-caltrack-technical-specification",
            "text": "While the technical working group acknowledged the potential use of comparison groups in gross savings estimation to correct for population-wide exogenous effects on use, after extensive debate, it was decided that the CalTRACK use cases (pay-for-performance in particular) required the ability for non-utility actors to be able to estimate savings without access to comparison group data. While several ideas were developed through the technical working group process about how to address this issue, there were serious concern about feasibility and the issue was tabled for future versions of CalTRACK.",
            "title": "Note on the lack of comparison group adjustments in v1 Monthly CalTRACK technical specification"
        }
    ]
}